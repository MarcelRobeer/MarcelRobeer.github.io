{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Extension of text_explainability for sensitivity testing (robustness, fairness). Marcel Robeer, 2021 Installation Method Instructions pip Install from PyPI via pip3 install text_sensitivity . Local Clone this repository and install via pip3 install -e . or locally run python3 setup.py install . Documentation Full documentation of the latest version is provided at https://marcelrobeer.github.io/text_sensitivity/ . Example usage See example_usage.md to see an example of how the package can be used, or run the lines in example_usage.py to do explore it interactively. Releases text_explainability is officially released through PyPI . See CHANGELOG.md for a full overview of the changes for each version. Citation 1 2 3 4 5 6 @misc{text_sensitivity, title = {Python package text_sensitivity}, author = {Marcel Robeer and Elize Herrewijnen}, howpublished = {https://git.science.uu.nl/m.j.robeer/text_sensitivity}, year = {2021} } Maintenance Contributors Marcel Robeer ( @m.j.robeer ) Elize Herrewijnen ( @e.herrewijnen ) Todo Tasks yet to be done: Word-level perturbations Add fairness-specific metrics: Subgroup fairness Counterfactual fairness Tests Add tests for data generation Add tests for perturbations Add tests for test-schemes Add visualization ability","title":"Home"},{"location":"#installation","text":"Method Instructions pip Install from PyPI via pip3 install text_sensitivity . Local Clone this repository and install via pip3 install -e . or locally run python3 setup.py install .","title":"Installation"},{"location":"#documentation","text":"Full documentation of the latest version is provided at https://marcelrobeer.github.io/text_sensitivity/ .","title":"Documentation"},{"location":"#example-usage","text":"See example_usage.md to see an example of how the package can be used, or run the lines in example_usage.py to do explore it interactively.","title":"Example usage"},{"location":"#releases","text":"text_explainability is officially released through PyPI . See CHANGELOG.md for a full overview of the changes for each version.","title":"Releases"},{"location":"#citation","text":"1 2 3 4 5 6 @misc{text_sensitivity, title = {Python package text_sensitivity}, author = {Marcel Robeer and Elize Herrewijnen}, howpublished = {https://git.science.uu.nl/m.j.robeer/text_sensitivity}, year = {2021} }","title":"Citation"},{"location":"#maintenance","text":"","title":"Maintenance"},{"location":"#contributors","text":"Marcel Robeer ( @m.j.robeer ) Elize Herrewijnen ( @e.herrewijnen )","title":"Contributors"},{"location":"#todo","text":"Tasks yet to be done: Word-level perturbations Add fairness-specific metrics: Subgroup fairness Counterfactual fairness Tests Add tests for data generation Add tests for perturbations Add tests for test-schemes Add visualization ability","title":"Todo"},{"location":"CHANGELOG/","text":"Changelog All notable changes to text_sensitivity will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . Unreleased Added Citation information Documentation styling 0.1.3 - 2021-09-27 Added Documentation Ability to make OneToOnePerturbation from unordered list Extended one-to-one and one-to-many dictionary mappings 0.1.2 - 2021-09-24 Changed Proper n -times application of function with OneToManyPerturbation Fixed Bugfix in character generation 0.1.1 - 2021-09-24 Added Example usage Sensitivity testing wrapper functions (compare accuracy, precision, recall) 0.1.0 - 2021-09-24 Added Random data generation One to one perturbation One to many perturbation Example perturbation functions README.md LICENSE CI/CD pipeline for flake8 testing setup.py","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"All notable changes to text_sensitivity will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"CHANGELOG/#added","text":"Citation information Documentation styling","title":"Added"},{"location":"CHANGELOG/#013-2021-09-27","text":"","title":"0.1.3 - 2021-09-27"},{"location":"CHANGELOG/#added_1","text":"Documentation Ability to make OneToOnePerturbation from unordered list Extended one-to-one and one-to-many dictionary mappings","title":"Added"},{"location":"CHANGELOG/#012-2021-09-24","text":"","title":"0.1.2 - 2021-09-24"},{"location":"CHANGELOG/#changed","text":"Proper n -times application of function with OneToManyPerturbation","title":"Changed"},{"location":"CHANGELOG/#fixed","text":"Bugfix in character generation","title":"Fixed"},{"location":"CHANGELOG/#011-2021-09-24","text":"","title":"0.1.1 - 2021-09-24"},{"location":"CHANGELOG/#added_2","text":"Example usage Sensitivity testing wrapper functions (compare accuracy, precision, recall)","title":"Added"},{"location":"CHANGELOG/#010-2021-09-24","text":"","title":"0.1.0 - 2021-09-24"},{"location":"CHANGELOG/#added_3","text":"Random data generation One to one perturbation One to many perturbation Example perturbation functions README.md LICENSE CI/CD pipeline for flake8 testing setup.py","title":"Added"},{"location":"example_usage/","text":"Example Usage Dependencies Like text_explainability , text_sensitivity uses instances and machine learning models wrapped with the InstanceLib library. Dataset and model We manually create a TextEnvironment , that holds both our ground-truth labels ( .labels ) and our instances ( .dataset ). Next, we fit a simple sklearn model that predicts whether the instances (sentence-length strings) contain punctuation or not. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Create a simple dataset (classify whether strings contain punctuation or not) from instancelib.environment.text import TextEnvironment instances = [ 'This is his example instance, not HERS!' , 'An example sentence for you?!' , 'She has her own sentence.' , 'Provide him with something without any punctuation' , 'RANDOM UPPERCASESTRING3' ] labels = [ 'punctuation' , 'punctuation' , 'punctuation' , 'no_punctuation' , 'no_punctuation' ] env = TextEnvironment . from_data ( indices = list ( range ( len ( instances ))), data = instances , target_labels = list ( set ( labels )), ground_truth = [[ label ] for label in labels ], vectors = []) # Create sklearn model with pipeline from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import CountVectorizer from sklearn.naive_bayes import MultinomialNB p = Pipeline ([( 'vect' , CountVectorizer ()), ( 'rf' , MultinomialNB ())]) # Wrap sklearn model from instancelib.machinelearning import SkLearnDataClassifier model = SkLearnDataClassifier . build ( p , env ) model . fit_provider ( env . dataset , env . labels ) Using Text Sensitivity Text Sensitivity is used for robustness testing (verifying if a model can handle all types of string data and whether its predictions are invariant to minor changes) and fairness testing (comparing model performance on subgroups). Robustness A robust text model should be able to handle different types of input strings (e.g. ASCII, emojis) and be invariant to minor changes in inputs (e.g. converting a string to uppercase, adding an unrelated string or users making typos). Generating random data 1 2 3 4 5 6 7 8 9 10 11 from text_sensitivity import RandomData , RandomDigits , RandomAscii , RandomEmojis , RandomWhitespace , combine_generators # Generate 10 instances with all printable characteres list ( RandomData () . generate ( n = 10 , min_length = 5 , max_length = 50 ) . all_data ()) # Generate 5 instances containing only digits list ( RandomDigits ( seed = 1 ) . generate ( n = 5 ) . all_data ()) # Generate 15 instances, combining emojis, whitespace characters and ASCII characters random_generator = combine_generators ( RandomAscii (), RandomEmojis (), RandomWhitespace ()) list ( random_generator ( n = 15 ) . all_data ()) Invariance testing A very simple method for invariance testing, is assessing whether the model performs the same on a metric (e.g. accuracy, precision or recall) before and after applying a perturbation. For example, let us compare whether the model retains the same performance when converting all instances to lowercase: 1 2 3 4 from text_sensitivity.test import compare_accuracy from text_sensitivity.perturbation.sentences import to_lower compare_accuracy ( env , model , to_lower ) Similarly, we can check whether precision scores are the same if we add an unrelated string after each sentence: 1 2 3 4 5 from text_sensitivity.test import compare_precision from text_sensitivity.perturbation.base import OneToOnePerturbation perturbation_fn = OneToOnePerturbation . from_string ( suffix = 'This should not affect scores' ) compare_precision ( env , model , perturbation_fn ) Under the hood, text_sensitivity.test uses text_sensitivity.perturbation to perturb instances ( instancelib.instances.text.TextInstance or str ), and generates the new instances and labels for the original instance (e.g. 'not_upper') and the new instance(s) (e.g. 'upper'). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from text_sensitivity.perturbation.sentences import to_upper , repeat_n_times from text_sensitivity.perturbation.characters import random_case_swap , random_spaces , swap_random , add_typos sample = 'This is his example string, made especially for HER!' # Convert the sample string to all upper list ( to_upper ()( sample )) # Repeat the string 'test' n times list ( repeat_n_times ( n = 3 )( 'test' )) list ( repeat_n_times ( n = 7 , connector = ' \\n ' )( 'test' )) # Randomly swap the character case (lower to upper or vice versa) in sample list ( random_case_swap ()( sample )) # Add random spaces to words within a sentence, or swap characters randomly within a word (excluding stopwords and uppercase words) to sample list ( random_spaces ( n = 5 )( sample )) list ( swap_random ( n = 10 , stopwords = [ 'the' , 'is' , 'of' ], include_upper_case = False )( sample )) # Add typos (based on QWERTY keyboard) to sample list ( add_typos ( n = 10 , stopwords = [ 'the' , 'is' , 'of' ], include_numeric = False , include_special_char = False )( sample )) Fairness TODO : Write up fairness.","title":"Example usage"},{"location":"example_usage/#example-usage","text":"","title":"Example Usage"},{"location":"example_usage/#dependencies","text":"Like text_explainability , text_sensitivity uses instances and machine learning models wrapped with the InstanceLib library.","title":"Dependencies"},{"location":"example_usage/#dataset-and-model","text":"We manually create a TextEnvironment , that holds both our ground-truth labels ( .labels ) and our instances ( .dataset ). Next, we fit a simple sklearn model that predicts whether the instances (sentence-length strings) contain punctuation or not. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Create a simple dataset (classify whether strings contain punctuation or not) from instancelib.environment.text import TextEnvironment instances = [ 'This is his example instance, not HERS!' , 'An example sentence for you?!' , 'She has her own sentence.' , 'Provide him with something without any punctuation' , 'RANDOM UPPERCASESTRING3' ] labels = [ 'punctuation' , 'punctuation' , 'punctuation' , 'no_punctuation' , 'no_punctuation' ] env = TextEnvironment . from_data ( indices = list ( range ( len ( instances ))), data = instances , target_labels = list ( set ( labels )), ground_truth = [[ label ] for label in labels ], vectors = []) # Create sklearn model with pipeline from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import CountVectorizer from sklearn.naive_bayes import MultinomialNB p = Pipeline ([( 'vect' , CountVectorizer ()), ( 'rf' , MultinomialNB ())]) # Wrap sklearn model from instancelib.machinelearning import SkLearnDataClassifier model = SkLearnDataClassifier . build ( p , env ) model . fit_provider ( env . dataset , env . labels )","title":"Dataset and model"},{"location":"example_usage/#using-text-sensitivity","text":"Text Sensitivity is used for robustness testing (verifying if a model can handle all types of string data and whether its predictions are invariant to minor changes) and fairness testing (comparing model performance on subgroups).","title":"Using Text Sensitivity"},{"location":"example_usage/#robustness","text":"A robust text model should be able to handle different types of input strings (e.g. ASCII, emojis) and be invariant to minor changes in inputs (e.g. converting a string to uppercase, adding an unrelated string or users making typos).","title":"Robustness"},{"location":"example_usage/#generating-random-data","text":"1 2 3 4 5 6 7 8 9 10 11 from text_sensitivity import RandomData , RandomDigits , RandomAscii , RandomEmojis , RandomWhitespace , combine_generators # Generate 10 instances with all printable characteres list ( RandomData () . generate ( n = 10 , min_length = 5 , max_length = 50 ) . all_data ()) # Generate 5 instances containing only digits list ( RandomDigits ( seed = 1 ) . generate ( n = 5 ) . all_data ()) # Generate 15 instances, combining emojis, whitespace characters and ASCII characters random_generator = combine_generators ( RandomAscii (), RandomEmojis (), RandomWhitespace ()) list ( random_generator ( n = 15 ) . all_data ())","title":"Generating random data"},{"location":"example_usage/#invariance-testing","text":"A very simple method for invariance testing, is assessing whether the model performs the same on a metric (e.g. accuracy, precision or recall) before and after applying a perturbation. For example, let us compare whether the model retains the same performance when converting all instances to lowercase: 1 2 3 4 from text_sensitivity.test import compare_accuracy from text_sensitivity.perturbation.sentences import to_lower compare_accuracy ( env , model , to_lower ) Similarly, we can check whether precision scores are the same if we add an unrelated string after each sentence: 1 2 3 4 5 from text_sensitivity.test import compare_precision from text_sensitivity.perturbation.base import OneToOnePerturbation perturbation_fn = OneToOnePerturbation . from_string ( suffix = 'This should not affect scores' ) compare_precision ( env , model , perturbation_fn ) Under the hood, text_sensitivity.test uses text_sensitivity.perturbation to perturb instances ( instancelib.instances.text.TextInstance or str ), and generates the new instances and labels for the original instance (e.g. 'not_upper') and the new instance(s) (e.g. 'upper'). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from text_sensitivity.perturbation.sentences import to_upper , repeat_n_times from text_sensitivity.perturbation.characters import random_case_swap , random_spaces , swap_random , add_typos sample = 'This is his example string, made especially for HER!' # Convert the sample string to all upper list ( to_upper ()( sample )) # Repeat the string 'test' n times list ( repeat_n_times ( n = 3 )( 'test' )) list ( repeat_n_times ( n = 7 , connector = ' \\n ' )( 'test' )) # Randomly swap the character case (lower to upper or vice versa) in sample list ( random_case_swap ()( sample )) # Add random spaces to words within a sentence, or swap characters randomly within a word (excluding stopwords and uppercase words) to sample list ( random_spaces ( n = 5 )( sample )) list ( swap_random ( n = 10 , stopwords = [ 'the' , 'is' , 'of' ], include_upper_case = False )( sample )) # Add typos (based on QWERTY keyboard) to sample list ( add_typos ( n = 10 , stopwords = [ 'the' , 'is' , 'of' ], include_numeric = False , include_special_char = False )( sample ))","title":"Invariance testing"},{"location":"example_usage/#fairness","text":"TODO : Write up fairness.","title":"Fairness"},{"location":"reference/text_sensitivity/","text":"Module text_sensitivity None None View Source 1 2 3 4 5 6 7 8 9 10 11 from text_sensitivity.test import compare_accuracy, compare_precision, compare_recall from text_sensitivity.perturbation import Perturbation, OneToOnePerturbation, OneToManyPerturbation from text_sensitivity.data.random import (RandomData, RandomAscii, RandomDigits, RandomEmojis, RandomLower, RandomPunctuation, RandomSpaces, RandomUpper, RandomWhitespace, combine_generators) __version__ = '0.1.3' Sub-modules text_sensitivity.data text_sensitivity.perturbation text_sensitivity.test","title":"Index"},{"location":"reference/text_sensitivity/#module-text_sensitivity","text":"None None View Source 1 2 3 4 5 6 7 8 9 10 11 from text_sensitivity.test import compare_accuracy, compare_precision, compare_recall from text_sensitivity.perturbation import Perturbation, OneToOnePerturbation, OneToManyPerturbation from text_sensitivity.data.random import (RandomData, RandomAscii, RandomDigits, RandomEmojis, RandomLower, RandomPunctuation, RandomSpaces, RandomUpper, RandomWhitespace, combine_generators) __version__ = '0.1.3'","title":"Module text_sensitivity"},{"location":"reference/text_sensitivity/#sub-modules","text":"text_sensitivity.data text_sensitivity.perturbation text_sensitivity.test","title":"Sub-modules"},{"location":"reference/text_sensitivity/test/","text":"Module text_sensitivity.test None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 from typing import Union from instancelib.instances.base import InstanceProvider from instancelib.environment.text import TextEnvironment from instancelib.instances.text import TextInstanceProvider from instancelib.labels.memory import MemoryLabelProvider from instancelib.analysis.base import label_metrics from text_sensitivity.perturbation.base import Perturbation def apply_perturbation(dataset: Union[InstanceProvider, TextEnvironment], perturbation: Perturbation): if isinstance(dataset, TextEnvironment): dataset = dataset.dataset if not isinstance(perturbation, Perturbation): perturbation = perturbation() new_data, attributes = [], [] for key in dataset: for instances, labels in perturbation(dataset[key]): new_data.extend(instances) if isinstance(instances, list) else new_data.append(instances) attributes.extend(labels) if isinstance(labels, list) else attributes.append(labels) instanceprovider = TextInstanceProvider(new_data) instanceprovider.add_range(*dataset.dataset.get_all()) labelprovider = MemoryLabelProvider.from_tuples(attributes) return instanceprovider, labelprovider def equal_ground_truth(ground_truth, instances): # TODO: add ability to provide a different expectation of what will happen to the instance labels after perturbation for key in instances.keys(): parent_key = key.split('|')[0] if isinstance(key, str) else str(key) parent_key = int(parent_key) if parent_key.isdigit() else parent_key yield (key, ground_truth._labeldict[parent_key]) def compare_metric(env, model, perturbation): \"\"\"Get metrics for each ground-truth label and attribute.\"\"\" instances, attributes = apply_perturbation(env, perturbation) model_predictions = MemoryLabelProvider.from_tuples(model.predict(instances)) ground_truth = MemoryLabelProvider.from_tuples(equal_ground_truth(env.labels, instances)) for label in list(model_predictions.labelset): for attribute in list(attributes.labelset): metrics = label_metrics(model_predictions, ground_truth, attributes.get_instances_by_label(attribute), label) yield label, attribute, metrics def compare_accuracy(*args, **kwargs): \"\"\"Compare accuracy scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.accuracy) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'accuracy']) def compare_precision(*args, **kwargs): \"\"\"Compare precision scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.precision) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'precision']) def compare_recall(*args, **kwargs): \"\"\"Compare recall scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.recall) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'recall']) Functions apply_perturbation 1 2 3 4 def apply_perturbation ( dataset : Union [ instancelib . instances . base . InstanceProvider , instancelib . environment . text . TextEnvironment ], perturbation : text_sensitivity . perturbation . base . Perturbation ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def apply_perturbation(dataset: Union[InstanceProvider, TextEnvironment], perturbation: Perturbation): if isinstance(dataset, TextEnvironment): dataset = dataset.dataset if not isinstance(perturbation, Perturbation): perturbation = perturbation() new_data, attributes = [], [] for key in dataset: for instances, labels in perturbation(dataset[key]): new_data.extend(instances) if isinstance(instances, list) else new_data.append(instances) attributes.extend(labels) if isinstance(labels, list) else attributes.append(labels) instanceprovider = TextInstanceProvider(new_data) instanceprovider.add_range(*dataset.dataset.get_all()) labelprovider = MemoryLabelProvider.from_tuples(attributes) return instanceprovider, labelprovider compare_accuracy 1 2 3 4 def compare_accuracy ( * args , ** kwargs ) Compare accuracy scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_accuracy(*args, **kwargs): \"\"\"Compare accuracy scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.accuracy) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'accuracy']) compare_metric 1 2 3 4 5 def compare_metric ( env , model , perturbation ) Get metrics for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def compare_metric(env, model, perturbation): \"\"\"Get metrics for each ground-truth label and attribute.\"\"\" instances, attributes = apply_perturbation(env, perturbation) model_predictions = MemoryLabelProvider.from_tuples(model.predict(instances)) ground_truth = MemoryLabelProvider.from_tuples(equal_ground_truth(env.labels, instances)) for label in list(model_predictions.labelset): for attribute in list(attributes.labelset): metrics = label_metrics(model_predictions, ground_truth, attributes.get_instances_by_label(attribute), label) yield label, attribute, metrics compare_precision 1 2 3 4 def compare_precision ( * args , ** kwargs ) Compare precision scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_precision(*args, **kwargs): \"\"\"Compare precision scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.precision) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'precision']) compare_recall 1 2 3 4 def compare_recall ( * args , ** kwargs ) Compare recall scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_recall(*args, **kwargs): \"\"\"Compare recall scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.recall) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'recall']) equal_ground_truth 1 2 3 4 def equal_ground_truth ( ground_truth , instances ) View Source 1 2 3 4 5 6 7 8 9 10 11 def equal_ground_truth(ground_truth, instances): # TODO: add ability to provide a different expectation of what will happen to the instance labels after perturbation for key in instances.keys(): parent_key = key.split('|')[0] if isinstance(key, str) else str(key) parent_key = int(parent_key) if parent_key.isdigit() else parent_key yield (key, ground_truth._labeldict[parent_key])","title":"Test"},{"location":"reference/text_sensitivity/test/#module-text_sensitivitytest","text":"None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 from typing import Union from instancelib.instances.base import InstanceProvider from instancelib.environment.text import TextEnvironment from instancelib.instances.text import TextInstanceProvider from instancelib.labels.memory import MemoryLabelProvider from instancelib.analysis.base import label_metrics from text_sensitivity.perturbation.base import Perturbation def apply_perturbation(dataset: Union[InstanceProvider, TextEnvironment], perturbation: Perturbation): if isinstance(dataset, TextEnvironment): dataset = dataset.dataset if not isinstance(perturbation, Perturbation): perturbation = perturbation() new_data, attributes = [], [] for key in dataset: for instances, labels in perturbation(dataset[key]): new_data.extend(instances) if isinstance(instances, list) else new_data.append(instances) attributes.extend(labels) if isinstance(labels, list) else attributes.append(labels) instanceprovider = TextInstanceProvider(new_data) instanceprovider.add_range(*dataset.dataset.get_all()) labelprovider = MemoryLabelProvider.from_tuples(attributes) return instanceprovider, labelprovider def equal_ground_truth(ground_truth, instances): # TODO: add ability to provide a different expectation of what will happen to the instance labels after perturbation for key in instances.keys(): parent_key = key.split('|')[0] if isinstance(key, str) else str(key) parent_key = int(parent_key) if parent_key.isdigit() else parent_key yield (key, ground_truth._labeldict[parent_key]) def compare_metric(env, model, perturbation): \"\"\"Get metrics for each ground-truth label and attribute.\"\"\" instances, attributes = apply_perturbation(env, perturbation) model_predictions = MemoryLabelProvider.from_tuples(model.predict(instances)) ground_truth = MemoryLabelProvider.from_tuples(equal_ground_truth(env.labels, instances)) for label in list(model_predictions.labelset): for attribute in list(attributes.labelset): metrics = label_metrics(model_predictions, ground_truth, attributes.get_instances_by_label(attribute), label) yield label, attribute, metrics def compare_accuracy(*args, **kwargs): \"\"\"Compare accuracy scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.accuracy) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'accuracy']) def compare_precision(*args, **kwargs): \"\"\"Compare precision scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.precision) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'precision']) def compare_recall(*args, **kwargs): \"\"\"Compare recall scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.recall) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'recall'])","title":"Module text_sensitivity.test"},{"location":"reference/text_sensitivity/test/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/test/#apply_perturbation","text":"1 2 3 4 def apply_perturbation ( dataset : Union [ instancelib . instances . base . InstanceProvider , instancelib . environment . text . TextEnvironment ], perturbation : text_sensitivity . perturbation . base . Perturbation ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def apply_perturbation(dataset: Union[InstanceProvider, TextEnvironment], perturbation: Perturbation): if isinstance(dataset, TextEnvironment): dataset = dataset.dataset if not isinstance(perturbation, Perturbation): perturbation = perturbation() new_data, attributes = [], [] for key in dataset: for instances, labels in perturbation(dataset[key]): new_data.extend(instances) if isinstance(instances, list) else new_data.append(instances) attributes.extend(labels) if isinstance(labels, list) else attributes.append(labels) instanceprovider = TextInstanceProvider(new_data) instanceprovider.add_range(*dataset.dataset.get_all()) labelprovider = MemoryLabelProvider.from_tuples(attributes) return instanceprovider, labelprovider","title":"apply_perturbation"},{"location":"reference/text_sensitivity/test/#compare_accuracy","text":"1 2 3 4 def compare_accuracy ( * args , ** kwargs ) Compare accuracy scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_accuracy(*args, **kwargs): \"\"\"Compare accuracy scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.accuracy) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'accuracy'])","title":"compare_accuracy"},{"location":"reference/text_sensitivity/test/#compare_metric","text":"1 2 3 4 5 def compare_metric ( env , model , perturbation ) Get metrics for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def compare_metric(env, model, perturbation): \"\"\"Get metrics for each ground-truth label and attribute.\"\"\" instances, attributes = apply_perturbation(env, perturbation) model_predictions = MemoryLabelProvider.from_tuples(model.predict(instances)) ground_truth = MemoryLabelProvider.from_tuples(equal_ground_truth(env.labels, instances)) for label in list(model_predictions.labelset): for attribute in list(attributes.labelset): metrics = label_metrics(model_predictions, ground_truth, attributes.get_instances_by_label(attribute), label) yield label, attribute, metrics","title":"compare_metric"},{"location":"reference/text_sensitivity/test/#compare_precision","text":"1 2 3 4 def compare_precision ( * args , ** kwargs ) Compare precision scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_precision(*args, **kwargs): \"\"\"Compare precision scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.precision) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'precision'])","title":"compare_precision"},{"location":"reference/text_sensitivity/test/#compare_recall","text":"1 2 3 4 def compare_recall ( * args , ** kwargs ) Compare recall scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_recall(*args, **kwargs): \"\"\"Compare recall scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.recall) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'recall'])","title":"compare_recall"},{"location":"reference/text_sensitivity/test/#equal_ground_truth","text":"1 2 3 4 def equal_ground_truth ( ground_truth , instances ) View Source 1 2 3 4 5 6 7 8 9 10 11 def equal_ground_truth(ground_truth, instances): # TODO: add ability to provide a different expectation of what will happen to the instance labels after perturbation for key in instances.keys(): parent_key = key.split('|')[0] if isinstance(key, str) else str(key) parent_key = int(parent_key) if parent_key.isdigit() else parent_key yield (key, ground_truth._labeldict[parent_key])","title":"equal_ground_truth"},{"location":"reference/text_sensitivity/data/","text":"Module text_sensitivity.data None None Sub-modules text_sensitivity.data.random","title":"Index"},{"location":"reference/text_sensitivity/data/#module-text_sensitivitydata","text":"None None","title":"Module text_sensitivity.data"},{"location":"reference/text_sensitivity/data/#sub-modules","text":"text_sensitivity.data.random","title":"Sub-modules"},{"location":"reference/text_sensitivity/data/random/","text":"Module text_sensitivity.data.random None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 import string import numpy as np from typing import Union, List, Optional from instancelib.instances.text import TextInstanceProvider from text_explainability.default import Readable class RandomData(Readable): def __init__(self, seed: int = 0, options: Union[str, List[str]] = string.printable): \"\"\"Base class for random data (string) generation. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. options (Union[str, List[str]], optional): Characters or strings to generate data from. Defaults to string.printable. \"\"\" self._seed = seed self.options = options def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) def __call__(self, *args, **kwargs): \"\"\"Alias for `RandomData.generate()`.\"\"\" return self.generate(*args, **kwargs) class RandomSpaces(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number of spaces.\"\"\" super().__init__(seed=seed, options=' ') class RandomWhitespace(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number whitespace characters.\"\"\" super().__init__(seed=seed, options=string.whitespace) class RandomAscii(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII characters.\"\"\" super().__init__(seed=seed, options=string.ascii_letters) class RandomUpper(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII uppercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_uppercase) class RandomLower(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII lowercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_lowercase) class RandomDigits(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random digits.\"\"\" super().__init__(seed=seed, options=string.digits) class RandomPunctuation(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random punctuation characters.\"\"\" super().__init__(seed=seed, options=string.punctuation) class RandomEmojis(RandomData): def __init__(self, seed: int = 0, base: bool = True, dingbats: bool = True, flags: bool = True, components: bool = False): \"\"\"Generate strings containing a subset of random unicode emojis. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. base (bool, optional): Include base emojis (e.g. smiley face). Defaults to True. dingbats (bool, optional): Include dingbat emojis. Defaults to True. flags (bool, optional): Include flag emojis. Defaults to True. components (bool, optional): Include emoji components (e.g. skin color modifier or country flags). Defaults to False. Raises: AssertionError: At least one of `base`, `dingbats`, `flags` should be True. \"\"\" assert base or dingbats or flags, \\ 'At least one of `base`, `dingbats`, `flags` should be True.' emojis = [] if base: emojis.extend(['\\U0001F600', '\\U0001F601', '\\U0001F602', '\\U0001F603', '\\U0001F604', '\\U0001F605', '\\U0001F606', '\\U0001F607', '\\U0001F608', '\\U0001F609', '\\U0001F60A', '\\U0001F60B', '\\U0001F60C', '\\U0001F60D', '\\U0001F60E', '\\U0001F60F', '\\U0001F610', '\\U0001F611', '\\U0001F612', '\\U0001F613', '\\U0001F910', '\\U0001F911', '\\U0001F912', '\\U0001F913']) if dingbats: # 2700-27BF emojis.extend(['\\U00002704', '\\U00002705', '\\U00002706', '\\U00002707', '\\U00002708', '\\U00002709', '\\U0000270A', '\\U0000270B', '\\U0000270C', '\\U0000270D', '\\U0000270E', '\\U0000270F', '\\U0000274C', '\\U0000274D', '\\U0000274E', '\\U0000274F']) if flags: emojis.extend(['\\U00002690', '\\U00002691', '\\U0001F3F3', '\\U0001F3F4', '\\U0001F6A9']) if components: # e.g. country flags emojis.extend(['\\U0001F1E6\\U0001F1E8', '\\U0001F1E6\\U0001F1E9', '\\U0001F1E6\\U0001F1EA', '\\U0001F1E6\\U0001F1EB']) if components: emojis.extend(['\\U0001F9D1\\U0001F3FB', '\\U0001F9D1\\U0001F3FC', '\\U0001F9D1\\U0001F3FD', '\\U0001F9D1\\U0001F3FE']) super().__init__(seed=seed, options=emojis) def combine_generators(*generators, seed: Optional[int] = None) -> RandomData: \"\"\"Combine muliple random data generators into one. Args: *generators: Generators to combine. seed (Optional[int]): Seed value for new generator. If None picks a random seed from the generators. Defaults to None. Example: Make a generator that generates random punctuation, emojis and ASCII characters: >>> new_generator = combine_generators(RandomPunctuation(), RandomEmojis(), RandomAscii()) Returns: RandomData: Generator with all generator options combined. \"\"\" all_options = [list(generator.options) for generator in generators] if seed is None: seed = np.random.choice([generator._seed for generator in generators]) return RandomData(seed=seed, options=[item for sublist in all_options for item in sublist]) Functions combine_generators 1 2 3 4 def combine_generators ( * generators , seed : Optional [ int ] = None ) -> text_sensitivity . data . random . RandomData Combine muliple random data generators into one. Parameters: Name Type Description Default *generators None Generators to combine. None seed Optional[int] Seed value for new generator. If None picks a random seed from the generators. Defaults to None. None Returns: Type Description RandomData Generator with all generator options combined. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def combine_generators(*generators, seed: Optional[int] = None) -> RandomData: \"\"\"Combine muliple random data generators into one. Args: *generators: Generators to combine. seed (Optional[int]): Seed value for new generator. If None picks a random seed from the generators. Defaults to None. Example: Make a generator that generates random punctuation, emojis and ASCII characters: >>> new_generator = combine_generators(RandomPunctuation(), RandomEmojis(), RandomAscii()) Returns: RandomData: Generator with all generator options combined. \"\"\" all_options = [list(generator.options) for generator in generators] if seed is None: seed = np.random.choice([generator._seed for generator in generators]) return RandomData(seed=seed, options=[item for sublist in all_options for item in sublist]) Classes RandomAscii 1 2 3 class RandomAscii ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomAscii(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII characters.\"\"\" super().__init__(seed=seed, options=string.ascii_letters) Ancestors (in MRO) text_sensitivity.data.random.RandomData text_explainability.default.Readable Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) RandomData 1 2 3 4 class RandomData ( seed : int = 0 , options : Union [ str , List [ str ]] = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%& \\' ()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n\\r\\x0b\\x0c ' ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class RandomData(Readable): def __init__(self, seed: int = 0, options: Union[str, List[str]] = string.printable): \"\"\"Base class for random data (string) generation. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. options (Union[str, List[str]], optional): Characters or strings to generate data from. Defaults to string.printable. \"\"\" self._seed = seed self.options = options def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) def __call__(self, *args, **kwargs): \"\"\"Alias for `RandomData.generate()`.\"\"\" return self.generate(*args, **kwargs) Ancestors (in MRO) text_explainability.default.Readable Descendants text_sensitivity.data.random.RandomSpaces text_sensitivity.data.random.RandomWhitespace text_sensitivity.data.random.RandomAscii text_sensitivity.data.random.RandomUpper text_sensitivity.data.random.RandomLower text_sensitivity.data.random.RandomDigits text_sensitivity.data.random.RandomPunctuation text_sensitivity.data.random.RandomEmojis Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) RandomDigits 1 2 3 class RandomDigits ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomDigits(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random digits.\"\"\" super().__init__(seed=seed, options=string.digits) Ancestors (in MRO) text_sensitivity.data.random.RandomData text_explainability.default.Readable Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) RandomEmojis 1 2 3 4 5 6 7 class RandomEmojis ( seed : int = 0 , base : bool = True , dingbats : bool = True , flags : bool = True , components : bool = False ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class RandomEmojis(RandomData): def __init__(self, seed: int = 0, base: bool = True, dingbats: bool = True, flags: bool = True, components: bool = False): \"\"\"Generate strings containing a subset of random unicode emojis. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. base (bool, optional): Include base emojis (e.g. smiley face). Defaults to True. dingbats (bool, optional): Include dingbat emojis. Defaults to True. flags (bool, optional): Include flag emojis. Defaults to True. components (bool, optional): Include emoji components (e.g. skin color modifier or country flags). Defaults to False. Raises: AssertionError: At least one of `base`, `dingbats`, `flags` should be True. \"\"\" assert base or dingbats or flags, \\ 'At least one of `base`, `dingbats`, `flags` should be True.' emojis = [] if base: emojis.extend(['\\U0001F600', '\\U0001F601', '\\U0001F602', '\\U0001F603', '\\U0001F604', '\\U0001F605', '\\U0001F606', '\\U0001F607', '\\U0001F608', '\\U0001F609', '\\U0001F60A', '\\U0001F60B', '\\U0001F60C', '\\U0001F60D', '\\U0001F60E', '\\U0001F60F', '\\U0001F610', '\\U0001F611', '\\U0001F612', '\\U0001F613', '\\U0001F910', '\\U0001F911', '\\U0001F912', '\\U0001F913']) if dingbats: # 2700-27BF emojis.extend(['\\U00002704', '\\U00002705', '\\U00002706', '\\U00002707', '\\U00002708', '\\U00002709', '\\U0000270A', '\\U0000270B', '\\U0000270C', '\\U0000270D', '\\U0000270E', '\\U0000270F', '\\U0000274C', '\\U0000274D', '\\U0000274E', '\\U0000274F']) if flags: emojis.extend(['\\U00002690', '\\U00002691', '\\U0001F3F3', '\\U0001F3F4', '\\U0001F6A9']) if components: # e.g. country flags emojis.extend(['\\U0001F1E6\\U0001F1E8', '\\U0001F1E6\\U0001F1E9', '\\U0001F1E6\\U0001F1EA', '\\U0001F1E6\\U0001F1EB']) if components: emojis.extend(['\\U0001F9D1\\U0001F3FB', '\\U0001F9D1\\U0001F3FC', '\\U0001F9D1\\U0001F3FD', '\\U0001F9D1\\U0001F3FE']) super().__init__(seed=seed, options=emojis) Ancestors (in MRO) text_sensitivity.data.random.RandomData text_explainability.default.Readable Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) RandomLower 1 2 3 class RandomLower ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomLower(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII lowercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_lowercase) Ancestors (in MRO) text_sensitivity.data.random.RandomData text_explainability.default.Readable Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) RandomPunctuation 1 2 3 class RandomPunctuation ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomPunctuation(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random punctuation characters.\"\"\" super().__init__(seed=seed, options=string.punctuation) Ancestors (in MRO) text_sensitivity.data.random.RandomData text_explainability.default.Readable Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) RandomSpaces 1 2 3 class RandomSpaces ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomSpaces(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number of spaces.\"\"\" super().__init__(seed=seed, options=' ') Ancestors (in MRO) text_sensitivity.data.random.RandomData text_explainability.default.Readable Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) RandomUpper 1 2 3 class RandomUpper ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomUpper(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII uppercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_uppercase) Ancestors (in MRO) text_sensitivity.data.random.RandomData text_explainability.default.Readable Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) RandomWhitespace 1 2 3 class RandomWhitespace ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomWhitespace(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number whitespace characters.\"\"\" super().__init__(seed=seed, options=string.whitespace) Ancestors (in MRO) text_sensitivity.data.random.RandomData text_explainability.default.Readable Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data)","title":"Random"},{"location":"reference/text_sensitivity/data/random/#module-text_sensitivitydatarandom","text":"None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 import string import numpy as np from typing import Union, List, Optional from instancelib.instances.text import TextInstanceProvider from text_explainability.default import Readable class RandomData(Readable): def __init__(self, seed: int = 0, options: Union[str, List[str]] = string.printable): \"\"\"Base class for random data (string) generation. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. options (Union[str, List[str]], optional): Characters or strings to generate data from. Defaults to string.printable. \"\"\" self._seed = seed self.options = options def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) def __call__(self, *args, **kwargs): \"\"\"Alias for `RandomData.generate()`.\"\"\" return self.generate(*args, **kwargs) class RandomSpaces(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number of spaces.\"\"\" super().__init__(seed=seed, options=' ') class RandomWhitespace(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number whitespace characters.\"\"\" super().__init__(seed=seed, options=string.whitespace) class RandomAscii(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII characters.\"\"\" super().__init__(seed=seed, options=string.ascii_letters) class RandomUpper(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII uppercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_uppercase) class RandomLower(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII lowercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_lowercase) class RandomDigits(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random digits.\"\"\" super().__init__(seed=seed, options=string.digits) class RandomPunctuation(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random punctuation characters.\"\"\" super().__init__(seed=seed, options=string.punctuation) class RandomEmojis(RandomData): def __init__(self, seed: int = 0, base: bool = True, dingbats: bool = True, flags: bool = True, components: bool = False): \"\"\"Generate strings containing a subset of random unicode emojis. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. base (bool, optional): Include base emojis (e.g. smiley face). Defaults to True. dingbats (bool, optional): Include dingbat emojis. Defaults to True. flags (bool, optional): Include flag emojis. Defaults to True. components (bool, optional): Include emoji components (e.g. skin color modifier or country flags). Defaults to False. Raises: AssertionError: At least one of `base`, `dingbats`, `flags` should be True. \"\"\" assert base or dingbats or flags, \\ 'At least one of `base`, `dingbats`, `flags` should be True.' emojis = [] if base: emojis.extend(['\\U0001F600', '\\U0001F601', '\\U0001F602', '\\U0001F603', '\\U0001F604', '\\U0001F605', '\\U0001F606', '\\U0001F607', '\\U0001F608', '\\U0001F609', '\\U0001F60A', '\\U0001F60B', '\\U0001F60C', '\\U0001F60D', '\\U0001F60E', '\\U0001F60F', '\\U0001F610', '\\U0001F611', '\\U0001F612', '\\U0001F613', '\\U0001F910', '\\U0001F911', '\\U0001F912', '\\U0001F913']) if dingbats: # 2700-27BF emojis.extend(['\\U00002704', '\\U00002705', '\\U00002706', '\\U00002707', '\\U00002708', '\\U00002709', '\\U0000270A', '\\U0000270B', '\\U0000270C', '\\U0000270D', '\\U0000270E', '\\U0000270F', '\\U0000274C', '\\U0000274D', '\\U0000274E', '\\U0000274F']) if flags: emojis.extend(['\\U00002690', '\\U00002691', '\\U0001F3F3', '\\U0001F3F4', '\\U0001F6A9']) if components: # e.g. country flags emojis.extend(['\\U0001F1E6\\U0001F1E8', '\\U0001F1E6\\U0001F1E9', '\\U0001F1E6\\U0001F1EA', '\\U0001F1E6\\U0001F1EB']) if components: emojis.extend(['\\U0001F9D1\\U0001F3FB', '\\U0001F9D1\\U0001F3FC', '\\U0001F9D1\\U0001F3FD', '\\U0001F9D1\\U0001F3FE']) super().__init__(seed=seed, options=emojis) def combine_generators(*generators, seed: Optional[int] = None) -> RandomData: \"\"\"Combine muliple random data generators into one. Args: *generators: Generators to combine. seed (Optional[int]): Seed value for new generator. If None picks a random seed from the generators. Defaults to None. Example: Make a generator that generates random punctuation, emojis and ASCII characters: >>> new_generator = combine_generators(RandomPunctuation(), RandomEmojis(), RandomAscii()) Returns: RandomData: Generator with all generator options combined. \"\"\" all_options = [list(generator.options) for generator in generators] if seed is None: seed = np.random.choice([generator._seed for generator in generators]) return RandomData(seed=seed, options=[item for sublist in all_options for item in sublist])","title":"Module text_sensitivity.data.random"},{"location":"reference/text_sensitivity/data/random/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/data/random/#combine_generators","text":"1 2 3 4 def combine_generators ( * generators , seed : Optional [ int ] = None ) -> text_sensitivity . data . random . RandomData Combine muliple random data generators into one. Parameters: Name Type Description Default *generators None Generators to combine. None seed Optional[int] Seed value for new generator. If None picks a random seed from the generators. Defaults to None. None Returns: Type Description RandomData Generator with all generator options combined. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def combine_generators(*generators, seed: Optional[int] = None) -> RandomData: \"\"\"Combine muliple random data generators into one. Args: *generators: Generators to combine. seed (Optional[int]): Seed value for new generator. If None picks a random seed from the generators. Defaults to None. Example: Make a generator that generates random punctuation, emojis and ASCII characters: >>> new_generator = combine_generators(RandomPunctuation(), RandomEmojis(), RandomAscii()) Returns: RandomData: Generator with all generator options combined. \"\"\" all_options = [list(generator.options) for generator in generators] if seed is None: seed = np.random.choice([generator._seed for generator in generators]) return RandomData(seed=seed, options=[item for sublist in all_options for item in sublist])","title":"combine_generators"},{"location":"reference/text_sensitivity/data/random/#classes","text":"","title":"Classes"},{"location":"reference/text_sensitivity/data/random/#randomascii","text":"1 2 3 class RandomAscii ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomAscii(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII characters.\"\"\" super().__init__(seed=seed, options=string.ascii_letters)","title":"RandomAscii"},{"location":"reference/text_sensitivity/data/random/#ancestors-in-mro","text":"text_sensitivity.data.random.RandomData text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/#methods","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/#generate","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/#randomdata","text":"1 2 3 4 class RandomData ( seed : int = 0 , options : Union [ str , List [ str ]] = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%& \\' ()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n\\r\\x0b\\x0c ' ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class RandomData(Readable): def __init__(self, seed: int = 0, options: Union[str, List[str]] = string.printable): \"\"\"Base class for random data (string) generation. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. options (Union[str, List[str]], optional): Characters or strings to generate data from. Defaults to string.printable. \"\"\" self._seed = seed self.options = options def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data) def __call__(self, *args, **kwargs): \"\"\"Alias for `RandomData.generate()`.\"\"\" return self.generate(*args, **kwargs)","title":"RandomData"},{"location":"reference/text_sensitivity/data/random/#ancestors-in-mro_1","text":"text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/#descendants","text":"text_sensitivity.data.random.RandomSpaces text_sensitivity.data.random.RandomWhitespace text_sensitivity.data.random.RandomAscii text_sensitivity.data.random.RandomUpper text_sensitivity.data.random.RandomLower text_sensitivity.data.random.RandomDigits text_sensitivity.data.random.RandomPunctuation text_sensitivity.data.random.RandomEmojis","title":"Descendants"},{"location":"reference/text_sensitivity/data/random/#methods_1","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/#generate_1","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/#randomdigits","text":"1 2 3 class RandomDigits ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomDigits(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random digits.\"\"\" super().__init__(seed=seed, options=string.digits)","title":"RandomDigits"},{"location":"reference/text_sensitivity/data/random/#ancestors-in-mro_2","text":"text_sensitivity.data.random.RandomData text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/#methods_2","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/#generate_2","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/#randomemojis","text":"1 2 3 4 5 6 7 class RandomEmojis ( seed : int = 0 , base : bool = True , dingbats : bool = True , flags : bool = True , components : bool = False ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class RandomEmojis(RandomData): def __init__(self, seed: int = 0, base: bool = True, dingbats: bool = True, flags: bool = True, components: bool = False): \"\"\"Generate strings containing a subset of random unicode emojis. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. base (bool, optional): Include base emojis (e.g. smiley face). Defaults to True. dingbats (bool, optional): Include dingbat emojis. Defaults to True. flags (bool, optional): Include flag emojis. Defaults to True. components (bool, optional): Include emoji components (e.g. skin color modifier or country flags). Defaults to False. Raises: AssertionError: At least one of `base`, `dingbats`, `flags` should be True. \"\"\" assert base or dingbats or flags, \\ 'At least one of `base`, `dingbats`, `flags` should be True.' emojis = [] if base: emojis.extend(['\\U0001F600', '\\U0001F601', '\\U0001F602', '\\U0001F603', '\\U0001F604', '\\U0001F605', '\\U0001F606', '\\U0001F607', '\\U0001F608', '\\U0001F609', '\\U0001F60A', '\\U0001F60B', '\\U0001F60C', '\\U0001F60D', '\\U0001F60E', '\\U0001F60F', '\\U0001F610', '\\U0001F611', '\\U0001F612', '\\U0001F613', '\\U0001F910', '\\U0001F911', '\\U0001F912', '\\U0001F913']) if dingbats: # 2700-27BF emojis.extend(['\\U00002704', '\\U00002705', '\\U00002706', '\\U00002707', '\\U00002708', '\\U00002709', '\\U0000270A', '\\U0000270B', '\\U0000270C', '\\U0000270D', '\\U0000270E', '\\U0000270F', '\\U0000274C', '\\U0000274D', '\\U0000274E', '\\U0000274F']) if flags: emojis.extend(['\\U00002690', '\\U00002691', '\\U0001F3F3', '\\U0001F3F4', '\\U0001F6A9']) if components: # e.g. country flags emojis.extend(['\\U0001F1E6\\U0001F1E8', '\\U0001F1E6\\U0001F1E9', '\\U0001F1E6\\U0001F1EA', '\\U0001F1E6\\U0001F1EB']) if components: emojis.extend(['\\U0001F9D1\\U0001F3FB', '\\U0001F9D1\\U0001F3FC', '\\U0001F9D1\\U0001F3FD', '\\U0001F9D1\\U0001F3FE']) super().__init__(seed=seed, options=emojis)","title":"RandomEmojis"},{"location":"reference/text_sensitivity/data/random/#ancestors-in-mro_3","text":"text_sensitivity.data.random.RandomData text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/#methods_3","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/#generate_3","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/#randomlower","text":"1 2 3 class RandomLower ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomLower(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII lowercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_lowercase)","title":"RandomLower"},{"location":"reference/text_sensitivity/data/random/#ancestors-in-mro_4","text":"text_sensitivity.data.random.RandomData text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/#methods_4","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/#generate_4","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/#randompunctuation","text":"1 2 3 class RandomPunctuation ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomPunctuation(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random punctuation characters.\"\"\" super().__init__(seed=seed, options=string.punctuation)","title":"RandomPunctuation"},{"location":"reference/text_sensitivity/data/random/#ancestors-in-mro_5","text":"text_sensitivity.data.random.RandomData text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/#methods_5","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/#generate_5","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/#randomspaces","text":"1 2 3 class RandomSpaces ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomSpaces(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number of spaces.\"\"\" super().__init__(seed=seed, options=' ')","title":"RandomSpaces"},{"location":"reference/text_sensitivity/data/random/#ancestors-in-mro_6","text":"text_sensitivity.data.random.RandomData text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/#methods_6","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/#generate_6","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/#randomupper","text":"1 2 3 class RandomUpper ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomUpper(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII uppercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_uppercase)","title":"RandomUpper"},{"location":"reference/text_sensitivity/data/random/#ancestors-in-mro_7","text":"text_sensitivity.data.random.RandomData text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/#methods_7","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/#generate_7","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/#randomwhitespace","text":"1 2 3 class RandomWhitespace ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomWhitespace(RandomData): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number whitespace characters.\"\"\" super().__init__(seed=seed, options=string.whitespace)","title":"RandomWhitespace"},{"location":"reference/text_sensitivity/data/random/#ancestors-in-mro_8","text":"text_sensitivity.data.random.RandomData text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/#methods_8","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/#generate_8","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description AssertionError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: AssertionError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" assert min_length < max_length, 'min_length should be smaller than max_length' min_length = max(min_length, 0) np.random.seed(self._seed) data = [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/perturbation/","text":"Module text_sensitivity.perturbation None None View Source 1 from text_sensitivity.perturbation.base import Perturbation, OneToOnePerturbation, OneToManyPerturbation Sub-modules text_sensitivity.perturbation.base text_sensitivity.perturbation.characters text_sensitivity.perturbation.sentences text_sensitivity.perturbation.words","title":"Index"},{"location":"reference/text_sensitivity/perturbation/#module-text_sensitivityperturbation","text":"None None View Source 1 from text_sensitivity.perturbation.base import Perturbation, OneToOnePerturbation, OneToManyPerturbation","title":"Module text_sensitivity.perturbation"},{"location":"reference/text_sensitivity/perturbation/#sub-modules","text":"text_sensitivity.perturbation.base text_sensitivity.perturbation.characters text_sensitivity.perturbation.sentences text_sensitivity.perturbation.words","title":"Sub-modules"},{"location":"reference/text_sensitivity/perturbation/base/","text":"Module text_sensitivity.perturbation.base None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 import numpy as np import itertools import copy from typing import Tuple, Dict, List, Optional, Callable, Sequence, Union, Iterable from nlpaug.base_augmenter import Augmenter from instancelib.instances.text import TextInstance, MemoryTextInstance from instancelib.typehints import KT, LT from text_explainability.default import Readable from text_explainability.decorators import text_instance from text_explainability.utils import default_tokenizer, default_detokenizer def oneway_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer) -> Optional[Tuple[str, LT, LT]]: tokenized = tokenizer(instance.data) # Get all options options = {i: dictionary[a] for i, a in enumerate(tokenized) if a in dictionary.keys()} all_options = list(itertools.product(*options.values())) # Pick up to N random replacements and apply them for idx in set(np.random.randint(len(all_options), size=n)): current_option = all_options[idx] new_tokenized = copy.deepcopy(tokenized) for i, option in enumerate(current_option): new_tokenized[options.keys()[i]] = option if tokenized != new_tokenized: yield detokenizer(new_tokenized), label_from, label_to def one_to_one_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, tokenizer, detokenizer): return list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=1))[0] def one_to_many_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=n)) res = list(filter(None, res)) if len(res) == 0: return None return res def as_list(x): return [x] if not isinstance(x, Iterable) or isinstance(x, str) else x def format_identifier(instance, key): return f'{instance.identifier}|{key}' class Perturbation(Readable): def __init__(self, perturbation_function: Callable): \"\"\"Apply a perturbation function to a single `TextInstance`. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and resulting instance(s). Should return None if no perturbation has been applied. \"\"\" self.perturbation_function = perturbation_function @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.') @text_instance def __call__(self, instance: TextInstance): return self.perturb(instance) class OneToOnePerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[str, LT, LT]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.', '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" mapping_list = [(a, b) for a, b in set(list(itertools.combinations(mapping_list, 2)))] return OneToManyPerturbation.from_tuples(mapping_list, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: AssertionError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" assert prefix is not None or suffix is not None or replacement is not None, \\ 'At least one of `prefix`, `suffix` and `replacement` should be provided.' if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))]) class OneToManyPerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[Sequence[str], LT, Union[LT, Sequence[LT]]]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to) @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, n=n, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])] Functions as_list 1 2 3 def as_list ( x ) View Source 1 2 3 def as_list(x): return [x] if not isinstance(x, Iterable) or isinstance(x, str) else x format_identifier 1 2 3 4 def format_identifier ( instance , key ) View Source 1 2 3 def format_identifier(instance, key): return f'{instance.identifier}|{key}' one_to_many_dictionary_mapping 1 2 3 4 5 6 7 8 9 def one_to_many_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int , tokenizer , detokenizer ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def one_to_many_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=n)) res = list(filter(None, res)) if len(res) == 0: return None return res one_to_one_dictionary_mapping 1 2 3 4 5 6 7 8 def one_to_one_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , tokenizer , detokenizer ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def one_to_one_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, tokenizer, detokenizer): return list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=1))[0] oneway_dictionary_mapping 1 2 3 4 5 6 7 8 9 def oneway_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int , tokenizer , detokenizer ) -> Optional [ Tuple [ str , ~ LT , ~ LT ]] View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def oneway_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer) -> Optional[Tuple[str, LT, LT]]: tokenized = tokenizer(instance.data) # Get all options options = {i: dictionary[a] for i, a in enumerate(tokenized) if a in dictionary.keys()} all_options = list(itertools.product(*options.values())) # Pick up to N random replacements and apply them for idx in set(np.random.randint(len(all_options), size=n)): current_option = all_options[idx] new_tokenized = copy.deepcopy(tokenized) for i, option in enumerate(current_option): new_tokenized[options.keys()[i]] = option if tokenized != new_tokenized: yield detokenizer(new_tokenized), label_from, label_to Classes OneToManyPerturbation 1 2 3 class OneToManyPerturbation ( perturbation_function : Callable [[ instancelib . instances . text . TextInstance ], Optional [ Tuple [ Sequence [ str ], ~ LT , Union [ ~ LT , Sequence [ ~ LT ]]]]] ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 class OneToManyPerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[Sequence[str], LT, Union[LT, Sequence[LT]]]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to) @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, n=n, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])] Ancestors (in MRO) text_sensitivity.perturbation.base.Perturbation text_explainability.default.Readable Static methods from_dict 1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) from_dictionary 1 2 3 4 5 6 7 8 def from_dictionary ( dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int = 10 , tokenizer : Callable = < function word_tokenizer at 0x16d0281f0 > , detokenizer : Callable = < function word_detokenizer at 0x16d028310 > ) Construct a OneToManyPerturbation from a dictionary. Parameters: Name Type Description Default dictionary Dict[str, List[str]] Lookup dictionary to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of dictionary). None label_to LT Attribute label of perturbed instance (right-hand side of dictionary). None n int Number of instances to generate. Defaults to 10. 10 tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) from_function 1 2 3 4 5 6 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , n : int = 10 ) Construct a OneToManyPerturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' n int Number of instances to generate. Defaults to 10. 10 View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to) from_nlpaug 1 2 3 4 5 6 7 def from_nlpaug ( augmenter : nlpaug . base_augmenter . Augmenter , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , n : int = 10 , ** augment_kwargs ) Construct a OneToManyPerturbation from a nlpaug _ Augmenter. Parameters: Name Type Description Default augmenter Augmenter Class with .augment() function applying a perturbation to a string. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' n int Number of instances to generate. Defaults to 10. 10 **augment_kwargs None Optional arguments passed to .augment() function. .. _nlpaug: None https None //github.com/makcedward/nlpaug None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, n=n, label_from=label_from, label_to=label_to) from_str 1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) from_string 1 2 3 4 def from_string ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') Methods perturb 1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) -> Optional [ Sequence [ Tuple [ instancelib . instances . text . TextInstance , Sequence [ Tuple [ ~ KT , ~ LT ]]]]] Apply a perturbation function to a single TextInstance , getting a multiple results per instance. Parameters: Name Type Description Default perturbation_function Callable Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. None Returns: Type Description Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]] None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])] OneToOnePerturbation 1 2 3 class OneToOnePerturbation ( perturbation_function : Callable [[ instancelib . instances . text . TextInstance ], Optional [ Tuple [ str , ~ LT , ~ LT ]]] ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 class OneToOnePerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[str, LT, LT]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.', '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" mapping_list = [(a, b) for a, b in set(list(itertools.combinations(mapping_list, 2)))] return OneToManyPerturbation.from_tuples(mapping_list, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: AssertionError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" assert prefix is not None or suffix is not None or replacement is not None, \\ 'At least one of `prefix`, `suffix` and `replacement` should be provided.' if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))]) Ancestors (in MRO) text_sensitivity.perturbation.base.Perturbation text_explainability.default.Readable Static methods from_dict 1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) from_dictionary 1 2 3 4 5 6 7 def from_dictionary ( dictionary : Dict [ str , str ], label_from : ~ LT , label_to : ~ LT , tokenizer : Callable = < function word_tokenizer at 0x16d0281f0 > , detokenizer : Callable = < function word_detokenizer at 0x16d028310 > ) Construct a OneToOnePerturbation from a dictionary. Parameters: Name Type Description Default dictionary Dict[str, str] Lookup dictionary to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of dictionary). None label_to LT Attribute label of perturbed instance (right-hand side of dictionary). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.', '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) from_function 1 2 3 4 5 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' ) Construct a Perturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) from_list 1 2 3 4 5 6 7 def from_list ( mapping_list : List [ str ], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , tokenizer : Callable = < function word_tokenizer at 0x16d0281f0 > , detokenizer : Callable = < function word_detokenizer at 0x16d028310 > ) Construct a OneToOnePerturbation from a list. A function is constructed that aims to map any value in the list to any other value in the list. Parameters: Name Type Description Default mapping_list List[str] Lookup list of tokens (e.g. words, characters). None label_from LT Attribute label of original instance (non-replaced). None label_to LT Attribute label of perturbed instance (replaced). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" mapping_list = [(a, b) for a, b in set(list(itertools.combinations(mapping_list, 2)))] return OneToManyPerturbation.from_tuples(mapping_list, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) from_nlpaug 1 2 3 4 5 6 def from_nlpaug ( augmenter : nlpaug . base_augmenter . Augmenter , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , ** augment_kwargs ) Construct a OneToOnePerturbation from a nlpaug _ Augmenter. Parameters: Name Type Description Default augmenter Augmenter Class with .augment() function applying a perturbation to a string. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' **augment_kwargs None Optional arguments passed to .augment() function. .. _nlpaug: None https None //github.com/makcedward/nlpaug None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to) from_str 1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) from_string 1 2 3 4 5 6 7 8 9 10 def from_string ( prefix : Optional [ str ] = None , suffix : Optional [ str ] = None , replacement : Optional [ str ] = None , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , connector : str = ' ' , connector_before : Optional [ str ] = None , connector_after : Optional [ str ] = None ) Construct a OneToOnePerturbation from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of prefix , suffix or replacement should be a string to apply the replacement. 1 2 3 4 5 6 7 8 9 10 11 Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after=' ', >>> label_to='more_negative') 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: AssertionError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: AssertionError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" assert prefix is not None or suffix is not None or replacement is not None, \\ 'At least one of `prefix`, `suffix` and `replacement` should be provided.' if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function) from_tuples 1 2 3 4 5 6 7 def from_tuples ( tuples : List [ Tuple [ str , str ]], label_from : ~ LT , label_to : ~ LT , tokenizer : Callable = < function word_tokenizer at 0x16d0281f0 > , detokenizer : Callable = < function word_detokenizer at 0x16d028310 > ) Construct a OneToOnePerturbation from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Parameters: Name Type Description Default tuples List[Tuple[str, str]] Lookup tuples to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of tuples). None label_to LT Attribute label of perturbed instance (right-hand side of tuples). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) Methods perturb 1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) -> Optional [ Sequence [ Tuple [ instancelib . instances . text . TextInstance , Sequence [ Tuple [ ~ KT , ~ LT ]]]]] Apply a perturbation function to a single TextInstance , getting a single result per instance. Parameters: Name Type Description Default perturbation_function Callable Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. None Returns: Type Description Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]] None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))]) Perturbation 1 2 3 class Perturbation ( perturbation_function : Callable ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class Perturbation(Readable): def __init__(self, perturbation_function: Callable): \"\"\"Apply a perturbation function to a single `TextInstance`. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and resulting instance(s). Should return None if no perturbation has been applied. \"\"\" self.perturbation_function = perturbation_function @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.') @text_instance def __call__(self, instance: TextInstance): return self.perturb(instance) Ancestors (in MRO) text_explainability.default.Readable Descendants text_sensitivity.perturbation.base.OneToOnePerturbation text_sensitivity.perturbation.base.OneToManyPerturbation Static methods from_dict 1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) from_dictionary 1 2 3 4 def from_dictionary ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') from_function 1 2 3 4 5 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' ) Construct a Perturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) from_str 1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) from_string 1 2 3 4 def from_string ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') Methods perturb 1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) View Source 1 2 3 4 5 @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.')","title":"Base"},{"location":"reference/text_sensitivity/perturbation/base/#module-text_sensitivityperturbationbase","text":"None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 import numpy as np import itertools import copy from typing import Tuple, Dict, List, Optional, Callable, Sequence, Union, Iterable from nlpaug.base_augmenter import Augmenter from instancelib.instances.text import TextInstance, MemoryTextInstance from instancelib.typehints import KT, LT from text_explainability.default import Readable from text_explainability.decorators import text_instance from text_explainability.utils import default_tokenizer, default_detokenizer def oneway_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer) -> Optional[Tuple[str, LT, LT]]: tokenized = tokenizer(instance.data) # Get all options options = {i: dictionary[a] for i, a in enumerate(tokenized) if a in dictionary.keys()} all_options = list(itertools.product(*options.values())) # Pick up to N random replacements and apply them for idx in set(np.random.randint(len(all_options), size=n)): current_option = all_options[idx] new_tokenized = copy.deepcopy(tokenized) for i, option in enumerate(current_option): new_tokenized[options.keys()[i]] = option if tokenized != new_tokenized: yield detokenizer(new_tokenized), label_from, label_to def one_to_one_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, tokenizer, detokenizer): return list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=1))[0] def one_to_many_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=n)) res = list(filter(None, res)) if len(res) == 0: return None return res def as_list(x): return [x] if not isinstance(x, Iterable) or isinstance(x, str) else x def format_identifier(instance, key): return f'{instance.identifier}|{key}' class Perturbation(Readable): def __init__(self, perturbation_function: Callable): \"\"\"Apply a perturbation function to a single `TextInstance`. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and resulting instance(s). Should return None if no perturbation has been applied. \"\"\" self.perturbation_function = perturbation_function @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.') @text_instance def __call__(self, instance: TextInstance): return self.perturb(instance) class OneToOnePerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[str, LT, LT]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.', '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" mapping_list = [(a, b) for a, b in set(list(itertools.combinations(mapping_list, 2)))] return OneToManyPerturbation.from_tuples(mapping_list, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: AssertionError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" assert prefix is not None or suffix is not None or replacement is not None, \\ 'At least one of `prefix`, `suffix` and `replacement` should be provided.' if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))]) class OneToManyPerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[Sequence[str], LT, Union[LT, Sequence[LT]]]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to) @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, n=n, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])]","title":"Module text_sensitivity.perturbation.base"},{"location":"reference/text_sensitivity/perturbation/base/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/perturbation/base/#as_list","text":"1 2 3 def as_list ( x ) View Source 1 2 3 def as_list(x): return [x] if not isinstance(x, Iterable) or isinstance(x, str) else x","title":"as_list"},{"location":"reference/text_sensitivity/perturbation/base/#format_identifier","text":"1 2 3 4 def format_identifier ( instance , key ) View Source 1 2 3 def format_identifier(instance, key): return f'{instance.identifier}|{key}'","title":"format_identifier"},{"location":"reference/text_sensitivity/perturbation/base/#one_to_many_dictionary_mapping","text":"1 2 3 4 5 6 7 8 9 def one_to_many_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int , tokenizer , detokenizer ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def one_to_many_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=n)) res = list(filter(None, res)) if len(res) == 0: return None return res","title":"one_to_many_dictionary_mapping"},{"location":"reference/text_sensitivity/perturbation/base/#one_to_one_dictionary_mapping","text":"1 2 3 4 5 6 7 8 def one_to_one_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , tokenizer , detokenizer ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def one_to_one_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, tokenizer, detokenizer): return list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=1))[0]","title":"one_to_one_dictionary_mapping"},{"location":"reference/text_sensitivity/perturbation/base/#oneway_dictionary_mapping","text":"1 2 3 4 5 6 7 8 9 def oneway_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int , tokenizer , detokenizer ) -> Optional [ Tuple [ str , ~ LT , ~ LT ]] View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def oneway_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer) -> Optional[Tuple[str, LT, LT]]: tokenized = tokenizer(instance.data) # Get all options options = {i: dictionary[a] for i, a in enumerate(tokenized) if a in dictionary.keys()} all_options = list(itertools.product(*options.values())) # Pick up to N random replacements and apply them for idx in set(np.random.randint(len(all_options), size=n)): current_option = all_options[idx] new_tokenized = copy.deepcopy(tokenized) for i, option in enumerate(current_option): new_tokenized[options.keys()[i]] = option if tokenized != new_tokenized: yield detokenizer(new_tokenized), label_from, label_to","title":"oneway_dictionary_mapping"},{"location":"reference/text_sensitivity/perturbation/base/#classes","text":"","title":"Classes"},{"location":"reference/text_sensitivity/perturbation/base/#onetomanyperturbation","text":"1 2 3 class OneToManyPerturbation ( perturbation_function : Callable [[ instancelib . instances . text . TextInstance ], Optional [ Tuple [ Sequence [ str ], ~ LT , Union [ ~ LT , Sequence [ ~ LT ]]]]] ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 class OneToManyPerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[Sequence[str], LT, Union[LT, Sequence[LT]]]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to) @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, n=n, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])]","title":"OneToManyPerturbation"},{"location":"reference/text_sensitivity/perturbation/base/#ancestors-in-mro","text":"text_sensitivity.perturbation.base.Perturbation text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/perturbation/base/#static-methods","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/perturbation/base/#from_dict","text":"1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs)","title":"from_dict"},{"location":"reference/text_sensitivity/perturbation/base/#from_dictionary","text":"1 2 3 4 5 6 7 8 def from_dictionary ( dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int = 10 , tokenizer : Callable = < function word_tokenizer at 0x16d0281f0 > , detokenizer : Callable = < function word_detokenizer at 0x16d028310 > ) Construct a OneToManyPerturbation from a dictionary. Parameters: Name Type Description Default dictionary Dict[str, List[str]] Lookup dictionary to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of dictionary). None label_to LT Attribute label of perturbed instance (right-hand side of dictionary). None n int Number of instances to generate. Defaults to 10. 10 tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function)","title":"from_dictionary"},{"location":"reference/text_sensitivity/perturbation/base/#from_function","text":"1 2 3 4 5 6 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , n : int = 10 ) Construct a OneToManyPerturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' n int Number of instances to generate. Defaults to 10. 10 View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to)","title":"from_function"},{"location":"reference/text_sensitivity/perturbation/base/#from_nlpaug","text":"1 2 3 4 5 6 7 def from_nlpaug ( augmenter : nlpaug . base_augmenter . Augmenter , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , n : int = 10 , ** augment_kwargs ) Construct a OneToManyPerturbation from a nlpaug _ Augmenter. Parameters: Name Type Description Default augmenter Augmenter Class with .augment() function applying a perturbation to a string. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' n int Number of instances to generate. Defaults to 10. 10 **augment_kwargs None Optional arguments passed to .augment() function. .. _nlpaug: None https None //github.com/makcedward/nlpaug None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, n=n, label_from=label_from, label_to=label_to)","title":"from_nlpaug"},{"location":"reference/text_sensitivity/perturbation/base/#from_str","text":"1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs)","title":"from_str"},{"location":"reference/text_sensitivity/perturbation/base/#from_string","text":"1 2 3 4 def from_string ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.')","title":"from_string"},{"location":"reference/text_sensitivity/perturbation/base/#methods","text":"","title":"Methods"},{"location":"reference/text_sensitivity/perturbation/base/#perturb","text":"1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) -> Optional [ Sequence [ Tuple [ instancelib . instances . text . TextInstance , Sequence [ Tuple [ ~ KT , ~ LT ]]]]] Apply a perturbation function to a single TextInstance , getting a multiple results per instance. Parameters: Name Type Description Default perturbation_function Callable Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. None Returns: Type Description Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]] None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])]","title":"perturb"},{"location":"reference/text_sensitivity/perturbation/base/#onetooneperturbation","text":"1 2 3 class OneToOnePerturbation ( perturbation_function : Callable [[ instancelib . instances . text . TextInstance ], Optional [ Tuple [ str , ~ LT , ~ LT ]]] ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 class OneToOnePerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[str, LT, LT]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.', '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" mapping_list = [(a, b) for a, b in set(list(itertools.combinations(mapping_list, 2)))] return OneToManyPerturbation.from_tuples(mapping_list, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: AssertionError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" assert prefix is not None or suffix is not None or replacement is not None, \\ 'At least one of `prefix`, `suffix` and `replacement` should be provided.' if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))])","title":"OneToOnePerturbation"},{"location":"reference/text_sensitivity/perturbation/base/#ancestors-in-mro_1","text":"text_sensitivity.perturbation.base.Perturbation text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/perturbation/base/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/perturbation/base/#from_dict_1","text":"1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs)","title":"from_dict"},{"location":"reference/text_sensitivity/perturbation/base/#from_dictionary_1","text":"1 2 3 4 5 6 7 def from_dictionary ( dictionary : Dict [ str , str ], label_from : ~ LT , label_to : ~ LT , tokenizer : Callable = < function word_tokenizer at 0x16d0281f0 > , detokenizer : Callable = < function word_detokenizer at 0x16d028310 > ) Construct a OneToOnePerturbation from a dictionary. Parameters: Name Type Description Default dictionary Dict[str, str] Lookup dictionary to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of dictionary). None label_to LT Attribute label of perturbed instance (right-hand side of dictionary). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.', '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function)","title":"from_dictionary"},{"location":"reference/text_sensitivity/perturbation/base/#from_function_1","text":"1 2 3 4 5 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' ) Construct a Perturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function)","title":"from_function"},{"location":"reference/text_sensitivity/perturbation/base/#from_list","text":"1 2 3 4 5 6 7 def from_list ( mapping_list : List [ str ], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , tokenizer : Callable = < function word_tokenizer at 0x16d0281f0 > , detokenizer : Callable = < function word_detokenizer at 0x16d028310 > ) Construct a OneToOnePerturbation from a list. A function is constructed that aims to map any value in the list to any other value in the list. Parameters: Name Type Description Default mapping_list List[str] Lookup list of tokens (e.g. words, characters). None label_from LT Attribute label of original instance (non-replaced). None label_to LT Attribute label of perturbed instance (replaced). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" mapping_list = [(a, b) for a, b in set(list(itertools.combinations(mapping_list, 2)))] return OneToManyPerturbation.from_tuples(mapping_list, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer)","title":"from_list"},{"location":"reference/text_sensitivity/perturbation/base/#from_nlpaug_1","text":"1 2 3 4 5 6 def from_nlpaug ( augmenter : nlpaug . base_augmenter . Augmenter , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , ** augment_kwargs ) Construct a OneToOnePerturbation from a nlpaug _ Augmenter. Parameters: Name Type Description Default augmenter Augmenter Class with .augment() function applying a perturbation to a string. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' **augment_kwargs None Optional arguments passed to .augment() function. .. _nlpaug: None https None //github.com/makcedward/nlpaug None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to)","title":"from_nlpaug"},{"location":"reference/text_sensitivity/perturbation/base/#from_str_1","text":"1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs)","title":"from_str"},{"location":"reference/text_sensitivity/perturbation/base/#from_string_1","text":"1 2 3 4 5 6 7 8 9 10 def from_string ( prefix : Optional [ str ] = None , suffix : Optional [ str ] = None , replacement : Optional [ str ] = None , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , connector : str = ' ' , connector_before : Optional [ str ] = None , connector_after : Optional [ str ] = None ) Construct a OneToOnePerturbation from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of prefix , suffix or replacement should be a string to apply the replacement. 1 2 3 4 5 6 7 8 9 10 11 Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after=' ', >>> label_to='more_negative') 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: AssertionError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: AssertionError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" assert prefix is not None or suffix is not None or replacement is not None, \\ 'At least one of `prefix`, `suffix` and `replacement` should be provided.' if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function)","title":"from_string"},{"location":"reference/text_sensitivity/perturbation/base/#from_tuples","text":"1 2 3 4 5 6 7 def from_tuples ( tuples : List [ Tuple [ str , str ]], label_from : ~ LT , label_to : ~ LT , tokenizer : Callable = < function word_tokenizer at 0x16d0281f0 > , detokenizer : Callable = < function word_detokenizer at 0x16d028310 > ) Construct a OneToOnePerturbation from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Parameters: Name Type Description Default tuples List[Tuple[str, str]] Lookup tuples to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of tuples). None label_to LT Attribute label of perturbed instance (right-hand side of tuples). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function)","title":"from_tuples"},{"location":"reference/text_sensitivity/perturbation/base/#methods_1","text":"","title":"Methods"},{"location":"reference/text_sensitivity/perturbation/base/#perturb_1","text":"1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) -> Optional [ Sequence [ Tuple [ instancelib . instances . text . TextInstance , Sequence [ Tuple [ ~ KT , ~ LT ]]]]] Apply a perturbation function to a single TextInstance , getting a single result per instance. Parameters: Name Type Description Default perturbation_function Callable Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. None Returns: Type Description Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]] None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None: return perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))])","title":"perturb"},{"location":"reference/text_sensitivity/perturbation/base/#perturbation","text":"1 2 3 class Perturbation ( perturbation_function : Callable ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class Perturbation(Readable): def __init__(self, perturbation_function: Callable): \"\"\"Apply a perturbation function to a single `TextInstance`. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and resulting instance(s). Should return None if no perturbation has been applied. \"\"\" self.perturbation_function = perturbation_function @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.') @text_instance def __call__(self, instance: TextInstance): return self.perturb(instance)","title":"Perturbation"},{"location":"reference/text_sensitivity/perturbation/base/#ancestors-in-mro_2","text":"text_explainability.default.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/perturbation/base/#descendants","text":"text_sensitivity.perturbation.base.OneToOnePerturbation text_sensitivity.perturbation.base.OneToManyPerturbation","title":"Descendants"},{"location":"reference/text_sensitivity/perturbation/base/#static-methods_2","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/perturbation/base/#from_dict_2","text":"1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs)","title":"from_dict"},{"location":"reference/text_sensitivity/perturbation/base/#from_dictionary_2","text":"1 2 3 4 def from_dictionary ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.')","title":"from_dictionary"},{"location":"reference/text_sensitivity/perturbation/base/#from_function_2","text":"1 2 3 4 5 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' ) Construct a Perturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function)","title":"from_function"},{"location":"reference/text_sensitivity/perturbation/base/#from_str_2","text":"1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs)","title":"from_str"},{"location":"reference/text_sensitivity/perturbation/base/#from_string_2","text":"1 2 3 4 def from_string ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.')","title":"from_string"},{"location":"reference/text_sensitivity/perturbation/base/#methods_2","text":"","title":"Methods"},{"location":"reference/text_sensitivity/perturbation/base/#perturb_2","text":"1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) View Source 1 2 3 4 5 @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.')","title":"perturb"},{"location":"reference/text_sensitivity/perturbation/characters/","text":"Module text_sensitivity.perturbation.characters None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 # perturbations/characters.py import numpy as np from typing import Callable import nlpaug.augmenter.word as naw import nlpaug.augmenter.char as nac from text_sensitivity.perturbation.base import Perturbation, OneToOnePerturbation, OneToManyPerturbation def __construct(cls_or_fn, constructor_one, constructor_many, **kwargs): \"\"\"Generic constructor, returning `constructor_many` if n > 1 else `constructor_one`.\"\"\" label_from = kwargs.pop('label_from') if 'label_from' in kwargs else 'original' label_to = kwargs.pop('label_to') if 'label_to' in kwargs else 'perturbed' if 'n' in kwargs and isinstance(kwargs['n'], int) and kwargs['n'] > 1: n = kwargs.pop('n') if not isinstance(cls_or_fn, (str, dict, Callable)) or isinstance(cls_or_fn, type): cls_or_fn = cls_or_fn(**kwargs) return constructor_many(cls_or_fn, n=n, label_from=label_from, label_to=label_to) if not isinstance(cls_or_fn, (str, dict, Callable)) or isinstance(cls_or_fn, type): cls_or_fn = cls_or_fn(**kwargs) return constructor_one(cls_or_fn, label_from=label_from, label_to=label_to) def _function(fn, **kwargs) -> Perturbation: \"\"\"Constructor for `Perturbation.from_function`.\"\"\" return __construct(fn, OneToOnePerturbation.from_function, OneToManyPerturbation.from_function, **kwargs) def _nlpaug(cls, **kwargs) -> Perturbation: \"\"\"Constructor for `Perturbation.from_nlpaug`.\"\"\" return __construct(cls, OneToOnePerturbation.from_nlpaug, OneToManyPerturbation.from_nlpaug, **kwargs) def __random_character_fn(string: str, function: Callable) -> str: \"\"\"Apply a function to random characters in a string.\"\"\" if len(string) == 0: return string random_indices = np.random.choice(range(len(string)), size=np.random.randint(1, len(string)), replace=False) for c in random_indices: string = string[:c] + function(string[c]) + string[c + 1:] return string def random_upper(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to uppercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.upper), label_to='random_upper', n=n) def random_lower(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to lowercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.lower), label_to='random_upper', n=n) def random_case_swap(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters case (lower to higher or vice versa). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.swapcase), label_to='random_upper', n=n) def random_spaces(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds random spaces within words (splits them up). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.SplitAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py \"\"\" return _nlpaug(naw.SplitAug, label_to='with_spaces', n=n, **kwargs) def add_typos(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds keyboard typos within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.KeyboardAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py \"\"\" return _nlpaug(nac.KeyboardAug, label_from='without_typos', label_to='with_typos', n=n, **kwargs) def swap_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='swap'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='swap', label_to='characters_swapped', n=n, **kwargs) def delete_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object with random character deletions in words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='delete'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='delete', label_to='characters_deleted', n=n, **kwargs) Functions add_typos 1 2 3 4 def add_typos ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that adds keyboard typos within words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See naw.KeyboardAug _ for optional constructor arguments. None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def add_typos(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds keyboard typos within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.KeyboardAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py \"\"\" return _nlpaug(nac.KeyboardAug, label_from='without_typos', label_to='with_typos', n=n, **kwargs) delete_random 1 2 3 4 def delete_random ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object with random character deletions in words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See nac.RandomCharAug _ for optional constructor arguments (uses action='delete' by default). None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def delete_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object with random character deletions in words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='delete'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='delete', label_to='characters_deleted', n=n, **kwargs) random_case_swap 1 2 3 def random_case_swap ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters case (lower to higher or vice versa). Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_case_swap(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters case (lower to higher or vice versa). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.swapcase), label_to='random_upper', n=n) random_lower 1 2 3 def random_lower ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters to lowercase. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_lower(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to lowercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.lower), label_to='random_upper', n=n) random_spaces 1 2 3 4 def random_spaces ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that adds random spaces within words (splits them up). Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See naw.SplitAug _ for optional constructor arguments. None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def random_spaces(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds random spaces within words (splits them up). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.SplitAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py \"\"\" return _nlpaug(naw.SplitAug, label_to='with_spaces', n=n, **kwargs) random_upper 1 2 3 def random_upper ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters to uppercase. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_upper(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to uppercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.upper), label_to='random_upper', n=n) swap_random 1 2 3 4 def swap_random ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters within words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See nac.RandomCharAug _ for optional constructor arguments (uses action='swap' by default). None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def swap_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='swap'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='swap', label_to='characters_swapped', n=n, **kwargs)","title":"Characters"},{"location":"reference/text_sensitivity/perturbation/characters/#module-text_sensitivityperturbationcharacters","text":"None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 # perturbations/characters.py import numpy as np from typing import Callable import nlpaug.augmenter.word as naw import nlpaug.augmenter.char as nac from text_sensitivity.perturbation.base import Perturbation, OneToOnePerturbation, OneToManyPerturbation def __construct(cls_or_fn, constructor_one, constructor_many, **kwargs): \"\"\"Generic constructor, returning `constructor_many` if n > 1 else `constructor_one`.\"\"\" label_from = kwargs.pop('label_from') if 'label_from' in kwargs else 'original' label_to = kwargs.pop('label_to') if 'label_to' in kwargs else 'perturbed' if 'n' in kwargs and isinstance(kwargs['n'], int) and kwargs['n'] > 1: n = kwargs.pop('n') if not isinstance(cls_or_fn, (str, dict, Callable)) or isinstance(cls_or_fn, type): cls_or_fn = cls_or_fn(**kwargs) return constructor_many(cls_or_fn, n=n, label_from=label_from, label_to=label_to) if not isinstance(cls_or_fn, (str, dict, Callable)) or isinstance(cls_or_fn, type): cls_or_fn = cls_or_fn(**kwargs) return constructor_one(cls_or_fn, label_from=label_from, label_to=label_to) def _function(fn, **kwargs) -> Perturbation: \"\"\"Constructor for `Perturbation.from_function`.\"\"\" return __construct(fn, OneToOnePerturbation.from_function, OneToManyPerturbation.from_function, **kwargs) def _nlpaug(cls, **kwargs) -> Perturbation: \"\"\"Constructor for `Perturbation.from_nlpaug`.\"\"\" return __construct(cls, OneToOnePerturbation.from_nlpaug, OneToManyPerturbation.from_nlpaug, **kwargs) def __random_character_fn(string: str, function: Callable) -> str: \"\"\"Apply a function to random characters in a string.\"\"\" if len(string) == 0: return string random_indices = np.random.choice(range(len(string)), size=np.random.randint(1, len(string)), replace=False) for c in random_indices: string = string[:c] + function(string[c]) + string[c + 1:] return string def random_upper(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to uppercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.upper), label_to='random_upper', n=n) def random_lower(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to lowercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.lower), label_to='random_upper', n=n) def random_case_swap(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters case (lower to higher or vice versa). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.swapcase), label_to='random_upper', n=n) def random_spaces(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds random spaces within words (splits them up). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.SplitAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py \"\"\" return _nlpaug(naw.SplitAug, label_to='with_spaces', n=n, **kwargs) def add_typos(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds keyboard typos within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.KeyboardAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py \"\"\" return _nlpaug(nac.KeyboardAug, label_from='without_typos', label_to='with_typos', n=n, **kwargs) def swap_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='swap'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='swap', label_to='characters_swapped', n=n, **kwargs) def delete_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object with random character deletions in words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='delete'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='delete', label_to='characters_deleted', n=n, **kwargs)","title":"Module text_sensitivity.perturbation.characters"},{"location":"reference/text_sensitivity/perturbation/characters/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/perturbation/characters/#add_typos","text":"1 2 3 4 def add_typos ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that adds keyboard typos within words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See naw.KeyboardAug _ for optional constructor arguments. None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def add_typos(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds keyboard typos within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.KeyboardAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py \"\"\" return _nlpaug(nac.KeyboardAug, label_from='without_typos', label_to='with_typos', n=n, **kwargs)","title":"add_typos"},{"location":"reference/text_sensitivity/perturbation/characters/#delete_random","text":"1 2 3 4 def delete_random ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object with random character deletions in words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See nac.RandomCharAug _ for optional constructor arguments (uses action='delete' by default). None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def delete_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object with random character deletions in words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='delete'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='delete', label_to='characters_deleted', n=n, **kwargs)","title":"delete_random"},{"location":"reference/text_sensitivity/perturbation/characters/#random_case_swap","text":"1 2 3 def random_case_swap ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters case (lower to higher or vice versa). Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_case_swap(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters case (lower to higher or vice versa). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.swapcase), label_to='random_upper', n=n)","title":"random_case_swap"},{"location":"reference/text_sensitivity/perturbation/characters/#random_lower","text":"1 2 3 def random_lower ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters to lowercase. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_lower(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to lowercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.lower), label_to='random_upper', n=n)","title":"random_lower"},{"location":"reference/text_sensitivity/perturbation/characters/#random_spaces","text":"1 2 3 4 def random_spaces ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that adds random spaces within words (splits them up). Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See naw.SplitAug _ for optional constructor arguments. None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def random_spaces(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds random spaces within words (splits them up). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.SplitAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py \"\"\" return _nlpaug(naw.SplitAug, label_to='with_spaces', n=n, **kwargs)","title":"random_spaces"},{"location":"reference/text_sensitivity/perturbation/characters/#random_upper","text":"1 2 3 def random_upper ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters to uppercase. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_upper(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to uppercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.upper), label_to='random_upper', n=n)","title":"random_upper"},{"location":"reference/text_sensitivity/perturbation/characters/#swap_random","text":"1 2 3 4 def swap_random ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters within words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See nac.RandomCharAug _ for optional constructor arguments (uses action='swap' by default). None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def swap_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='swap'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='swap', label_to='characters_swapped', n=n, **kwargs)","title":"swap_random"},{"location":"reference/text_sensitivity/perturbation/sentences/","text":"Module text_sensitivity.perturbation.sentences None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from typing import Optional from text_sensitivity.perturbation.base import OneToOnePerturbation def to_upper() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.upper, 'not_upper', 'upper') def to_lower() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.lower, 'not_lower', 'lower') def repeat_n_times(n: int = 10, connector: Optional[str] = ' '): \"\"\"Repeat a string n times.\"\"\" if connector is None: connector = '' def repeat_n(string: str) -> str: return connector.join([string] * n) return OneToOnePerturbation.from_function(repeat_n, label_to='repeated') Functions repeat_n_times 1 2 3 4 def repeat_n_times ( n : int = 10 , connector : Optional [ str ] = ' ' ) Repeat a string n times. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def repeat_n_times(n: int = 10, connector: Optional[str] = ' '): \"\"\"Repeat a string n times.\"\"\" if connector is None: connector = '' def repeat_n(string: str) -> str: return connector.join([string] * n) return OneToOnePerturbation.from_function(repeat_n, label_to='repeated') to_lower 1 2 3 def to_lower ( ) -> text_sensitivity . perturbation . base . OneToOnePerturbation View Source 1 2 3 def to_lower() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.lower, 'not_lower', 'lower') to_upper 1 2 3 def to_upper ( ) -> text_sensitivity . perturbation . base . OneToOnePerturbation View Source 1 2 3 def to_upper() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.upper, 'not_upper', 'upper')","title":"Sentences"},{"location":"reference/text_sensitivity/perturbation/sentences/#module-text_sensitivityperturbationsentences","text":"None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from typing import Optional from text_sensitivity.perturbation.base import OneToOnePerturbation def to_upper() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.upper, 'not_upper', 'upper') def to_lower() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.lower, 'not_lower', 'lower') def repeat_n_times(n: int = 10, connector: Optional[str] = ' '): \"\"\"Repeat a string n times.\"\"\" if connector is None: connector = '' def repeat_n(string: str) -> str: return connector.join([string] * n) return OneToOnePerturbation.from_function(repeat_n, label_to='repeated')","title":"Module text_sensitivity.perturbation.sentences"},{"location":"reference/text_sensitivity/perturbation/sentences/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/perturbation/sentences/#repeat_n_times","text":"1 2 3 4 def repeat_n_times ( n : int = 10 , connector : Optional [ str ] = ' ' ) Repeat a string n times. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def repeat_n_times(n: int = 10, connector: Optional[str] = ' '): \"\"\"Repeat a string n times.\"\"\" if connector is None: connector = '' def repeat_n(string: str) -> str: return connector.join([string] * n) return OneToOnePerturbation.from_function(repeat_n, label_to='repeated')","title":"repeat_n_times"},{"location":"reference/text_sensitivity/perturbation/sentences/#to_lower","text":"1 2 3 def to_lower ( ) -> text_sensitivity . perturbation . base . OneToOnePerturbation View Source 1 2 3 def to_lower() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.lower, 'not_lower', 'lower')","title":"to_lower"},{"location":"reference/text_sensitivity/perturbation/sentences/#to_upper","text":"1 2 3 def to_upper ( ) -> text_sensitivity . perturbation . base . OneToOnePerturbation View Source 1 2 3 def to_upper() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.upper, 'not_upper', 'upper')","title":"to_upper"},{"location":"reference/text_sensitivity/perturbation/words/","text":"Module text_sensitivity.perturbation.words None None","title":"Words"},{"location":"reference/text_sensitivity/perturbation/words/#module-text_sensitivityperturbationwords","text":"None None","title":"Module text_sensitivity.perturbation.words"}]}