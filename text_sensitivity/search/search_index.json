{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Sensitivity testing (fairness & robustness) for text machine learning models Extension of text_explainability Uses the generic architecture of text_explainability to also include tests of robustness ( how generalizable the model is in production , e.g. ability to handle input characters, stability when adding typos, or the effect of adding random unrelated data) and fairness ( if equal individuals are treated equally by the model , e.g. subgroup fairness on sex and nationality). \u00a9 Marcel Robeer, 2021 Quick tour Robustness : test whether your model is able to handle different data types... 1 2 3 4 5 6 7 from text_sensitivity import RandomAscii , RandomEmojis , combine_generators # Generate 10 strings with random ASCII characters RandomAscii () . generate_list ( n = 10 ) # Generate 5 strings with random ASCII characters and emojis combine_generators ( RandomAscii (), RandomEmojis ()) . generate_list ( n = 5 ) ... whether your model performs equally for different entities ... 1 2 3 4 5 6 7 from text_sensitivity import RandomAddress , RandomEmail # Random address of your current locale (default = 'nl') RandomAddress ( sep = ', ' ) . generate_list ( n = 5 ) # Random e-mail addresses in Spanish ('es') and Portuguese ('pt'), and include from which country the e-mail is RandomEmail ( languages = [ 'es' , 'pt' ]) . generate_list ( n = 10 , attributes = True ) ... and if it is robust under simple perturbations. 1 2 3 4 5 6 7 8 from text_sensitivity import compare_accuracy from text_sensitivity.perturbation import to_upper , add_typos # Is model accuracy equal when we change all sentences to uppercase? compare_accuracy ( env , model , to_upper ) # Is model accuracy equal when we add typos in words? compare_accuracy ( env , model , add_typos ) Fairness : see if performance is equal among subgroups. 1 2 3 4 from text_sensitivity import RandomName # Generate random Dutch ('nl') and Russian ('ru') names, both 'male' and 'female' (+ return attributes) RandomName ( languages = [ 'nl' , 'ru' ], sex = [ 'male' , 'female' ]) . generate_list ( n = 10 , attributes = True ) Installation Method Instructions pip Install from PyPI via pip3 install text_sensitivity . Local Clone this repository and install via pip3 install -e . or locally run python3 setup.py install . Documentation Full documentation of the latest version is provided at https://marcelrobeer.github.io/text_sensitivity/ . Example usage See example_usage.md to see an example of how the package can be used, or run the lines in example_usage.py to do explore it interactively. Releases text_explainability is officially released through PyPI . See CHANGELOG.md for a full overview of the changes for each version. Citation 1 2 3 4 5 6 @misc { text_sensitivity , title = {Python package text\\_sensitivity} , author = {Marcel Robeer} , howpublished = {\\url{https://git.science.uu.nl/m.j.robeer/text_sensitivity}} , year = {2021} } Maintenance Contributors Marcel Robeer ( @m.j.robeer ) Elize Herrewijnen ( @e.herrewijnen ) Todo Tasks yet to be done: Word-level perturbations Add fairness-specific metrics: Subgroup fairness Counterfactual fairness Add expected behavior Robustness: equal to prior prediction, or in some cases might expect that it deviates Fairness: may deviate from original prediction Tests Add tests for perturbations Add tests for sensitivity testing schemes Add visualization ability Credits Edward Ma. NLP Augmentation . 2019. Daniele Faraglia and other contributors. Faker . 2012. Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin and Sameer Singh. Beyond Accuracy: Behavioral Testing of NLP models with CheckList . Association for Computational Linguistics ( ACL ). 2020.","title":"Home"},{"location":"#quick-tour","text":"Robustness : test whether your model is able to handle different data types... 1 2 3 4 5 6 7 from text_sensitivity import RandomAscii , RandomEmojis , combine_generators # Generate 10 strings with random ASCII characters RandomAscii () . generate_list ( n = 10 ) # Generate 5 strings with random ASCII characters and emojis combine_generators ( RandomAscii (), RandomEmojis ()) . generate_list ( n = 5 ) ... whether your model performs equally for different entities ... 1 2 3 4 5 6 7 from text_sensitivity import RandomAddress , RandomEmail # Random address of your current locale (default = 'nl') RandomAddress ( sep = ', ' ) . generate_list ( n = 5 ) # Random e-mail addresses in Spanish ('es') and Portuguese ('pt'), and include from which country the e-mail is RandomEmail ( languages = [ 'es' , 'pt' ]) . generate_list ( n = 10 , attributes = True ) ... and if it is robust under simple perturbations. 1 2 3 4 5 6 7 8 from text_sensitivity import compare_accuracy from text_sensitivity.perturbation import to_upper , add_typos # Is model accuracy equal when we change all sentences to uppercase? compare_accuracy ( env , model , to_upper ) # Is model accuracy equal when we add typos in words? compare_accuracy ( env , model , add_typos ) Fairness : see if performance is equal among subgroups. 1 2 3 4 from text_sensitivity import RandomName # Generate random Dutch ('nl') and Russian ('ru') names, both 'male' and 'female' (+ return attributes) RandomName ( languages = [ 'nl' , 'ru' ], sex = [ 'male' , 'female' ]) . generate_list ( n = 10 , attributes = True )","title":"Quick tour"},{"location":"#installation","text":"Method Instructions pip Install from PyPI via pip3 install text_sensitivity . Local Clone this repository and install via pip3 install -e . or locally run python3 setup.py install .","title":"Installation"},{"location":"#documentation","text":"Full documentation of the latest version is provided at https://marcelrobeer.github.io/text_sensitivity/ .","title":"Documentation"},{"location":"#example-usage","text":"See example_usage.md to see an example of how the package can be used, or run the lines in example_usage.py to do explore it interactively.","title":"Example usage"},{"location":"#releases","text":"text_explainability is officially released through PyPI . See CHANGELOG.md for a full overview of the changes for each version.","title":"Releases"},{"location":"#citation","text":"1 2 3 4 5 6 @misc { text_sensitivity , title = {Python package text\\_sensitivity} , author = {Marcel Robeer} , howpublished = {\\url{https://git.science.uu.nl/m.j.robeer/text_sensitivity}} , year = {2021} }","title":"Citation"},{"location":"#maintenance","text":"","title":"Maintenance"},{"location":"#contributors","text":"Marcel Robeer ( @m.j.robeer ) Elize Herrewijnen ( @e.herrewijnen )","title":"Contributors"},{"location":"#todo","text":"Tasks yet to be done: Word-level perturbations Add fairness-specific metrics: Subgroup fairness Counterfactual fairness Add expected behavior Robustness: equal to prior prediction, or in some cases might expect that it deviates Fairness: may deviate from original prediction Tests Add tests for perturbations Add tests for sensitivity testing schemes Add visualization ability","title":"Todo"},{"location":"#credits","text":"Edward Ma. NLP Augmentation . 2019. Daniele Faraglia and other contributors. Faker . 2012. Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin and Sameer Singh. Beyond Accuracy: Behavioral Testing of NLP models with CheckList . Association for Computational Linguistics ( ACL ). 2020.","title":"Credits"},{"location":"CHANGELOG/","text":"Changelog All notable changes to text_sensitivity will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . Unreleased 0.2.5 - 2021-12-02 Added Return types for sensitivity tests Rendering of sensitivity tests using genbase.ui Changed Moved SeedMixin and CaseMixin to genbase Use genbase.internationalization Requires genbase>=0.1.13 0.2.4 - 2021-11-16 Fixed Bugfix in OneToOnePerturbation.from_dictionary Bugfix in compare_metric Bugfix in one_to_one_dictionary_mapping 0.2.3 - 2021-11-16 Fixed Bugfix in oneway_dictionary_mapping 0.2.2 - 2021-11-15 Fixed Bugfix in one_to_one_dictionary_mapping 0.2.1 - 2021-11-03 Added Invariance testing Comparison of mean scores (labelwise) 0.2.0 - 2021-10-08 Added Random license plate generation Added SeedMixin to WordList Added CaseMixin to WordList Robustness testing for random inputs Generate data from patterns Example usage for robustness testing and data generation Changed Ability to generate items from WordList 0.1.10 - 2021-10-07 Added Perturbation imports (character, word, sentence) to text_sensitivity.perturbation Examples in README.md Attribute renaming in text_sensitivity.data.random.entity Changed Updated usage with text_explainability==0.5.0 Updated usage with faker==8.16.0 0.1.9 - 2021-10-02 Fixed Bugfix in reading .csv files 0.1.8 - 2021-10-02 Removed Removed cities from wordlists 0.1.7 - 2021-10-02 Added MANIFEST.in Security tests with bandit Ability to make random entities lowercase, uppercase or sentencecase Tests for text_sensitivity.data.random.string Tests for text_sensitivity.data.random.entity Additional documentation Ability to generate addresses/cities in a country with a likelihood based on their population Removed Removed countries from wordlists Fixed Bugfixes in OneToOnePerturbation and OneToManyPerturbation 0.1.6 - 2021-10-02 Changed Moved random string data generation from text_sensitivity.data.random to text_sensitivity.data.random.string Renamed RandomData to RandomString Seed behavior generalized in SeedMixin , only requiring a self._seed and self._original_seed to work with a class Added Random multilingual entity generation with Python package faker Documentation and example usages for random entity generation 0.1.5 - 2021-10-01 Added Internationalization support Name of countries by language word list Top 100 most populous cities by country word list 0.1.4 - 2021-09-30 Added Citation information Documentation styling Generation of random Cyrillic text 0.1.3 - 2021-09-27 Added Documentation Ability to make OneToOnePerturbation from unordered list Extended one-to-one and one-to-many dictionary mappings 0.1.2 - 2021-09-24 Changed Proper n -times application of function with OneToManyPerturbation Fixed Bugfix in character generation 0.1.1 - 2021-09-24 Added Example usage Sensitivity testing wrapper functions (compare accuracy, precision, recall) 0.1.0 - 2021-09-24 Added Random data generation One to one perturbation One to many perturbation Example perturbation functions README.md LICENSE CI/CD pipeline for flake8 testing setup.py","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"All notable changes to text_sensitivity will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"CHANGELOG/#025-2021-12-02","text":"","title":"0.2.5 - 2021-12-02"},{"location":"CHANGELOG/#added","text":"Return types for sensitivity tests Rendering of sensitivity tests using genbase.ui","title":"Added"},{"location":"CHANGELOG/#changed","text":"Moved SeedMixin and CaseMixin to genbase Use genbase.internationalization Requires genbase>=0.1.13","title":"Changed"},{"location":"CHANGELOG/#024-2021-11-16","text":"","title":"0.2.4 - 2021-11-16"},{"location":"CHANGELOG/#fixed","text":"Bugfix in OneToOnePerturbation.from_dictionary Bugfix in compare_metric Bugfix in one_to_one_dictionary_mapping","title":"Fixed"},{"location":"CHANGELOG/#023-2021-11-16","text":"","title":"0.2.3 - 2021-11-16"},{"location":"CHANGELOG/#fixed_1","text":"Bugfix in oneway_dictionary_mapping","title":"Fixed"},{"location":"CHANGELOG/#022-2021-11-15","text":"","title":"0.2.2 - 2021-11-15"},{"location":"CHANGELOG/#fixed_2","text":"Bugfix in one_to_one_dictionary_mapping","title":"Fixed"},{"location":"CHANGELOG/#021-2021-11-03","text":"","title":"0.2.1 - 2021-11-03"},{"location":"CHANGELOG/#added_1","text":"Invariance testing Comparison of mean scores (labelwise)","title":"Added"},{"location":"CHANGELOG/#020-2021-10-08","text":"","title":"0.2.0 - 2021-10-08"},{"location":"CHANGELOG/#added_2","text":"Random license plate generation Added SeedMixin to WordList Added CaseMixin to WordList Robustness testing for random inputs Generate data from patterns Example usage for robustness testing and data generation","title":"Added"},{"location":"CHANGELOG/#changed_1","text":"Ability to generate items from WordList","title":"Changed"},{"location":"CHANGELOG/#0110-2021-10-07","text":"","title":"0.1.10 - 2021-10-07"},{"location":"CHANGELOG/#added_3","text":"Perturbation imports (character, word, sentence) to text_sensitivity.perturbation Examples in README.md Attribute renaming in text_sensitivity.data.random.entity","title":"Added"},{"location":"CHANGELOG/#changed_2","text":"Updated usage with text_explainability==0.5.0 Updated usage with faker==8.16.0","title":"Changed"},{"location":"CHANGELOG/#019-2021-10-02","text":"","title":"0.1.9 - 2021-10-02"},{"location":"CHANGELOG/#fixed_3","text":"Bugfix in reading .csv files","title":"Fixed"},{"location":"CHANGELOG/#018-2021-10-02","text":"","title":"0.1.8 - 2021-10-02"},{"location":"CHANGELOG/#removed","text":"Removed cities from wordlists","title":"Removed"},{"location":"CHANGELOG/#017-2021-10-02","text":"","title":"0.1.7 - 2021-10-02"},{"location":"CHANGELOG/#added_4","text":"MANIFEST.in Security tests with bandit Ability to make random entities lowercase, uppercase or sentencecase Tests for text_sensitivity.data.random.string Tests for text_sensitivity.data.random.entity Additional documentation Ability to generate addresses/cities in a country with a likelihood based on their population","title":"Added"},{"location":"CHANGELOG/#removed_1","text":"Removed countries from wordlists","title":"Removed"},{"location":"CHANGELOG/#fixed_4","text":"Bugfixes in OneToOnePerturbation and OneToManyPerturbation","title":"Fixed"},{"location":"CHANGELOG/#016-2021-10-02","text":"","title":"0.1.6 - 2021-10-02"},{"location":"CHANGELOG/#changed_3","text":"Moved random string data generation from text_sensitivity.data.random to text_sensitivity.data.random.string Renamed RandomData to RandomString Seed behavior generalized in SeedMixin , only requiring a self._seed and self._original_seed to work with a class","title":"Changed"},{"location":"CHANGELOG/#added_5","text":"Random multilingual entity generation with Python package faker Documentation and example usages for random entity generation","title":"Added"},{"location":"CHANGELOG/#015-2021-10-01","text":"","title":"0.1.5 - 2021-10-01"},{"location":"CHANGELOG/#added_6","text":"Internationalization support Name of countries by language word list Top 100 most populous cities by country word list","title":"Added"},{"location":"CHANGELOG/#014-2021-09-30","text":"","title":"0.1.4 - 2021-09-30"},{"location":"CHANGELOG/#added_7","text":"Citation information Documentation styling Generation of random Cyrillic text","title":"Added"},{"location":"CHANGELOG/#013-2021-09-27","text":"","title":"0.1.3 - 2021-09-27"},{"location":"CHANGELOG/#added_8","text":"Documentation Ability to make OneToOnePerturbation from unordered list Extended one-to-one and one-to-many dictionary mappings","title":"Added"},{"location":"CHANGELOG/#012-2021-09-24","text":"","title":"0.1.2 - 2021-09-24"},{"location":"CHANGELOG/#changed_4","text":"Proper n -times application of function with OneToManyPerturbation","title":"Changed"},{"location":"CHANGELOG/#fixed_5","text":"Bugfix in character generation","title":"Fixed"},{"location":"CHANGELOG/#011-2021-09-24","text":"","title":"0.1.1 - 2021-09-24"},{"location":"CHANGELOG/#added_9","text":"Example usage Sensitivity testing wrapper functions (compare accuracy, precision, recall)","title":"Added"},{"location":"CHANGELOG/#010-2021-09-24","text":"","title":"0.1.0 - 2021-09-24"},{"location":"CHANGELOG/#added_10","text":"Random data generation One to one perturbation One to many perturbation Example perturbation functions README.md LICENSE CI/CD pipeline for flake8 testing setup.py","title":"Added"},{"location":"example_usage/","text":"Example Usage Dependencies Like text_explainability , text_sensitivity uses instances and machine learning models wrapped with the InstanceLib library. Dataset and model We manually create a TextEnvironment , that holds both our ground-truth labels ( .labels ) and our instances ( .dataset ). Next, we fit a simple sklearn model that predicts whether the instances (sentence-length strings) contain punctuation or not. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Create a simple dataset (classify whether strings contain punctuation or not) from instancelib.environment.text import TextEnvironment instances = [ 'This is his example instance, not HERS!' , 'An example sentence for you?!' , 'She has her own sentence.' , 'Provide him with something without any punctuation' , 'RANDOM UPPERCASESTRING3' ] labels = [ 'punctuation' , 'punctuation' , 'punctuation' , 'no_punctuation' , 'no_punctuation' ] env = TextEnvironment . from_data ( indices = list ( range ( len ( instances ))), data = instances , target_labels = list ( set ( labels )), ground_truth = [[ label ] for label in labels ], vectors = []) # Create sklearn model with pipeline from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import CountVectorizer from sklearn.naive_bayes import MultinomialNB p = Pipeline ([( 'vect' , CountVectorizer ()), ( 'rf' , MultinomialNB ())]) # Wrap sklearn model from instancelib.machinelearning import SkLearnDataClassifier model = SkLearnDataClassifier . build ( p , env ) model . fit_provider ( env . dataset , env . labels ) Using Text Sensitivity Text Sensitivity is used for robustness testing (verifying if a model can handle all types of string data and whether its predictions are invariant to minor changes) and fairness testing (comparing model performance on subgroups). Robustness A robust text model should be able to handle different types of input strings (e.g. ASCII, emojis) and be invariant to minor changes in inputs (e.g. converting a string to uppercase, adding an unrelated string or users making typos). Generating random data Random strings can be used for testing if a model is able to handle ass sorts of inputs: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from text_sensitivity import ( RandomData , RandomDigits , RandomAscii , RandomEmojis , RandomWhitespace , RandomCyrillic , combine_generators ) # Generate 10 instances with all printable characters RandomData () . generate_list ( n = 10 , min_length = 5 , max_length = 50 ) # Generate 5 instances containing only digits RandomDigits ( seed = 1 ) . generate_list ( n = 5 ) # Generate 15 instances, combining emojis, whitespace characters and ASCII characters random_generator = combine_generators ( RandomAscii (), RandomEmojis (), RandomWhitespace ()) random_generator . generate_list ( n = 15 ) # Generate 20 instances with random ASCII characters, whitespace and Russian (Cyrillic) characters ascii_cyrillic_generator = combine_generators ( RandomAscii (), RandomWhitespace (), RandomCyrillic ( languages = 'ru' )) ascii_cyrillic_generator . generate_list ( n = 20 ) Invariance testing A very simple method for invariance testing, is assessing whether the model performs the same on a metric (e.g. accuracy, precision or recall) before and after applying a perturbation. For example, let us compare whether the model retains the same performance when converting all instances to lowercase: 1 2 3 4 from text_sensitivity.test import compare_accuracy from text_sensitivity.perturbation.sentences import to_lower compare_accuracy ( env , model , to_lower ) Similarly, we can check whether precision scores are the same if we add an unrelated string after each sentence: 1 2 3 4 5 from text_sensitivity.test import compare_precision from text_sensitivity.perturbation.base import OneToOnePerturbation perturbation_fn = OneToOnePerturbation . from_string ( suffix = 'This should not affect scores' ) compare_precision ( env , model , perturbation_fn ) Under the hood, text_sensitivity.test uses text_sensitivity.perturbation to perturb instances ( instancelib.instances.text.TextInstance or str ), and generates the new instances and labels for the original instance (e.g. 'not_upper') and the new instance(s) (e.g. 'upper'). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from text_sensitivity.perturbation.sentences import to_upper , repeat_k_times from text_sensitivity.perturbation.characters import random_case_swap , random_spaces , swap_random , add_typos sample = 'This is his example string, made especially for HER!' # Convert the sample string to all upper list ( to_upper ()( sample )) # Repeat the string 'test' n times list ( repeat_k_times ( n = 3 )( 'test' )) list ( repeat_k_times ( n = 7 , connector = ' \\n ' )( 'test' )) # Randomly swap the character case (lower to upper or vice versa) in sample list ( random_case_swap ()( sample )) # Add random spaces to words within a sentence, or swap characters randomly within a word (excluding stopwords and uppercase words) to sample list ( random_spaces ( n = 5 )( sample )) list ( swap_random ( n = 10 , stopwords = [ 'the' , 'is' , 'of' ], include_upper_case = False )( sample )) # Add typos (based on QWERTY keyboard) to sample list ( add_typos ( n = 10 , stopwords = [ 'the' , 'is' , 'of' ], include_numeric = False , include_special_char = False )( sample )) Fairness TODO : Write up fairness. Generating random data Data for entities can be generated in the same manner as random strings: 1 2 3 4 5 6 7 from text_sensitivity import ( RandomCity , RandomCountry , RandomName ) # Generates data for the current locale, e.g. if it is 'nl' it generates country names in Dutch and cities in the Netherlands RandomCity () . generate_list ( n = 10 ) # If you specify the locale, it can generate the entity (e.g. country) for multiple languages RandomCountry ( languages = [ 'nl' , 'de' , 'fr' , 'jp' ]) . generate_list ( n = 15 ) Unlike random strings, random entities can also output the corresponding attribute labels for the generated data 1 2 3 4 5 6 # For example, generated Dutch and Russian male and female names, and output which language and sex they are generator = RandomName ( languages = [ 'nl' , 'ru' ], sex = [ 'male' , 'female' ], seed = 5 ) generator . generate_list ( n = 10 , attributes = True ) # The same data can also be captured in an instancelib.InstanceProvider and instancelib.LabelProviders generator . generate ( n = 10 , attributes = True ) Other random entities that can be generated are dates, street addresses, emails, phone numbers, price tags and crypto names: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Dates from text_sensitivity import RandomYear , RandomMonth , RandomDay , RandomDayOfWeek print ( RandomYear () . generate_list ( n = 3 )) print ( RandomMonth ( languages = [ 'nl' , 'en' ]) . upper () . generate_list ( n = 6 )) # use .upper() to generate all uppercase or .lower() for all lower print ( RandomDay () . generate_list ( n = 3 )) print ( RandomDayOfWeek () . sentence () . generate_list ( n = 3 )) # use .sentence() for all sentencecase or .title() for titlecase # Street addresses, emails, phone numbers, price tags and crypto names from text_sensitivity import RandomAddress , RandomEmail , RandomPhoneNumber , RandomPriceTag , RandomCryptoCurrency print ( RandomAddress ( sep = ', ' ) . generate_list ( n = 5 )) print ( RandomEmail ( languages = [ 'es' , 'pt' ]) . generate_list ( n = 10 , attributes = True )) print ( RandomPhoneNumber () . generate_list ( n = 5 )) print ( RandomPriceTag ( languages = [ 'ru' , 'de' , 'it' , 'br' ]) . generate_list ( n = 10 )) print ( RandomCryptoCurrency () . generate_list ( n = 3 )) Generating data from patterns These entities, or your own lists, can be used to generate strings for locally testing model robustness/fairness. Text within curly braces ( {} ) is replaced, and attribute are added to each perturbed instance. The text outside of the curly braces remains the same. Examples of patterns that can be put between curly braces are: {a|b|c} generates a list with elements a , b and c . {city} uses RandomCity() (in current locale) to generate n random cities. For a full list of default patterns see from text_sensitivity import default_patterns; default_patterns() . {custom_entity_name} with keyword argument custom_entity_name=['this', 'is', 'cool] generates a list with elements this , is , cool . 1 2 3 4 5 6 7 8 9 10 from text_sensitivity import from_pattern # Generate a list ['This is his house', 'This was his house', 'This is his car', 'This was his car', ...]: from_pattern ( 'This {is|was} his {house|car|boat}' ) # Generate a list ['His home town is Eindhoven.', 'Her home town is Eindhoven.', 'His home town is Meerssen.', ...]. By default uses `RandomCity()` to generate the city name. from_pattern ( '{His|Her} home town is {city} .' ) # Override the 'city' default with your own list ['Amsterdam', 'Rotterdam', 'Utrecht']: from_pattern ( '{His|Her} home town is {city} .' , city = [ 'Amsterdam' , 'Rotterdam' , 'Utrecht' ]) In addition, modifiers can be added before a semicolon ( : ) within a curly brace to modify the generated data. Example modifiers are: {lower:address} generates addresses ( RandomAddress() for current locale) in all-lowercase {upper:name} generates full name ( RandomName() for current locale) in all-uppercase {sentence:day_of_week} generates day of week ( RandomDayOfWeek() for current locale) in sentencecase. {title:country} generates country names ( RandomCountry() in locale language) in titlecase. 1 2 # Apply lower case to the first argument and uppercase to the last, getting ['Vandaag, donderdag heeft Sanne COLIN gebeld op +31612351983!', ..., 'Vandaag, maandag heeft Nora SEPP gebeld op +31612351983!', ...] from_pattern ( 'Vandaag, {lower:day_of_week}, heeft {first_name} {upper:first_name} gebeld op {phone_number} !' , n = 5 )","title":"Example usage"},{"location":"example_usage/#example-usage","text":"","title":"Example Usage"},{"location":"example_usage/#dependencies","text":"Like text_explainability , text_sensitivity uses instances and machine learning models wrapped with the InstanceLib library.","title":"Dependencies"},{"location":"example_usage/#dataset-and-model","text":"We manually create a TextEnvironment , that holds both our ground-truth labels ( .labels ) and our instances ( .dataset ). Next, we fit a simple sklearn model that predicts whether the instances (sentence-length strings) contain punctuation or not. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Create a simple dataset (classify whether strings contain punctuation or not) from instancelib.environment.text import TextEnvironment instances = [ 'This is his example instance, not HERS!' , 'An example sentence for you?!' , 'She has her own sentence.' , 'Provide him with something without any punctuation' , 'RANDOM UPPERCASESTRING3' ] labels = [ 'punctuation' , 'punctuation' , 'punctuation' , 'no_punctuation' , 'no_punctuation' ] env = TextEnvironment . from_data ( indices = list ( range ( len ( instances ))), data = instances , target_labels = list ( set ( labels )), ground_truth = [[ label ] for label in labels ], vectors = []) # Create sklearn model with pipeline from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import CountVectorizer from sklearn.naive_bayes import MultinomialNB p = Pipeline ([( 'vect' , CountVectorizer ()), ( 'rf' , MultinomialNB ())]) # Wrap sklearn model from instancelib.machinelearning import SkLearnDataClassifier model = SkLearnDataClassifier . build ( p , env ) model . fit_provider ( env . dataset , env . labels )","title":"Dataset and model"},{"location":"example_usage/#using-text-sensitivity","text":"Text Sensitivity is used for robustness testing (verifying if a model can handle all types of string data and whether its predictions are invariant to minor changes) and fairness testing (comparing model performance on subgroups).","title":"Using Text Sensitivity"},{"location":"example_usage/#robustness","text":"A robust text model should be able to handle different types of input strings (e.g. ASCII, emojis) and be invariant to minor changes in inputs (e.g. converting a string to uppercase, adding an unrelated string or users making typos).","title":"Robustness"},{"location":"example_usage/#generating-random-data","text":"Random strings can be used for testing if a model is able to handle ass sorts of inputs: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from text_sensitivity import ( RandomData , RandomDigits , RandomAscii , RandomEmojis , RandomWhitespace , RandomCyrillic , combine_generators ) # Generate 10 instances with all printable characters RandomData () . generate_list ( n = 10 , min_length = 5 , max_length = 50 ) # Generate 5 instances containing only digits RandomDigits ( seed = 1 ) . generate_list ( n = 5 ) # Generate 15 instances, combining emojis, whitespace characters and ASCII characters random_generator = combine_generators ( RandomAscii (), RandomEmojis (), RandomWhitespace ()) random_generator . generate_list ( n = 15 ) # Generate 20 instances with random ASCII characters, whitespace and Russian (Cyrillic) characters ascii_cyrillic_generator = combine_generators ( RandomAscii (), RandomWhitespace (), RandomCyrillic ( languages = 'ru' )) ascii_cyrillic_generator . generate_list ( n = 20 )","title":"Generating random data"},{"location":"example_usage/#invariance-testing","text":"A very simple method for invariance testing, is assessing whether the model performs the same on a metric (e.g. accuracy, precision or recall) before and after applying a perturbation. For example, let us compare whether the model retains the same performance when converting all instances to lowercase: 1 2 3 4 from text_sensitivity.test import compare_accuracy from text_sensitivity.perturbation.sentences import to_lower compare_accuracy ( env , model , to_lower ) Similarly, we can check whether precision scores are the same if we add an unrelated string after each sentence: 1 2 3 4 5 from text_sensitivity.test import compare_precision from text_sensitivity.perturbation.base import OneToOnePerturbation perturbation_fn = OneToOnePerturbation . from_string ( suffix = 'This should not affect scores' ) compare_precision ( env , model , perturbation_fn ) Under the hood, text_sensitivity.test uses text_sensitivity.perturbation to perturb instances ( instancelib.instances.text.TextInstance or str ), and generates the new instances and labels for the original instance (e.g. 'not_upper') and the new instance(s) (e.g. 'upper'). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from text_sensitivity.perturbation.sentences import to_upper , repeat_k_times from text_sensitivity.perturbation.characters import random_case_swap , random_spaces , swap_random , add_typos sample = 'This is his example string, made especially for HER!' # Convert the sample string to all upper list ( to_upper ()( sample )) # Repeat the string 'test' n times list ( repeat_k_times ( n = 3 )( 'test' )) list ( repeat_k_times ( n = 7 , connector = ' \\n ' )( 'test' )) # Randomly swap the character case (lower to upper or vice versa) in sample list ( random_case_swap ()( sample )) # Add random spaces to words within a sentence, or swap characters randomly within a word (excluding stopwords and uppercase words) to sample list ( random_spaces ( n = 5 )( sample )) list ( swap_random ( n = 10 , stopwords = [ 'the' , 'is' , 'of' ], include_upper_case = False )( sample )) # Add typos (based on QWERTY keyboard) to sample list ( add_typos ( n = 10 , stopwords = [ 'the' , 'is' , 'of' ], include_numeric = False , include_special_char = False )( sample ))","title":"Invariance testing"},{"location":"example_usage/#fairness","text":"TODO : Write up fairness.","title":"Fairness"},{"location":"example_usage/#generating-random-data_1","text":"Data for entities can be generated in the same manner as random strings: 1 2 3 4 5 6 7 from text_sensitivity import ( RandomCity , RandomCountry , RandomName ) # Generates data for the current locale, e.g. if it is 'nl' it generates country names in Dutch and cities in the Netherlands RandomCity () . generate_list ( n = 10 ) # If you specify the locale, it can generate the entity (e.g. country) for multiple languages RandomCountry ( languages = [ 'nl' , 'de' , 'fr' , 'jp' ]) . generate_list ( n = 15 ) Unlike random strings, random entities can also output the corresponding attribute labels for the generated data 1 2 3 4 5 6 # For example, generated Dutch and Russian male and female names, and output which language and sex they are generator = RandomName ( languages = [ 'nl' , 'ru' ], sex = [ 'male' , 'female' ], seed = 5 ) generator . generate_list ( n = 10 , attributes = True ) # The same data can also be captured in an instancelib.InstanceProvider and instancelib.LabelProviders generator . generate ( n = 10 , attributes = True ) Other random entities that can be generated are dates, street addresses, emails, phone numbers, price tags and crypto names: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Dates from text_sensitivity import RandomYear , RandomMonth , RandomDay , RandomDayOfWeek print ( RandomYear () . generate_list ( n = 3 )) print ( RandomMonth ( languages = [ 'nl' , 'en' ]) . upper () . generate_list ( n = 6 )) # use .upper() to generate all uppercase or .lower() for all lower print ( RandomDay () . generate_list ( n = 3 )) print ( RandomDayOfWeek () . sentence () . generate_list ( n = 3 )) # use .sentence() for all sentencecase or .title() for titlecase # Street addresses, emails, phone numbers, price tags and crypto names from text_sensitivity import RandomAddress , RandomEmail , RandomPhoneNumber , RandomPriceTag , RandomCryptoCurrency print ( RandomAddress ( sep = ', ' ) . generate_list ( n = 5 )) print ( RandomEmail ( languages = [ 'es' , 'pt' ]) . generate_list ( n = 10 , attributes = True )) print ( RandomPhoneNumber () . generate_list ( n = 5 )) print ( RandomPriceTag ( languages = [ 'ru' , 'de' , 'it' , 'br' ]) . generate_list ( n = 10 )) print ( RandomCryptoCurrency () . generate_list ( n = 3 ))","title":"Generating random data"},{"location":"example_usage/#generating-data-from-patterns","text":"These entities, or your own lists, can be used to generate strings for locally testing model robustness/fairness. Text within curly braces ( {} ) is replaced, and attribute are added to each perturbed instance. The text outside of the curly braces remains the same. Examples of patterns that can be put between curly braces are: {a|b|c} generates a list with elements a , b and c . {city} uses RandomCity() (in current locale) to generate n random cities. For a full list of default patterns see from text_sensitivity import default_patterns; default_patterns() . {custom_entity_name} with keyword argument custom_entity_name=['this', 'is', 'cool] generates a list with elements this , is , cool . 1 2 3 4 5 6 7 8 9 10 from text_sensitivity import from_pattern # Generate a list ['This is his house', 'This was his house', 'This is his car', 'This was his car', ...]: from_pattern ( 'This {is|was} his {house|car|boat}' ) # Generate a list ['His home town is Eindhoven.', 'Her home town is Eindhoven.', 'His home town is Meerssen.', ...]. By default uses `RandomCity()` to generate the city name. from_pattern ( '{His|Her} home town is {city} .' ) # Override the 'city' default with your own list ['Amsterdam', 'Rotterdam', 'Utrecht']: from_pattern ( '{His|Her} home town is {city} .' , city = [ 'Amsterdam' , 'Rotterdam' , 'Utrecht' ]) In addition, modifiers can be added before a semicolon ( : ) within a curly brace to modify the generated data. Example modifiers are: {lower:address} generates addresses ( RandomAddress() for current locale) in all-lowercase {upper:name} generates full name ( RandomName() for current locale) in all-uppercase {sentence:day_of_week} generates day of week ( RandomDayOfWeek() for current locale) in sentencecase. {title:country} generates country names ( RandomCountry() in locale language) in titlecase. 1 2 # Apply lower case to the first argument and uppercase to the last, getting ['Vandaag, donderdag heeft Sanne COLIN gebeld op +31612351983!', ..., 'Vandaag, maandag heeft Nora SEPP gebeld op +31612351983!', ...] from_pattern ( 'Vandaag, {lower:day_of_week}, heeft {first_name} {upper:first_name} gebeld op {phone_number} !' , n = 5 )","title":"Generating data from patterns"},{"location":"docs/installation/","text":"Installation Installation of text_sensitivity requires Python 3.8 or higher. If not yet installed, installing text_sensitivity will also install its main dependency, text_explainability . 1. Python installation Install Python on your operating system using the Python Setup and Usage guide. 2. Installing text_sensitivity text_sensitivity can be installed: using pip : pip3 install (released on PyPI ) locally : cloning the repository and using python3 setup.py install Using pip Open up a terminal (Linux / macOS) or cmd.exe / powershell.exe (Windows) Run the command: pip3 install text_sensitivity , or pip install text_sensitivity . 1 2 3 4 5 user@terminal:~$ pip3 install text_sensitivity Collecting text_sensitivity ... Installing collected packages: text-sensitivity Successfully installed text-sensitivity Locally Download the folder from GitLab/GitHub : Clone this repository, or Download it as a .zip file and extract it. Open up a terminal (Linux / macOS) or cmd.exe / powershell.exe (Windows) and navigate to the folder you downloaded text_sensitivity in. In the main folder (containing the setup.py file) run: python3 setup.py install , or python setup.py install . 1 2 3 4 5 6 7 user@terminal:~$ cd ~/text_sensitivity user@terminal:~/text_explanability$ python3 setup.py install running install running bdist_egg running egg_info ... Finished processing dependencies for text-sensitivity","title":"Installation"},{"location":"docs/installation/#installation","text":"Installation of text_sensitivity requires Python 3.8 or higher. If not yet installed, installing text_sensitivity will also install its main dependency, text_explainability .","title":"Installation"},{"location":"docs/installation/#1-python-installation","text":"Install Python on your operating system using the Python Setup and Usage guide.","title":"1. Python installation"},{"location":"docs/installation/#2-installing-text_sensitivity","text":"text_sensitivity can be installed: using pip : pip3 install (released on PyPI ) locally : cloning the repository and using python3 setup.py install","title":"2. Installing text_sensitivity"},{"location":"docs/installation/#using-pip","text":"Open up a terminal (Linux / macOS) or cmd.exe / powershell.exe (Windows) Run the command: pip3 install text_sensitivity , or pip install text_sensitivity . 1 2 3 4 5 user@terminal:~$ pip3 install text_sensitivity Collecting text_sensitivity ... Installing collected packages: text-sensitivity Successfully installed text-sensitivity","title":"Using pip"},{"location":"docs/installation/#locally","text":"Download the folder from GitLab/GitHub : Clone this repository, or Download it as a .zip file and extract it. Open up a terminal (Linux / macOS) or cmd.exe / powershell.exe (Windows) and navigate to the folder you downloaded text_sensitivity in. In the main folder (containing the setup.py file) run: python3 setup.py install , or python setup.py install . 1 2 3 4 5 6 7 user@terminal:~$ cd ~/text_sensitivity user@terminal:~/text_explanability$ python3 setup.py install running install running bdist_egg running egg_info ... Finished processing dependencies for text-sensitivity","title":"Locally"},{"location":"reference/text_sensitivity/","text":"Module text_sensitivity None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 from text_sensitivity.data.generate import default_patterns, from_pattern from text_sensitivity.data.random.entity import (RandomAddress, RandomCity, RandomCountry, RandomCryptoCurrency, RandomCurrencySymbol, RandomDay, RandomDayOfWeek, RandomEmail, RandomFirstName, RandomLastName, RandomLicensePlate, RandomMonth, RandomName, RandomPhoneNumber, RandomPriceTag, RandomYear) from text_sensitivity.data.random.string import (RandomAscii, RandomCyrillic, RandomDigits, RandomEmojis, RandomLower, RandomPunctuation, RandomSpaces, RandomString, RandomUpper, RandomWhitespace, combine_generators) from text_sensitivity.perturbation import (OneToManyPerturbation, OneToOnePerturbation, Perturbation) from text_sensitivity.sensitivity import (compare_accuracy, compare_metric, compare_precision, compare_recall, input_space_robustness, invariance, mean_score) __version__ = '0.2.5' Sub-modules text_sensitivity.data text_sensitivity.perturbation text_sensitivity.return_types text_sensitivity.sensitivity text_sensitivity.ui","title":"Index"},{"location":"reference/text_sensitivity/#module-text_sensitivity","text":"None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 from text_sensitivity.data.generate import default_patterns, from_pattern from text_sensitivity.data.random.entity import (RandomAddress, RandomCity, RandomCountry, RandomCryptoCurrency, RandomCurrencySymbol, RandomDay, RandomDayOfWeek, RandomEmail, RandomFirstName, RandomLastName, RandomLicensePlate, RandomMonth, RandomName, RandomPhoneNumber, RandomPriceTag, RandomYear) from text_sensitivity.data.random.string import (RandomAscii, RandomCyrillic, RandomDigits, RandomEmojis, RandomLower, RandomPunctuation, RandomSpaces, RandomString, RandomUpper, RandomWhitespace, combine_generators) from text_sensitivity.perturbation import (OneToManyPerturbation, OneToOnePerturbation, Perturbation) from text_sensitivity.sensitivity import (compare_accuracy, compare_metric, compare_precision, compare_recall, input_space_robustness, invariance, mean_score) __version__ = '0.2.5'","title":"Module text_sensitivity"},{"location":"reference/text_sensitivity/#sub-modules","text":"text_sensitivity.data text_sensitivity.perturbation text_sensitivity.return_types text_sensitivity.sensitivity text_sensitivity.ui","title":"Sub-modules"},{"location":"reference/text_sensitivity/return_types/","text":"Module text_sensitivity.return_types Return types for sensitivity (tests). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 \"\"\"Return types for sensitivity (tests).\"\"\" from typing import Optional, Union from instancelib.labels import LabelProvider, MemoryLabelProvider from text_explainability.generation.return_types import Instances from text_sensitivity.ui.notebook import Render class SuccessTest(Instances): def __init__(self, success_percentage: float, successes, failures, predictions: Optional[Union[LabelProvider, list, dict]] = None, type: str = 'robustness', subtype: str = 'input_space', callargs: Optional[dict] = None, **kwargs): super().__init__(instances={'successes': successes, 'failures': failures}, type=type, subtype=subtype, callargs=callargs, renderer=Render, **kwargs) self.success_percentage = success_percentage self.predictions = self.__load_predictions(predictions) def __load_predictions(self, predictions): if predictions is None: return None if not isinstance(predictions, LabelProvider): return MemoryLabelProvider.from_tuples(predictions) return predictions @property def content(self): res = {'success_percentage': self.success_percentage, 'failure_percentage': 1.0 - self.success_percentage, 'successes': self.instances['successes'], 'failures': self.instances['failures']} if self.predictions is not None: res['predictions'] = self.predictions return res Classes SuccessTest 1 2 3 4 5 6 7 8 9 10 class SuccessTest ( success_percentage : float , successes , failures , predictions : Union [ instancelib . labels . base . LabelProvider , list , dict , NoneType ] = None , type : str = 'robustness' , subtype : str = 'input_space' , callargs : Optional [ dict ] = None , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class SuccessTest(Instances): def __init__(self, success_percentage: float, successes, failures, predictions: Optional[Union[LabelProvider, list, dict]] = None, type: str = 'robustness', subtype: str = 'input_space', callargs: Optional[dict] = None, **kwargs): super().__init__(instances={'successes': successes, 'failures': failures}, type=type, subtype=subtype, callargs=callargs, renderer=Render, **kwargs) self.success_percentage = success_percentage self.predictions = self.__load_predictions(predictions) def __load_predictions(self, predictions): if predictions is None: return None if not isinstance(predictions, LabelProvider): return MemoryLabelProvider.from_tuples(predictions) return predictions @property def content(self): res = {'success_percentage': self.success_percentage, 'failure_percentage': 1.0 - self.success_percentage, 'successes': self.instances['successes'], 'failures': self.instances['failures']} if self.predictions is not None: res['predictions'] = self.predictions return res Ancestors (in MRO) text_explainability.generation.return_types.Instances text_explainability.generation.return_types.BaseReturnType genbase.MetaInfo genbase.Configurable Static methods from_config 1 2 3 4 def from_config ( config : dict , ** kwargs ) -> 'Configurable' View Source 1 2 3 4 5 6 7 8 9 @classmethod def from_config(cls, config: dict, **kwargs) -> 'Configurable': config = {**config, **kwargs} _ = config.pop('__class__', None) return cls(**config) from_json 1 2 3 4 def from_json ( json_or_path : str , ** read_args ) -> 'Configurable' Get config from JSON string or filepath. Parameters: Name Type Description Default json_or_path str File path or JSON string. None **read_args None Optional arguments passed to srsly.read_json() / srsly.read_jsonl() / srsly.read_gzip_json . None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @classmethod def from_json(cls, json_or_path: str, **read_args) -> 'Configurable': \"\"\"Get config from JSON string or filepath. Args: json_or_path (str): File path or JSON string. **read_args: Optional arguments passed to `srsly.read_json()`/`srsly.read_jsonl()`/`srsly.read_gzip_json`. \"\"\" if Path.is_file(json_or_path): cls.read_json(json_or_path, **read_args) return cls.from_config(srsly.json_loads(json_or_path)) from_yaml 1 2 3 def from_yaml ( yaml_or_path : str ) -> 'Configurable' Get config from YAML string or filepath. Parameters: Name Type Description Default yaml_or_path str File path or YAML string. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @classmethod def from_yaml(cls, yaml_or_path: str) -> 'Configurable': \"\"\"Get config from YAML string or filepath. Args: yaml_or_path (str): File path or YAML string. \"\"\" if Path.is_file(yaml_or_path): return cls.from_config(cls.read_yaml(yaml_or_path)) return cls.from_config(srsly.yaml_loads(yaml_or_path)) read_json 1 2 3 4 def read_json ( path : str , ** read_args ) -> 'Configurable' Read config from JSON file (GZIP JSON, JSONL or JSON). Parameters: Name Type Description Default path str File path. None **read_args None Optional arguments passed to srsly.read_json() / srsly.read_jsonl() / srsly.read_gzip_json . None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @classmethod def read_json(cls, path: str, **read_args) -> 'Configurable': \"\"\"Read config from JSON file (GZIP JSON, JSONL or JSON). Args: path (str): File path. **read_args: Optional arguments passed to `srsly.read_json()`/`srsly.read_jsonl()`/`srsly.read_gzip_json`. \"\"\" read_fn = srsly.read_json if path.endswith('.json.gz'): read_fn = srsly.read_gzip_json elif path.endswith('.jsonl'): read_fn = srsly.read_jsonl return cls.from_config(read_fn(path, **read_args)) read_yaml 1 2 3 def read_yaml ( path : str ) -> 'Configurable' Read config from YAML file. Parameters: Name Type Description Default path str File path. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 @classmethod def read_yaml(cls, path: str) -> 'Configurable': \"\"\"Read config from YAML file. Args: path (str): File path. \"\"\" return srsly.read_yaml(path) Instance variables 1 callargs 1 content 1 labels Get labels property. 1 labelset Get label names property. 1 meta 1 renderargs 1 subtype 1 type Methods label_by_index 1 2 3 4 def label_by_index ( self , idx : int ) -> Union [ str , int ] Access label name by index, if labelset is set. Parameters: Name Type Description Default idx int Lookup index. None Returns: Type Description Union[str, int] Label name (if available) else index. Raises: Type Description IndexError labelset is set but the element index is not in labelset (index out of bounds). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def label_by_index(self, idx: int) -> Union[str, int]: \"\"\"Access label name by index, if `labelset` is set. Args: idx (int): Lookup index. Raises: IndexError: `labelset` is set but the element index is not in `labelset` (index out of bounds). Returns: Union[str, int]: Label name (if available) else index. \"\"\" if self.labelset is not None: return self.labelset[idx] return idx to_config 1 2 3 def to_config ( self ) Convert class information into config (configuration dictionary). Parameters: Name Type Description Default exclude List[str] Names of variables to exclude. None Returns: Type Description dict [description] View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def to_config(self): if hasattr(self, 'content'): _content = self.content() if callable(self.content) else self.content content = dict(recursive_to_dict(_content, include_class=False)) else: content = super().to_config(exclude=['_type', '_subtype', '_dict', '_callargs']) return {'META': self.meta, 'CONTENT': content} to_json 1 2 3 4 def to_json ( self , indent : int = 2 ) -> str Convert config to JSON-formatted string. Parameters: Name Type Description Default indent int Number of spaces to indent JSON. Defaults to 2. 2 Returns: Type Description str Config formatted as JSON. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def to_json(self, indent: int = 2) -> str: \"\"\"Convert config to JSON-formatted string. Args: indent (int, optional): Number of spaces to indent JSON. Defaults to 2. Returns: str: Config formatted as JSON. \"\"\" return srsly.json_dumps(self.to_config(), indent=indent) to_yaml 1 2 3 4 def to_yaml ( self , ** write_args ) -> str Convert config to YAML-formatted string. Parameters: Name Type Description Default **write_args None Optional arguments passed to srsly.yaml_dumps() None Returns: Type Description str Config formatted as YAML. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def to_yaml(self, **write_args) -> str: \"\"\"Convert config to YAML-formatted string. Args: **write_args: Optional arguments passed to `srsly.yaml_dumps()` Returns: str: Config formatted as YAML. \"\"\" return srsly.yaml_dumps(self.to_config(), **write_args) write_json 1 2 3 4 5 def write_json ( self , path : str , indent : int = 2 ) -> None Write class config to JSON. Parameters: Name Type Description Default path str Path to save to. If ends in .json.gz saves as GZIP JSON, .jsonl as JSONL or JSON by default. None indent int Number of spaces to indent JSON. Defaults to 2. 2 View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def write_json(self, path: str, indent: int = 2) -> None: \"\"\"Write class config to JSON. Args: path (str): Path to save to. If ends in `.json.gz` saves as GZIP JSON, `.jsonl` as JSONL or JSON by default. indent (int, optional): Number of spaces to indent JSON. Defaults to 2. \"\"\" write_fn = srsly.write_json if path.endswith('.json.gz'): write_fn = srsly.write_gzip_json elif path.endswith('.jsonl'): write_fn = srsly.write_jsonl write_fn(path, self.to_config(), indent=indent) write_yaml 1 2 3 4 5 def write_yaml ( self , path : str , ** write_args ) -> None Write class config to YAML. Parameters: Name Type Description Default path str Path to save to. None **write_args None Optional arguments passed to srsly.write_yaml() None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def write_yaml(self, path: str, **write_args) -> None: \"\"\"Write class config to YAML. Args: path (str): Path to save to. **write_args: Optional arguments passed to `srsly.write_yaml()` \"\"\" srsly.write_yaml(path, self.to_config(), **write_args)","title":"Return Types"},{"location":"reference/text_sensitivity/return_types/#module-text_sensitivityreturn_types","text":"Return types for sensitivity (tests). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 \"\"\"Return types for sensitivity (tests).\"\"\" from typing import Optional, Union from instancelib.labels import LabelProvider, MemoryLabelProvider from text_explainability.generation.return_types import Instances from text_sensitivity.ui.notebook import Render class SuccessTest(Instances): def __init__(self, success_percentage: float, successes, failures, predictions: Optional[Union[LabelProvider, list, dict]] = None, type: str = 'robustness', subtype: str = 'input_space', callargs: Optional[dict] = None, **kwargs): super().__init__(instances={'successes': successes, 'failures': failures}, type=type, subtype=subtype, callargs=callargs, renderer=Render, **kwargs) self.success_percentage = success_percentage self.predictions = self.__load_predictions(predictions) def __load_predictions(self, predictions): if predictions is None: return None if not isinstance(predictions, LabelProvider): return MemoryLabelProvider.from_tuples(predictions) return predictions @property def content(self): res = {'success_percentage': self.success_percentage, 'failure_percentage': 1.0 - self.success_percentage, 'successes': self.instances['successes'], 'failures': self.instances['failures']} if self.predictions is not None: res['predictions'] = self.predictions return res","title":"Module text_sensitivity.return_types"},{"location":"reference/text_sensitivity/return_types/#classes","text":"","title":"Classes"},{"location":"reference/text_sensitivity/return_types/#successtest","text":"1 2 3 4 5 6 7 8 9 10 class SuccessTest ( success_percentage : float , successes , failures , predictions : Union [ instancelib . labels . base . LabelProvider , list , dict , NoneType ] = None , type : str = 'robustness' , subtype : str = 'input_space' , callargs : Optional [ dict ] = None , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class SuccessTest(Instances): def __init__(self, success_percentage: float, successes, failures, predictions: Optional[Union[LabelProvider, list, dict]] = None, type: str = 'robustness', subtype: str = 'input_space', callargs: Optional[dict] = None, **kwargs): super().__init__(instances={'successes': successes, 'failures': failures}, type=type, subtype=subtype, callargs=callargs, renderer=Render, **kwargs) self.success_percentage = success_percentage self.predictions = self.__load_predictions(predictions) def __load_predictions(self, predictions): if predictions is None: return None if not isinstance(predictions, LabelProvider): return MemoryLabelProvider.from_tuples(predictions) return predictions @property def content(self): res = {'success_percentage': self.success_percentage, 'failure_percentage': 1.0 - self.success_percentage, 'successes': self.instances['successes'], 'failures': self.instances['failures']} if self.predictions is not None: res['predictions'] = self.predictions return res","title":"SuccessTest"},{"location":"reference/text_sensitivity/return_types/#ancestors-in-mro","text":"text_explainability.generation.return_types.Instances text_explainability.generation.return_types.BaseReturnType genbase.MetaInfo genbase.Configurable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/return_types/#static-methods","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/return_types/#from_config","text":"1 2 3 4 def from_config ( config : dict , ** kwargs ) -> 'Configurable' View Source 1 2 3 4 5 6 7 8 9 @classmethod def from_config(cls, config: dict, **kwargs) -> 'Configurable': config = {**config, **kwargs} _ = config.pop('__class__', None) return cls(**config)","title":"from_config"},{"location":"reference/text_sensitivity/return_types/#from_json","text":"1 2 3 4 def from_json ( json_or_path : str , ** read_args ) -> 'Configurable' Get config from JSON string or filepath. Parameters: Name Type Description Default json_or_path str File path or JSON string. None **read_args None Optional arguments passed to srsly.read_json() / srsly.read_jsonl() / srsly.read_gzip_json . None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @classmethod def from_json(cls, json_or_path: str, **read_args) -> 'Configurable': \"\"\"Get config from JSON string or filepath. Args: json_or_path (str): File path or JSON string. **read_args: Optional arguments passed to `srsly.read_json()`/`srsly.read_jsonl()`/`srsly.read_gzip_json`. \"\"\" if Path.is_file(json_or_path): cls.read_json(json_or_path, **read_args) return cls.from_config(srsly.json_loads(json_or_path))","title":"from_json"},{"location":"reference/text_sensitivity/return_types/#from_yaml","text":"1 2 3 def from_yaml ( yaml_or_path : str ) -> 'Configurable' Get config from YAML string or filepath. Parameters: Name Type Description Default yaml_or_path str File path or YAML string. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @classmethod def from_yaml(cls, yaml_or_path: str) -> 'Configurable': \"\"\"Get config from YAML string or filepath. Args: yaml_or_path (str): File path or YAML string. \"\"\" if Path.is_file(yaml_or_path): return cls.from_config(cls.read_yaml(yaml_or_path)) return cls.from_config(srsly.yaml_loads(yaml_or_path))","title":"from_yaml"},{"location":"reference/text_sensitivity/return_types/#read_json","text":"1 2 3 4 def read_json ( path : str , ** read_args ) -> 'Configurable' Read config from JSON file (GZIP JSON, JSONL or JSON). Parameters: Name Type Description Default path str File path. None **read_args None Optional arguments passed to srsly.read_json() / srsly.read_jsonl() / srsly.read_gzip_json . None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @classmethod def read_json(cls, path: str, **read_args) -> 'Configurable': \"\"\"Read config from JSON file (GZIP JSON, JSONL or JSON). Args: path (str): File path. **read_args: Optional arguments passed to `srsly.read_json()`/`srsly.read_jsonl()`/`srsly.read_gzip_json`. \"\"\" read_fn = srsly.read_json if path.endswith('.json.gz'): read_fn = srsly.read_gzip_json elif path.endswith('.jsonl'): read_fn = srsly.read_jsonl return cls.from_config(read_fn(path, **read_args))","title":"read_json"},{"location":"reference/text_sensitivity/return_types/#read_yaml","text":"1 2 3 def read_yaml ( path : str ) -> 'Configurable' Read config from YAML file. Parameters: Name Type Description Default path str File path. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 @classmethod def read_yaml(cls, path: str) -> 'Configurable': \"\"\"Read config from YAML file. Args: path (str): File path. \"\"\" return srsly.read_yaml(path)","title":"read_yaml"},{"location":"reference/text_sensitivity/return_types/#instance-variables","text":"1 callargs 1 content 1 labels Get labels property. 1 labelset Get label names property. 1 meta 1 renderargs 1 subtype 1 type","title":"Instance variables"},{"location":"reference/text_sensitivity/return_types/#methods","text":"","title":"Methods"},{"location":"reference/text_sensitivity/return_types/#label_by_index","text":"1 2 3 4 def label_by_index ( self , idx : int ) -> Union [ str , int ] Access label name by index, if labelset is set. Parameters: Name Type Description Default idx int Lookup index. None Returns: Type Description Union[str, int] Label name (if available) else index. Raises: Type Description IndexError labelset is set but the element index is not in labelset (index out of bounds). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def label_by_index(self, idx: int) -> Union[str, int]: \"\"\"Access label name by index, if `labelset` is set. Args: idx (int): Lookup index. Raises: IndexError: `labelset` is set but the element index is not in `labelset` (index out of bounds). Returns: Union[str, int]: Label name (if available) else index. \"\"\" if self.labelset is not None: return self.labelset[idx] return idx","title":"label_by_index"},{"location":"reference/text_sensitivity/return_types/#to_config","text":"1 2 3 def to_config ( self ) Convert class information into config (configuration dictionary). Parameters: Name Type Description Default exclude List[str] Names of variables to exclude. None Returns: Type Description dict [description] View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def to_config(self): if hasattr(self, 'content'): _content = self.content() if callable(self.content) else self.content content = dict(recursive_to_dict(_content, include_class=False)) else: content = super().to_config(exclude=['_type', '_subtype', '_dict', '_callargs']) return {'META': self.meta, 'CONTENT': content}","title":"to_config"},{"location":"reference/text_sensitivity/return_types/#to_json","text":"1 2 3 4 def to_json ( self , indent : int = 2 ) -> str Convert config to JSON-formatted string. Parameters: Name Type Description Default indent int Number of spaces to indent JSON. Defaults to 2. 2 Returns: Type Description str Config formatted as JSON. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def to_json(self, indent: int = 2) -> str: \"\"\"Convert config to JSON-formatted string. Args: indent (int, optional): Number of spaces to indent JSON. Defaults to 2. Returns: str: Config formatted as JSON. \"\"\" return srsly.json_dumps(self.to_config(), indent=indent)","title":"to_json"},{"location":"reference/text_sensitivity/return_types/#to_yaml","text":"1 2 3 4 def to_yaml ( self , ** write_args ) -> str Convert config to YAML-formatted string. Parameters: Name Type Description Default **write_args None Optional arguments passed to srsly.yaml_dumps() None Returns: Type Description str Config formatted as YAML. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def to_yaml(self, **write_args) -> str: \"\"\"Convert config to YAML-formatted string. Args: **write_args: Optional arguments passed to `srsly.yaml_dumps()` Returns: str: Config formatted as YAML. \"\"\" return srsly.yaml_dumps(self.to_config(), **write_args)","title":"to_yaml"},{"location":"reference/text_sensitivity/return_types/#write_json","text":"1 2 3 4 5 def write_json ( self , path : str , indent : int = 2 ) -> None Write class config to JSON. Parameters: Name Type Description Default path str Path to save to. If ends in .json.gz saves as GZIP JSON, .jsonl as JSONL or JSON by default. None indent int Number of spaces to indent JSON. Defaults to 2. 2 View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def write_json(self, path: str, indent: int = 2) -> None: \"\"\"Write class config to JSON. Args: path (str): Path to save to. If ends in `.json.gz` saves as GZIP JSON, `.jsonl` as JSONL or JSON by default. indent (int, optional): Number of spaces to indent JSON. Defaults to 2. \"\"\" write_fn = srsly.write_json if path.endswith('.json.gz'): write_fn = srsly.write_gzip_json elif path.endswith('.jsonl'): write_fn = srsly.write_jsonl write_fn(path, self.to_config(), indent=indent)","title":"write_json"},{"location":"reference/text_sensitivity/return_types/#write_yaml","text":"1 2 3 4 5 def write_yaml ( self , path : str , ** write_args ) -> None Write class config to YAML. Parameters: Name Type Description Default path str Path to save to. None **write_args None Optional arguments passed to srsly.write_yaml() None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def write_yaml(self, path: str, **write_args) -> None: \"\"\"Write class config to YAML. Args: path (str): Path to save to. **write_args: Optional arguments passed to `srsly.write_yaml()` \"\"\" srsly.write_yaml(path, self.to_config(), **write_args)","title":"write_yaml"},{"location":"reference/text_sensitivity/sensitivity/","text":"Module text_sensitivity.sensitivity Sensitivity testing, for fairness and robustness. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 \"\"\"Sensitivity testing, for fairness and robustness.\"\"\" from typing import Iterator, List, Optional, Tuple, Union import numpy as np from genbase import add_callargs from instancelib.analysis.base import (BinaryModelMetrics, MulticlassModelMetrics, label_metrics) from instancelib.environment.text import TextEnvironment from instancelib.instances.base import InstanceProvider from instancelib.instances.text import MemoryTextInstance, TextInstanceProvider from instancelib.labels.memory import MemoryLabelProvider from instancelib.machinelearning.base import AbstractClassifier from instancelib.typehints import LT from text_sensitivity.data.generate import from_pattern from text_sensitivity.data.random.string import (RandomString, combine_generators) from text_sensitivity.perturbation.base import Perturbation from text_sensitivity.return_types import SuccessTest def apply_perturbation(dataset: Union[InstanceProvider, TextEnvironment], perturbation: Perturbation) -> Tuple[TextInstanceProvider, MemoryLabelProvider]: \"\"\"Apply a perturbation to a dataset, getting the perturbed instances and corresponding attribute labels. Examples: Repeat each string twice: >>> from text_sensitivity.perturbation.sentences import repeat_k_times >>> apply_perturbation(env, repeat_k_times(k=2)) Add the unrelated string 'This is unrelated.' before each instance: >>> from text_sensitivity.perturbation import OneToOnePerturbation >>> perturbation = OneToOnePerturbation.from_string(prefix='This is unrelated.') >>> apply_perturbation(env, perturbation) Args: dataset (Union[InstanceProvider, TextEnvironment]): Dataset to apply perturbation to (e.g. all data, train set, test set, set belonging to a given label, or subset of data for a (un)protected group). perturbation (Perturbation): Perturbation to apply, one-to-one or one-to-many. Returns: Tuple[TextInstanceProvider, MemoryLabelProvider]: Perturbed instances and corresponding attribute labels. \"\"\" if isinstance(dataset, TextEnvironment): dataset = dataset.dataset if not isinstance(perturbation, Perturbation): perturbation = perturbation() new_data, attributes = [], [] for key in dataset: for instances, labels in perturbation(dataset[key]): new_data.extend(instances) if isinstance(instances, list) else new_data.append(instances) attributes.extend(labels) if isinstance(labels, list) else attributes.append(labels) instanceprovider = TextInstanceProvider(new_data) instanceprovider.add_range(*dataset.dataset.get_all()) labelprovider = MemoryLabelProvider.from_tuples(attributes) return instanceprovider, labelprovider def equal_ground_truth(ground_truth, instances): # TODO: add ability to provide a different expectation of what will happen to the instance labels after perturbation for key in instances.keys(): parent_key = key.split('|')[0] if isinstance(key, str) else str(key) parent_key = int(parent_key) if parent_key.isdigit() else parent_key yield (key, ground_truth._labeldict[parent_key]) def compare_metric(env: TextEnvironment, model: AbstractClassifier, perturbation: Perturbation ) -> Iterator[Tuple[LT, LT, Union[BinaryModelMetrics, MulticlassModelMetrics]]]: \"\"\"Get metrics for each ground-truth label and attribute. Examples: Compare metric of `model` performance (e.g. accuracy, precision) before and after mapping each instance in a dataset to uppercase. >>> from text_sensitivity.perturbation.sentences import to_upper >>> compare_metric(env, model, to_upper) Compare metric when randomly adding 10 perturbed instances with typos to each instance in a dataset. >>> from text_sensitivity.perturbation.characters import add_typos >>> compare_metric(env, model, add_typos(n=10)) Args: env (TextEnvironment): Environment containing original instances (`.dataset`) and ground-truth labels (`.labels`). model (AbstractClassifier): Black-box model to compare metrics on. perturbation (Perturbation): Peturbation to apply. Yields: Iterator[Sequence[Tuple[LT, LT, Union[BinaryModelMetrics, MulticlassModelMetrics]]]]: Original label (before perturbation), perturbed label (after perturbation) and metrics for label-attribute pair. \"\"\" # Apply perturbations and get attributes instances, attributes = apply_perturbation(env, perturbation) # Perform prediction on original instances and perturbed instances model_predictions = MemoryLabelProvider.from_tuples(model.predict(instances)) # Expectation (for now that labels should remain equal) ground_truth = MemoryLabelProvider.from_tuples(list(equal_ground_truth(env.labels, instances))) for label in list(model_predictions.labelset): for attribute in list(attributes.labelset): metrics = label_metrics(model_predictions, ground_truth, attributes.get_instances_by_label(attribute), label) yield label, attribute, metrics def compare_accuracy(*args, **kwargs): \"\"\"Compare accuracy scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.accuracy) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'accuracy']) def compare_precision(*args, **kwargs): \"\"\"Compare precision scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.precision) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'precision']) def compare_recall(*args, **kwargs): \"\"\"Compare recall scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.recall) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'recall']) @add_callargs def input_space_robustness(model: AbstractClassifier, generators: List[RandomString], n_samples: int = 100, min_length: int = 0, max_length: int = 100, seed: Optional[int] = 0, **kwargs) -> SuccessTest: \"\"\"Test the robustness of a machine learning model to different input types. Example: Test a pretrained black-box `model` for its robustness to 1000 random strings (length 0 to 500), containing whitespace characters, ASCII (upper, lower and numbers), emojis and Russian Cyrillic characters: >>> from text_sensitivity.data.random.string import RandomAscii, RandomCyrillic, RandomEmojis, RandomWhitespace >>> input_space_robustness(model, >>> [RandomWhitespace(), RandomAscii(), RandomEmojis(base=True), RandomCyrillic('ru')], >>> n_samples=1000, >>> min_length=0, >>> max_length=500) Args: model (AbstractClassifier): Machine learning model to test. generators (List[RandomString]): Random character generators. n_samples (int, optional): Number of test samples. Defaults to 100. min_length (int, optional): Input minimum length. Defaults to 0. max_length (int, optional): Input maximum length. Defaults to 100. seed (Optional[int], optional): Seed for reproducibility purposes. Defaults to 0. Returns: SuccessTest: Percentage of success cases, list of succeeded/failed instances \"\"\" callargs = kwargs.pop('__callargs__', None) # Combine all generators into one generator = combine_generators(*generators, seed=seed) # Generate instances instances = generator.generate(n=n_samples, min_length=min_length, max_length=max_length) # Percentage success, instances that succeeded, instances that failed success: int = 0 successes: List[List[str]] = [] failures: List[List[str]] = [] # Do not perform it batchwise but per instance, in order to return the error-throwing failures for i in instances: try: model.predict([instances[i]]) success += 1 successes.append(instances[i]) except Exception: failures.append(instances[i]) return SuccessTest(1.0 if len(instances) == 0 else success / len(instances), successes, failures, type='robustness', subtype='input_space', callargs=callargs) @add_callargs def invariance(pattern: str, model: AbstractClassifier, expectation: Optional[LT] = None, **kwargs, ) -> SuccessTest: \"\"\"Test for the failure rate under invariance. Args: pattern (str): String pattern to generate examples from. model (AbstractClassifier): Model to test. expectation (Optional[LT], optional): Expected outcome values. Defaults to None. **kwargs: Optional arguments passed onto the `data.generate.from_pattern()` function. Returns: SuccessTest: Percentage of success cases, list of succeeded (invariant)/failed (variant) instances \"\"\" callargs = kwargs.pop('__callargs__', None) # Generate instances from pattern and predict instances, _ = from_pattern(pattern, **kwargs) predictions = model.predict(instances) if expectation is None: if len(predictions) == 0: return 0.0, [], [] expectation = predictions[0][-1] if not isinstance(expectation, frozenset): expectation = frozenset({expectation}) correct = [instances[id] for id, label in predictions if label == expectation] wrong = [instances[id] for id, label in predictions if label != expectation] return SuccessTest(1.0 if len(predictions) == 0 else len(correct) / len(predictions), correct, wrong, predictions=predictions, type='sensitivity', subtype='invariance', callargs=callargs) def mean_score(pattern: str, model: AbstractClassifier, selected_label: Optional[LT] = None, **kwargs) -> Tuple[float, List[Tuple[MemoryTextInstance, float]]]: \"\"\"Calculate mean (probability) score for a given label, for data generated from a pattern. Args: pattern (str): model (AbstractClassifier): Model to generate scores from. selected_label (Optional[LT], optional): Label name to select. If None is replaced by the first label. Defaults to None. Returns: Tuple[float, List[Tuple[LT, float]]]: Mean score for the selected label, generated instances and label scores. \"\"\" instances, _ = from_pattern(pattern, **kwargs) predictions = model.predict_proba_provider(instances) if selected_label is None: if len(predictions) == 0: return selected_label = list(model.encoder.labelset)[0] if isinstance(selected_label, frozenset): selected_label = list(selected_label)[0] predictions_by_label = [(instances[id], [proba for label, proba in list(probas) if label == selected_label][0]) for id, probas in predictions] return np.mean([p for id, p in predictions_by_label]), predictions_by_label Functions apply_perturbation 1 2 3 4 def apply_perturbation ( dataset : Union [ instancelib . instances . base . InstanceProvider , instancelib . environment . text . TextEnvironment ], perturbation : text_sensitivity . perturbation . base . Perturbation ) -> Tuple [ instancelib . instances . text . TextInstanceProvider , instancelib . labels . memory . MemoryLabelProvider ] Apply a perturbation to a dataset, getting the perturbed instances and corresponding attribute labels. Parameters: Name Type Description Default dataset Union[InstanceProvider, TextEnvironment] Dataset to apply perturbation to (e.g. all data, train set, test set, set belonging to a given label, or subset of data for a (un)protected group). None perturbation Perturbation Perturbation to apply, one-to-one or one-to-many. None Returns: Type Description Tuple[TextInstanceProvider, MemoryLabelProvider] Perturbed instances and corresponding attribute labels. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def apply_perturbation(dataset: Union[InstanceProvider, TextEnvironment], perturbation: Perturbation) -> Tuple[TextInstanceProvider, MemoryLabelProvider]: \"\"\"Apply a perturbation to a dataset, getting the perturbed instances and corresponding attribute labels. Examples: Repeat each string twice: >>> from text_sensitivity.perturbation.sentences import repeat_k_times >>> apply_perturbation(env, repeat_k_times(k=2)) Add the unrelated string 'This is unrelated.' before each instance: >>> from text_sensitivity.perturbation import OneToOnePerturbation >>> perturbation = OneToOnePerturbation.from_string(prefix='This is unrelated.') >>> apply_perturbation(env, perturbation) Args: dataset (Union[InstanceProvider, TextEnvironment]): Dataset to apply perturbation to (e.g. all data, train set, test set, set belonging to a given label, or subset of data for a (un)protected group). perturbation (Perturbation): Perturbation to apply, one-to-one or one-to-many. Returns: Tuple[TextInstanceProvider, MemoryLabelProvider]: Perturbed instances and corresponding attribute labels. \"\"\" if isinstance(dataset, TextEnvironment): dataset = dataset.dataset if not isinstance(perturbation, Perturbation): perturbation = perturbation() new_data, attributes = [], [] for key in dataset: for instances, labels in perturbation(dataset[key]): new_data.extend(instances) if isinstance(instances, list) else new_data.append(instances) attributes.extend(labels) if isinstance(labels, list) else attributes.append(labels) instanceprovider = TextInstanceProvider(new_data) instanceprovider.add_range(*dataset.dataset.get_all()) labelprovider = MemoryLabelProvider.from_tuples(attributes) return instanceprovider, labelprovider compare_accuracy 1 2 3 4 def compare_accuracy ( * args , ** kwargs ) Compare accuracy scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_accuracy(*args, **kwargs): \"\"\"Compare accuracy scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.accuracy) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'accuracy']) compare_metric 1 2 3 4 5 def compare_metric ( env : instancelib . environment . text . TextEnvironment , model : instancelib . machinelearning . base . AbstractClassifier , perturbation : text_sensitivity . perturbation . base . Perturbation ) -> Iterator [ Tuple [ ~ LT , ~ LT , Union [ instancelib . analysis . base . BinaryModelMetrics , instancelib . analysis . base . MulticlassModelMetrics ]]] Get metrics for each ground-truth label and attribute. Parameters: Name Type Description Default env TextEnvironment Environment containing original instances ( .dataset ) and ground-truth labels ( .labels ). None model AbstractClassifier Black-box model to compare metrics on. None perturbation Perturbation Peturbation to apply. None Yields: Type Description Iterator[Sequence[Tuple[LT, LT, Union[BinaryModelMetrics, MulticlassModelMetrics]]]] Original label (before perturbation), perturbed label (after perturbation) and metrics for label-attribute pair. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def compare_metric(env: TextEnvironment, model: AbstractClassifier, perturbation: Perturbation ) -> Iterator[Tuple[LT, LT, Union[BinaryModelMetrics, MulticlassModelMetrics]]]: \"\"\"Get metrics for each ground-truth label and attribute. Examples: Compare metric of `model` performance (e.g. accuracy, precision) before and after mapping each instance in a dataset to uppercase. >>> from text_sensitivity.perturbation.sentences import to_upper >>> compare_metric(env, model, to_upper) Compare metric when randomly adding 10 perturbed instances with typos to each instance in a dataset. >>> from text_sensitivity.perturbation.characters import add_typos >>> compare_metric(env, model, add_typos(n=10)) Args: env (TextEnvironment): Environment containing original instances (`.dataset`) and ground-truth labels (`.labels`). model (AbstractClassifier): Black-box model to compare metrics on. perturbation (Perturbation): Peturbation to apply. Yields: Iterator[Sequence[Tuple[LT, LT, Union[BinaryModelMetrics, MulticlassModelMetrics]]]]: Original label (before perturbation), perturbed label (after perturbation) and metrics for label-attribute pair. \"\"\" # Apply perturbations and get attributes instances, attributes = apply_perturbation(env, perturbation) # Perform prediction on original instances and perturbed instances model_predictions = MemoryLabelProvider.from_tuples(model.predict(instances)) # Expectation (for now that labels should remain equal) ground_truth = MemoryLabelProvider.from_tuples(list(equal_ground_truth(env.labels, instances))) for label in list(model_predictions.labelset): for attribute in list(attributes.labelset): metrics = label_metrics(model_predictions, ground_truth, attributes.get_instances_by_label(attribute), label) yield label, attribute, metrics compare_precision 1 2 3 4 def compare_precision ( * args , ** kwargs ) Compare precision scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_precision(*args, **kwargs): \"\"\"Compare precision scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.precision) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'precision']) compare_recall 1 2 3 4 def compare_recall ( * args , ** kwargs ) Compare recall scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_recall(*args, **kwargs): \"\"\"Compare recall scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.recall) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'recall']) equal_ground_truth 1 2 3 4 def equal_ground_truth ( ground_truth , instances ) View Source 1 2 3 4 5 6 7 8 9 10 11 def equal_ground_truth(ground_truth, instances): # TODO: add ability to provide a different expectation of what will happen to the instance labels after perturbation for key in instances.keys(): parent_key = key.split('|')[0] if isinstance(key, str) else str(key) parent_key = int(parent_key) if parent_key.isdigit() else parent_key yield (key, ground_truth._labeldict[parent_key]) mean_score 1 2 3 4 5 6 def mean_score ( pattern : str , model : instancelib . machinelearning . base . AbstractClassifier , selected_label : Optional [ ~ LT ] = None , ** kwargs ) -> Tuple [ float , List [ Tuple [ instancelib . instances . text . MemoryTextInstance , float ]]] Calculate mean (probability) score for a given label, for data generated from a pattern. Parameters: Name Type Description Default pattern str None model AbstractClassifier Model to generate scores from. None selected_label Optional[LT] Label name to select. If None is replaced by the first label. Defaults to None. None Returns: Type Description Tuple[float, List[Tuple[LT, float]]] Mean score for the selected label, generated instances and label scores. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def mean_score(pattern: str, model: AbstractClassifier, selected_label: Optional[LT] = None, **kwargs) -> Tuple[float, List[Tuple[MemoryTextInstance, float]]]: \"\"\"Calculate mean (probability) score for a given label, for data generated from a pattern. Args: pattern (str): model (AbstractClassifier): Model to generate scores from. selected_label (Optional[LT], optional): Label name to select. If None is replaced by the first label. Defaults to None. Returns: Tuple[float, List[Tuple[LT, float]]]: Mean score for the selected label, generated instances and label scores. \"\"\" instances, _ = from_pattern(pattern, **kwargs) predictions = model.predict_proba_provider(instances) if selected_label is None: if len(predictions) == 0: return selected_label = list(model.encoder.labelset)[0] if isinstance(selected_label, frozenset): selected_label = list(selected_label)[0] predictions_by_label = [(instances[id], [proba for label, proba in list(probas) if label == selected_label][0]) for id, probas in predictions] return np.mean([p for id, p in predictions_by_label]), predictions_by_label","title":"Sensitivity"},{"location":"reference/text_sensitivity/sensitivity/#module-text_sensitivitysensitivity","text":"Sensitivity testing, for fairness and robustness. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 \"\"\"Sensitivity testing, for fairness and robustness.\"\"\" from typing import Iterator, List, Optional, Tuple, Union import numpy as np from genbase import add_callargs from instancelib.analysis.base import (BinaryModelMetrics, MulticlassModelMetrics, label_metrics) from instancelib.environment.text import TextEnvironment from instancelib.instances.base import InstanceProvider from instancelib.instances.text import MemoryTextInstance, TextInstanceProvider from instancelib.labels.memory import MemoryLabelProvider from instancelib.machinelearning.base import AbstractClassifier from instancelib.typehints import LT from text_sensitivity.data.generate import from_pattern from text_sensitivity.data.random.string import (RandomString, combine_generators) from text_sensitivity.perturbation.base import Perturbation from text_sensitivity.return_types import SuccessTest def apply_perturbation(dataset: Union[InstanceProvider, TextEnvironment], perturbation: Perturbation) -> Tuple[TextInstanceProvider, MemoryLabelProvider]: \"\"\"Apply a perturbation to a dataset, getting the perturbed instances and corresponding attribute labels. Examples: Repeat each string twice: >>> from text_sensitivity.perturbation.sentences import repeat_k_times >>> apply_perturbation(env, repeat_k_times(k=2)) Add the unrelated string 'This is unrelated.' before each instance: >>> from text_sensitivity.perturbation import OneToOnePerturbation >>> perturbation = OneToOnePerturbation.from_string(prefix='This is unrelated.') >>> apply_perturbation(env, perturbation) Args: dataset (Union[InstanceProvider, TextEnvironment]): Dataset to apply perturbation to (e.g. all data, train set, test set, set belonging to a given label, or subset of data for a (un)protected group). perturbation (Perturbation): Perturbation to apply, one-to-one or one-to-many. Returns: Tuple[TextInstanceProvider, MemoryLabelProvider]: Perturbed instances and corresponding attribute labels. \"\"\" if isinstance(dataset, TextEnvironment): dataset = dataset.dataset if not isinstance(perturbation, Perturbation): perturbation = perturbation() new_data, attributes = [], [] for key in dataset: for instances, labels in perturbation(dataset[key]): new_data.extend(instances) if isinstance(instances, list) else new_data.append(instances) attributes.extend(labels) if isinstance(labels, list) else attributes.append(labels) instanceprovider = TextInstanceProvider(new_data) instanceprovider.add_range(*dataset.dataset.get_all()) labelprovider = MemoryLabelProvider.from_tuples(attributes) return instanceprovider, labelprovider def equal_ground_truth(ground_truth, instances): # TODO: add ability to provide a different expectation of what will happen to the instance labels after perturbation for key in instances.keys(): parent_key = key.split('|')[0] if isinstance(key, str) else str(key) parent_key = int(parent_key) if parent_key.isdigit() else parent_key yield (key, ground_truth._labeldict[parent_key]) def compare_metric(env: TextEnvironment, model: AbstractClassifier, perturbation: Perturbation ) -> Iterator[Tuple[LT, LT, Union[BinaryModelMetrics, MulticlassModelMetrics]]]: \"\"\"Get metrics for each ground-truth label and attribute. Examples: Compare metric of `model` performance (e.g. accuracy, precision) before and after mapping each instance in a dataset to uppercase. >>> from text_sensitivity.perturbation.sentences import to_upper >>> compare_metric(env, model, to_upper) Compare metric when randomly adding 10 perturbed instances with typos to each instance in a dataset. >>> from text_sensitivity.perturbation.characters import add_typos >>> compare_metric(env, model, add_typos(n=10)) Args: env (TextEnvironment): Environment containing original instances (`.dataset`) and ground-truth labels (`.labels`). model (AbstractClassifier): Black-box model to compare metrics on. perturbation (Perturbation): Peturbation to apply. Yields: Iterator[Sequence[Tuple[LT, LT, Union[BinaryModelMetrics, MulticlassModelMetrics]]]]: Original label (before perturbation), perturbed label (after perturbation) and metrics for label-attribute pair. \"\"\" # Apply perturbations and get attributes instances, attributes = apply_perturbation(env, perturbation) # Perform prediction on original instances and perturbed instances model_predictions = MemoryLabelProvider.from_tuples(model.predict(instances)) # Expectation (for now that labels should remain equal) ground_truth = MemoryLabelProvider.from_tuples(list(equal_ground_truth(env.labels, instances))) for label in list(model_predictions.labelset): for attribute in list(attributes.labelset): metrics = label_metrics(model_predictions, ground_truth, attributes.get_instances_by_label(attribute), label) yield label, attribute, metrics def compare_accuracy(*args, **kwargs): \"\"\"Compare accuracy scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.accuracy) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'accuracy']) def compare_precision(*args, **kwargs): \"\"\"Compare precision scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.precision) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'precision']) def compare_recall(*args, **kwargs): \"\"\"Compare recall scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.recall) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'recall']) @add_callargs def input_space_robustness(model: AbstractClassifier, generators: List[RandomString], n_samples: int = 100, min_length: int = 0, max_length: int = 100, seed: Optional[int] = 0, **kwargs) -> SuccessTest: \"\"\"Test the robustness of a machine learning model to different input types. Example: Test a pretrained black-box `model` for its robustness to 1000 random strings (length 0 to 500), containing whitespace characters, ASCII (upper, lower and numbers), emojis and Russian Cyrillic characters: >>> from text_sensitivity.data.random.string import RandomAscii, RandomCyrillic, RandomEmojis, RandomWhitespace >>> input_space_robustness(model, >>> [RandomWhitespace(), RandomAscii(), RandomEmojis(base=True), RandomCyrillic('ru')], >>> n_samples=1000, >>> min_length=0, >>> max_length=500) Args: model (AbstractClassifier): Machine learning model to test. generators (List[RandomString]): Random character generators. n_samples (int, optional): Number of test samples. Defaults to 100. min_length (int, optional): Input minimum length. Defaults to 0. max_length (int, optional): Input maximum length. Defaults to 100. seed (Optional[int], optional): Seed for reproducibility purposes. Defaults to 0. Returns: SuccessTest: Percentage of success cases, list of succeeded/failed instances \"\"\" callargs = kwargs.pop('__callargs__', None) # Combine all generators into one generator = combine_generators(*generators, seed=seed) # Generate instances instances = generator.generate(n=n_samples, min_length=min_length, max_length=max_length) # Percentage success, instances that succeeded, instances that failed success: int = 0 successes: List[List[str]] = [] failures: List[List[str]] = [] # Do not perform it batchwise but per instance, in order to return the error-throwing failures for i in instances: try: model.predict([instances[i]]) success += 1 successes.append(instances[i]) except Exception: failures.append(instances[i]) return SuccessTest(1.0 if len(instances) == 0 else success / len(instances), successes, failures, type='robustness', subtype='input_space', callargs=callargs) @add_callargs def invariance(pattern: str, model: AbstractClassifier, expectation: Optional[LT] = None, **kwargs, ) -> SuccessTest: \"\"\"Test for the failure rate under invariance. Args: pattern (str): String pattern to generate examples from. model (AbstractClassifier): Model to test. expectation (Optional[LT], optional): Expected outcome values. Defaults to None. **kwargs: Optional arguments passed onto the `data.generate.from_pattern()` function. Returns: SuccessTest: Percentage of success cases, list of succeeded (invariant)/failed (variant) instances \"\"\" callargs = kwargs.pop('__callargs__', None) # Generate instances from pattern and predict instances, _ = from_pattern(pattern, **kwargs) predictions = model.predict(instances) if expectation is None: if len(predictions) == 0: return 0.0, [], [] expectation = predictions[0][-1] if not isinstance(expectation, frozenset): expectation = frozenset({expectation}) correct = [instances[id] for id, label in predictions if label == expectation] wrong = [instances[id] for id, label in predictions if label != expectation] return SuccessTest(1.0 if len(predictions) == 0 else len(correct) / len(predictions), correct, wrong, predictions=predictions, type='sensitivity', subtype='invariance', callargs=callargs) def mean_score(pattern: str, model: AbstractClassifier, selected_label: Optional[LT] = None, **kwargs) -> Tuple[float, List[Tuple[MemoryTextInstance, float]]]: \"\"\"Calculate mean (probability) score for a given label, for data generated from a pattern. Args: pattern (str): model (AbstractClassifier): Model to generate scores from. selected_label (Optional[LT], optional): Label name to select. If None is replaced by the first label. Defaults to None. Returns: Tuple[float, List[Tuple[LT, float]]]: Mean score for the selected label, generated instances and label scores. \"\"\" instances, _ = from_pattern(pattern, **kwargs) predictions = model.predict_proba_provider(instances) if selected_label is None: if len(predictions) == 0: return selected_label = list(model.encoder.labelset)[0] if isinstance(selected_label, frozenset): selected_label = list(selected_label)[0] predictions_by_label = [(instances[id], [proba for label, proba in list(probas) if label == selected_label][0]) for id, probas in predictions] return np.mean([p for id, p in predictions_by_label]), predictions_by_label","title":"Module text_sensitivity.sensitivity"},{"location":"reference/text_sensitivity/sensitivity/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/sensitivity/#apply_perturbation","text":"1 2 3 4 def apply_perturbation ( dataset : Union [ instancelib . instances . base . InstanceProvider , instancelib . environment . text . TextEnvironment ], perturbation : text_sensitivity . perturbation . base . Perturbation ) -> Tuple [ instancelib . instances . text . TextInstanceProvider , instancelib . labels . memory . MemoryLabelProvider ] Apply a perturbation to a dataset, getting the perturbed instances and corresponding attribute labels. Parameters: Name Type Description Default dataset Union[InstanceProvider, TextEnvironment] Dataset to apply perturbation to (e.g. all data, train set, test set, set belonging to a given label, or subset of data for a (un)protected group). None perturbation Perturbation Perturbation to apply, one-to-one or one-to-many. None Returns: Type Description Tuple[TextInstanceProvider, MemoryLabelProvider] Perturbed instances and corresponding attribute labels. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def apply_perturbation(dataset: Union[InstanceProvider, TextEnvironment], perturbation: Perturbation) -> Tuple[TextInstanceProvider, MemoryLabelProvider]: \"\"\"Apply a perturbation to a dataset, getting the perturbed instances and corresponding attribute labels. Examples: Repeat each string twice: >>> from text_sensitivity.perturbation.sentences import repeat_k_times >>> apply_perturbation(env, repeat_k_times(k=2)) Add the unrelated string 'This is unrelated.' before each instance: >>> from text_sensitivity.perturbation import OneToOnePerturbation >>> perturbation = OneToOnePerturbation.from_string(prefix='This is unrelated.') >>> apply_perturbation(env, perturbation) Args: dataset (Union[InstanceProvider, TextEnvironment]): Dataset to apply perturbation to (e.g. all data, train set, test set, set belonging to a given label, or subset of data for a (un)protected group). perturbation (Perturbation): Perturbation to apply, one-to-one or one-to-many. Returns: Tuple[TextInstanceProvider, MemoryLabelProvider]: Perturbed instances and corresponding attribute labels. \"\"\" if isinstance(dataset, TextEnvironment): dataset = dataset.dataset if not isinstance(perturbation, Perturbation): perturbation = perturbation() new_data, attributes = [], [] for key in dataset: for instances, labels in perturbation(dataset[key]): new_data.extend(instances) if isinstance(instances, list) else new_data.append(instances) attributes.extend(labels) if isinstance(labels, list) else attributes.append(labels) instanceprovider = TextInstanceProvider(new_data) instanceprovider.add_range(*dataset.dataset.get_all()) labelprovider = MemoryLabelProvider.from_tuples(attributes) return instanceprovider, labelprovider","title":"apply_perturbation"},{"location":"reference/text_sensitivity/sensitivity/#compare_accuracy","text":"1 2 3 4 def compare_accuracy ( * args , ** kwargs ) Compare accuracy scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_accuracy(*args, **kwargs): \"\"\"Compare accuracy scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.accuracy) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'accuracy'])","title":"compare_accuracy"},{"location":"reference/text_sensitivity/sensitivity/#compare_metric","text":"1 2 3 4 5 def compare_metric ( env : instancelib . environment . text . TextEnvironment , model : instancelib . machinelearning . base . AbstractClassifier , perturbation : text_sensitivity . perturbation . base . Perturbation ) -> Iterator [ Tuple [ ~ LT , ~ LT , Union [ instancelib . analysis . base . BinaryModelMetrics , instancelib . analysis . base . MulticlassModelMetrics ]]] Get metrics for each ground-truth label and attribute. Parameters: Name Type Description Default env TextEnvironment Environment containing original instances ( .dataset ) and ground-truth labels ( .labels ). None model AbstractClassifier Black-box model to compare metrics on. None perturbation Perturbation Peturbation to apply. None Yields: Type Description Iterator[Sequence[Tuple[LT, LT, Union[BinaryModelMetrics, MulticlassModelMetrics]]]] Original label (before perturbation), perturbed label (after perturbation) and metrics for label-attribute pair. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def compare_metric(env: TextEnvironment, model: AbstractClassifier, perturbation: Perturbation ) -> Iterator[Tuple[LT, LT, Union[BinaryModelMetrics, MulticlassModelMetrics]]]: \"\"\"Get metrics for each ground-truth label and attribute. Examples: Compare metric of `model` performance (e.g. accuracy, precision) before and after mapping each instance in a dataset to uppercase. >>> from text_sensitivity.perturbation.sentences import to_upper >>> compare_metric(env, model, to_upper) Compare metric when randomly adding 10 perturbed instances with typos to each instance in a dataset. >>> from text_sensitivity.perturbation.characters import add_typos >>> compare_metric(env, model, add_typos(n=10)) Args: env (TextEnvironment): Environment containing original instances (`.dataset`) and ground-truth labels (`.labels`). model (AbstractClassifier): Black-box model to compare metrics on. perturbation (Perturbation): Peturbation to apply. Yields: Iterator[Sequence[Tuple[LT, LT, Union[BinaryModelMetrics, MulticlassModelMetrics]]]]: Original label (before perturbation), perturbed label (after perturbation) and metrics for label-attribute pair. \"\"\" # Apply perturbations and get attributes instances, attributes = apply_perturbation(env, perturbation) # Perform prediction on original instances and perturbed instances model_predictions = MemoryLabelProvider.from_tuples(model.predict(instances)) # Expectation (for now that labels should remain equal) ground_truth = MemoryLabelProvider.from_tuples(list(equal_ground_truth(env.labels, instances))) for label in list(model_predictions.labelset): for attribute in list(attributes.labelset): metrics = label_metrics(model_predictions, ground_truth, attributes.get_instances_by_label(attribute), label) yield label, attribute, metrics","title":"compare_metric"},{"location":"reference/text_sensitivity/sensitivity/#compare_precision","text":"1 2 3 4 def compare_precision ( * args , ** kwargs ) Compare precision scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_precision(*args, **kwargs): \"\"\"Compare precision scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.precision) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'precision'])","title":"compare_precision"},{"location":"reference/text_sensitivity/sensitivity/#compare_recall","text":"1 2 3 4 def compare_recall ( * args , ** kwargs ) Compare recall scores for each ground-truth label and attribute. View Source 1 2 3 4 5 6 7 8 9 10 11 def compare_recall(*args, **kwargs): \"\"\"Compare recall scores for each ground-truth label and attribute.\"\"\" import pandas as pd return pd.DataFrame([(label, attribute, metrics.recall) for label, attribute, metrics in compare_metric(*args, **kwargs)], columns=['label', 'attribute', 'recall'])","title":"compare_recall"},{"location":"reference/text_sensitivity/sensitivity/#equal_ground_truth","text":"1 2 3 4 def equal_ground_truth ( ground_truth , instances ) View Source 1 2 3 4 5 6 7 8 9 10 11 def equal_ground_truth(ground_truth, instances): # TODO: add ability to provide a different expectation of what will happen to the instance labels after perturbation for key in instances.keys(): parent_key = key.split('|')[0] if isinstance(key, str) else str(key) parent_key = int(parent_key) if parent_key.isdigit() else parent_key yield (key, ground_truth._labeldict[parent_key])","title":"equal_ground_truth"},{"location":"reference/text_sensitivity/sensitivity/#mean_score","text":"1 2 3 4 5 6 def mean_score ( pattern : str , model : instancelib . machinelearning . base . AbstractClassifier , selected_label : Optional [ ~ LT ] = None , ** kwargs ) -> Tuple [ float , List [ Tuple [ instancelib . instances . text . MemoryTextInstance , float ]]] Calculate mean (probability) score for a given label, for data generated from a pattern. Parameters: Name Type Description Default pattern str None model AbstractClassifier Model to generate scores from. None selected_label Optional[LT] Label name to select. If None is replaced by the first label. Defaults to None. None Returns: Type Description Tuple[float, List[Tuple[LT, float]]] Mean score for the selected label, generated instances and label scores. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def mean_score(pattern: str, model: AbstractClassifier, selected_label: Optional[LT] = None, **kwargs) -> Tuple[float, List[Tuple[MemoryTextInstance, float]]]: \"\"\"Calculate mean (probability) score for a given label, for data generated from a pattern. Args: pattern (str): model (AbstractClassifier): Model to generate scores from. selected_label (Optional[LT], optional): Label name to select. If None is replaced by the first label. Defaults to None. Returns: Tuple[float, List[Tuple[LT, float]]]: Mean score for the selected label, generated instances and label scores. \"\"\" instances, _ = from_pattern(pattern, **kwargs) predictions = model.predict_proba_provider(instances) if selected_label is None: if len(predictions) == 0: return selected_label = list(model.encoder.labelset)[0] if isinstance(selected_label, frozenset): selected_label = list(selected_label)[0] predictions_by_label = [(instances[id], [proba for label, proba in list(probas) if label == selected_label][0]) for id, probas in predictions] return np.mean([p for id, p in predictions_by_label]), predictions_by_label","title":"mean_score"},{"location":"reference/text_sensitivity/data/","text":"Module text_sensitivity.data All randomly generated data, and data for lookups (e.g. word lists). None View Source 1 2 3 \"\"\"All randomly generated data, and data for lookups (e.g. word lists).\"\"\" from text_sensitivity.data.generate import from_pattern Sub-modules text_sensitivity.data.generate text_sensitivity.data.lists text_sensitivity.data.random text_sensitivity.data.wordlist","title":"Index"},{"location":"reference/text_sensitivity/data/#module-text_sensitivitydata","text":"All randomly generated data, and data for lookups (e.g. word lists). None View Source 1 2 3 \"\"\"All randomly generated data, and data for lookups (e.g. word lists).\"\"\" from text_sensitivity.data.generate import from_pattern","title":"Module text_sensitivity.data"},{"location":"reference/text_sensitivity/data/#sub-modules","text":"text_sensitivity.data.generate text_sensitivity.data.lists text_sensitivity.data.random text_sensitivity.data.wordlist","title":"Sub-modules"},{"location":"reference/text_sensitivity/data/generate/","text":"Module text_sensitivity.data.generate Generate data from a pattern, e.g. '{He|She} lives in {city}.' None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 \"\"\"Generate data from a pattern, e.g. `'{He|She} lives in {city}.'`\"\"\" import itertools from typing import List, Tuple from instancelib.instances.text import MemoryTextInstance, TextInstanceProvider from instancelib.labels.memory import MemoryLabelProvider from text_explainability.utils import word_detokenizer, word_tokenizer from text_sensitivity.data.random.entity import (RandomAddress, RandomCity, RandomCountry, RandomCryptoCurrency, RandomCurrencySymbol, RandomDay, RandomDayOfWeek, RandomEmail, RandomFirstName, RandomLastName, RandomLicensePlate, RandomMonth, RandomName, RandomPhoneNumber, RandomPriceTag, RandomYear) from text_sensitivity.data.wordlist import WordList DEFAULTS = {'address': RandomAddress, 'city': RandomCity, 'country': RandomCountry, 'name': RandomName, 'first_name': RandomFirstName, 'last_name': RandomLastName, 'email': RandomEmail, 'phone_number': RandomPhoneNumber, 'year': RandomYear, 'month': RandomMonth, 'day': RandomDay, 'day_of_week': RandomDayOfWeek, 'price_tag': RandomPriceTag, 'currency_symbol': RandomCurrencySymbol, 'crypto_currency': RandomCryptoCurrency, 'license_plate': RandomLicensePlate} def options_from_brackets(string: str, n: int = 3, seed: int = 0, **kwargs): def from_pattern(token: str): if token.startswith('{') and token.endswith('}'): pattern = token[1:-1] if ':' not in pattern: pattern = ':' + pattern modifiers, pattern = pattern.split(':') modifiers = [str(token).strip().lower() for x in modifiers.split(',')] def modify(p): if 'upper' in modifiers: return p.upper() elif 'lower' in modifiers: return p.lower() elif 'sentence' in modifiers: return p.sentence() elif 'title' in modifiers: return p.title() return p.original() if '|' in pattern: pattern = pattern.split('|') elif pattern in kwargs: pattern = kwargs[pattern] elif pattern in DEFAULTS: pattern = DEFAULTS[pattern] else: raise ValueError(f'Unknown {pattern=}') if isinstance(pattern, list): return modify(WordList.from_list(pattern, seed=seed)).generate_list() return modify(pattern(seed=seed)).generate_list(n=n) else: return [token] return [from_pattern(s) for s in word_tokenizer(string, exclude_curly_brackets=True)] def from_pattern(pattern: str, n: int = 3, seed: int = 0, **kwargs) -> Tuple[TextInstanceProvider, MemoryLabelProvider]: \"\"\"Generate data from a pattern. Examples: Generate a list ['This is his house', 'This was his house', 'This is his car', 'This was his car', ...]: >>> from_pattern('This {is|was} his {house|car|boat}') Generate a list ['His home town is Eindhoven.', 'Her home town is Eindhoven.', 'His home town is Meerssen.', ...]. By default uses `RandomCity()` to generate the city name. >>> from_pattern('{His|Her} home town is {city}.') Override the 'city' default with your own list ['Amsterdam', 'Rotterdam', 'Utrecht']: >>> from_pattern('{His|Her} home town is {city}.', city=['Amsterdam', 'Rotterdam', 'Utrecht']) Apply lower case to the first argument and uppercase to the last, getting ['Vandaag, donderdag heeft Sanne COLIN gebeld!', ..., 'Vandaag, maandag heeft Nora SEPP gebeld!', ...] for five random elements of each: >>> from_pattern('Vandaag, {lower:day_of_week}, heeft {first_name} {upper:first_name} gebeld!', n=5) Args: pattern (str): String containing pattern. n (int, optional): Number of elements to generate for each element, when generator is random. Defaults to 3. seed (int, optional): Seed for reproducibility. Defaults to 0. Returns: Tuple[TextInstanceProvider, MemoryLabelProvider]: Generated instances and corresponding labels. \"\"\" instances = list(map(list, itertools.product(*options_from_brackets(pattern, n=n, seed=seed, **kwargs)))) ids = [i for i in range(len(instances))] instances = TextInstanceProvider([MemoryTextInstance(id, word_detokenizer(instance), None, tokenized=instance) for id, instance in zip(ids, instances)]) # TODO: get labels from options_from_brackets labels = MemoryLabelProvider.from_tuples(list(zip(ids, [frozenset({'perturbed'})] * len(instances)))) return instances, labels def default_patterns() -> List[str]: return list(DEFAULTS.keys()) Variables 1 DEFAULTS Functions default_patterns 1 2 3 def default_patterns ( ) -> List [ str ] View Source 1 2 3 def default_patterns() -> List[str]: return list(DEFAULTS.keys()) from_pattern 1 2 3 4 5 6 def from_pattern ( pattern : str , n : int = 3 , seed : int = 0 , ** kwargs ) -> Tuple [ instancelib . instances . text . TextInstanceProvider , instancelib . labels . memory . MemoryLabelProvider ] Generate data from a pattern. Parameters: Name Type Description Default pattern str String containing pattern. None n int Number of elements to generate for each element, when generator is random. Defaults to 3. 3 seed int Seed for reproducibility. Defaults to 0. 0 Returns: Type Description Tuple[TextInstanceProvider, MemoryLabelProvider] Generated instances and corresponding labels. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def from_pattern(pattern: str, n: int = 3, seed: int = 0, **kwargs) -> Tuple[TextInstanceProvider, MemoryLabelProvider]: \"\"\"Generate data from a pattern. Examples: Generate a list ['This is his house', 'This was his house', 'This is his car', 'This was his car', ...]: >>> from_pattern('This {is|was} his {house|car|boat}') Generate a list ['His home town is Eindhoven.', 'Her home town is Eindhoven.', 'His home town is Meerssen.', ...]. By default uses `RandomCity()` to generate the city name. >>> from_pattern('{His|Her} home town is {city}.') Override the 'city' default with your own list ['Amsterdam', 'Rotterdam', 'Utrecht']: >>> from_pattern('{His|Her} home town is {city}.', city=['Amsterdam', 'Rotterdam', 'Utrecht']) Apply lower case to the first argument and uppercase to the last, getting ['Vandaag, donderdag heeft Sanne COLIN gebeld!', ..., 'Vandaag, maandag heeft Nora SEPP gebeld!', ...] for five random elements of each: >>> from_pattern('Vandaag, {lower:day_of_week}, heeft {first_name} {upper:first_name} gebeld!', n=5) Args: pattern (str): String containing pattern. n (int, optional): Number of elements to generate for each element, when generator is random. Defaults to 3. seed (int, optional): Seed for reproducibility. Defaults to 0. Returns: Tuple[TextInstanceProvider, MemoryLabelProvider]: Generated instances and corresponding labels. \"\"\" instances = list(map(list, itertools.product(*options_from_brackets(pattern, n=n, seed=seed, **kwargs)))) ids = [i for i in range(len(instances))] instances = TextInstanceProvider([MemoryTextInstance(id, word_detokenizer(instance), None, tokenized=instance) for id, instance in zip(ids, instances)]) # TODO: get labels from options_from_brackets labels = MemoryLabelProvider.from_tuples(list(zip(ids, [frozenset({'perturbed'})] * len(instances)))) return instances, labels options_from_brackets 1 2 3 4 5 6 def options_from_brackets ( string : str , n : int = 3 , seed : int = 0 , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def options_from_brackets(string: str, n: int = 3, seed: int = 0, **kwargs): def from_pattern(token: str): if token.startswith('{') and token.endswith('}'): pattern = token[1:-1] if ':' not in pattern: pattern = ':' + pattern modifiers, pattern = pattern.split(':') modifiers = [str(token).strip().lower() for x in modifiers.split(',')] def modify(p): if 'upper' in modifiers: return p.upper() elif 'lower' in modifiers: return p.lower() elif 'sentence' in modifiers: return p.sentence() elif 'title' in modifiers: return p.title() return p.original() if '|' in pattern: pattern = pattern.split('|') elif pattern in kwargs: pattern = kwargs[pattern] elif pattern in DEFAULTS: pattern = DEFAULTS[pattern] else: raise ValueError(f'Unknown {pattern=}') if isinstance(pattern, list): return modify(WordList.from_list(pattern, seed=seed)).generate_list() return modify(pattern(seed=seed)).generate_list(n=n) else: return [token] return [from_pattern(s) for s in word_tokenizer(string, exclude_curly_brackets=True)]","title":"Generate"},{"location":"reference/text_sensitivity/data/generate/#module-text_sensitivitydatagenerate","text":"Generate data from a pattern, e.g. '{He|She} lives in {city}.' None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 \"\"\"Generate data from a pattern, e.g. `'{He|She} lives in {city}.'`\"\"\" import itertools from typing import List, Tuple from instancelib.instances.text import MemoryTextInstance, TextInstanceProvider from instancelib.labels.memory import MemoryLabelProvider from text_explainability.utils import word_detokenizer, word_tokenizer from text_sensitivity.data.random.entity import (RandomAddress, RandomCity, RandomCountry, RandomCryptoCurrency, RandomCurrencySymbol, RandomDay, RandomDayOfWeek, RandomEmail, RandomFirstName, RandomLastName, RandomLicensePlate, RandomMonth, RandomName, RandomPhoneNumber, RandomPriceTag, RandomYear) from text_sensitivity.data.wordlist import WordList DEFAULTS = {'address': RandomAddress, 'city': RandomCity, 'country': RandomCountry, 'name': RandomName, 'first_name': RandomFirstName, 'last_name': RandomLastName, 'email': RandomEmail, 'phone_number': RandomPhoneNumber, 'year': RandomYear, 'month': RandomMonth, 'day': RandomDay, 'day_of_week': RandomDayOfWeek, 'price_tag': RandomPriceTag, 'currency_symbol': RandomCurrencySymbol, 'crypto_currency': RandomCryptoCurrency, 'license_plate': RandomLicensePlate} def options_from_brackets(string: str, n: int = 3, seed: int = 0, **kwargs): def from_pattern(token: str): if token.startswith('{') and token.endswith('}'): pattern = token[1:-1] if ':' not in pattern: pattern = ':' + pattern modifiers, pattern = pattern.split(':') modifiers = [str(token).strip().lower() for x in modifiers.split(',')] def modify(p): if 'upper' in modifiers: return p.upper() elif 'lower' in modifiers: return p.lower() elif 'sentence' in modifiers: return p.sentence() elif 'title' in modifiers: return p.title() return p.original() if '|' in pattern: pattern = pattern.split('|') elif pattern in kwargs: pattern = kwargs[pattern] elif pattern in DEFAULTS: pattern = DEFAULTS[pattern] else: raise ValueError(f'Unknown {pattern=}') if isinstance(pattern, list): return modify(WordList.from_list(pattern, seed=seed)).generate_list() return modify(pattern(seed=seed)).generate_list(n=n) else: return [token] return [from_pattern(s) for s in word_tokenizer(string, exclude_curly_brackets=True)] def from_pattern(pattern: str, n: int = 3, seed: int = 0, **kwargs) -> Tuple[TextInstanceProvider, MemoryLabelProvider]: \"\"\"Generate data from a pattern. Examples: Generate a list ['This is his house', 'This was his house', 'This is his car', 'This was his car', ...]: >>> from_pattern('This {is|was} his {house|car|boat}') Generate a list ['His home town is Eindhoven.', 'Her home town is Eindhoven.', 'His home town is Meerssen.', ...]. By default uses `RandomCity()` to generate the city name. >>> from_pattern('{His|Her} home town is {city}.') Override the 'city' default with your own list ['Amsterdam', 'Rotterdam', 'Utrecht']: >>> from_pattern('{His|Her} home town is {city}.', city=['Amsterdam', 'Rotterdam', 'Utrecht']) Apply lower case to the first argument and uppercase to the last, getting ['Vandaag, donderdag heeft Sanne COLIN gebeld!', ..., 'Vandaag, maandag heeft Nora SEPP gebeld!', ...] for five random elements of each: >>> from_pattern('Vandaag, {lower:day_of_week}, heeft {first_name} {upper:first_name} gebeld!', n=5) Args: pattern (str): String containing pattern. n (int, optional): Number of elements to generate for each element, when generator is random. Defaults to 3. seed (int, optional): Seed for reproducibility. Defaults to 0. Returns: Tuple[TextInstanceProvider, MemoryLabelProvider]: Generated instances and corresponding labels. \"\"\" instances = list(map(list, itertools.product(*options_from_brackets(pattern, n=n, seed=seed, **kwargs)))) ids = [i for i in range(len(instances))] instances = TextInstanceProvider([MemoryTextInstance(id, word_detokenizer(instance), None, tokenized=instance) for id, instance in zip(ids, instances)]) # TODO: get labels from options_from_brackets labels = MemoryLabelProvider.from_tuples(list(zip(ids, [frozenset({'perturbed'})] * len(instances)))) return instances, labels def default_patterns() -> List[str]: return list(DEFAULTS.keys())","title":"Module text_sensitivity.data.generate"},{"location":"reference/text_sensitivity/data/generate/#variables","text":"1 DEFAULTS","title":"Variables"},{"location":"reference/text_sensitivity/data/generate/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/data/generate/#default_patterns","text":"1 2 3 def default_patterns ( ) -> List [ str ] View Source 1 2 3 def default_patterns() -> List[str]: return list(DEFAULTS.keys())","title":"default_patterns"},{"location":"reference/text_sensitivity/data/generate/#from_pattern","text":"1 2 3 4 5 6 def from_pattern ( pattern : str , n : int = 3 , seed : int = 0 , ** kwargs ) -> Tuple [ instancelib . instances . text . TextInstanceProvider , instancelib . labels . memory . MemoryLabelProvider ] Generate data from a pattern. Parameters: Name Type Description Default pattern str String containing pattern. None n int Number of elements to generate for each element, when generator is random. Defaults to 3. 3 seed int Seed for reproducibility. Defaults to 0. 0 Returns: Type Description Tuple[TextInstanceProvider, MemoryLabelProvider] Generated instances and corresponding labels. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def from_pattern(pattern: str, n: int = 3, seed: int = 0, **kwargs) -> Tuple[TextInstanceProvider, MemoryLabelProvider]: \"\"\"Generate data from a pattern. Examples: Generate a list ['This is his house', 'This was his house', 'This is his car', 'This was his car', ...]: >>> from_pattern('This {is|was} his {house|car|boat}') Generate a list ['His home town is Eindhoven.', 'Her home town is Eindhoven.', 'His home town is Meerssen.', ...]. By default uses `RandomCity()` to generate the city name. >>> from_pattern('{His|Her} home town is {city}.') Override the 'city' default with your own list ['Amsterdam', 'Rotterdam', 'Utrecht']: >>> from_pattern('{His|Her} home town is {city}.', city=['Amsterdam', 'Rotterdam', 'Utrecht']) Apply lower case to the first argument and uppercase to the last, getting ['Vandaag, donderdag heeft Sanne COLIN gebeld!', ..., 'Vandaag, maandag heeft Nora SEPP gebeld!', ...] for five random elements of each: >>> from_pattern('Vandaag, {lower:day_of_week}, heeft {first_name} {upper:first_name} gebeld!', n=5) Args: pattern (str): String containing pattern. n (int, optional): Number of elements to generate for each element, when generator is random. Defaults to 3. seed (int, optional): Seed for reproducibility. Defaults to 0. Returns: Tuple[TextInstanceProvider, MemoryLabelProvider]: Generated instances and corresponding labels. \"\"\" instances = list(map(list, itertools.product(*options_from_brackets(pattern, n=n, seed=seed, **kwargs)))) ids = [i for i in range(len(instances))] instances = TextInstanceProvider([MemoryTextInstance(id, word_detokenizer(instance), None, tokenized=instance) for id, instance in zip(ids, instances)]) # TODO: get labels from options_from_brackets labels = MemoryLabelProvider.from_tuples(list(zip(ids, [frozenset({'perturbed'})] * len(instances)))) return instances, labels","title":"from_pattern"},{"location":"reference/text_sensitivity/data/generate/#options_from_brackets","text":"1 2 3 4 5 6 def options_from_brackets ( string : str , n : int = 3 , seed : int = 0 , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def options_from_brackets(string: str, n: int = 3, seed: int = 0, **kwargs): def from_pattern(token: str): if token.startswith('{') and token.endswith('}'): pattern = token[1:-1] if ':' not in pattern: pattern = ':' + pattern modifiers, pattern = pattern.split(':') modifiers = [str(token).strip().lower() for x in modifiers.split(',')] def modify(p): if 'upper' in modifiers: return p.upper() elif 'lower' in modifiers: return p.lower() elif 'sentence' in modifiers: return p.sentence() elif 'title' in modifiers: return p.title() return p.original() if '|' in pattern: pattern = pattern.split('|') elif pattern in kwargs: pattern = kwargs[pattern] elif pattern in DEFAULTS: pattern = DEFAULTS[pattern] else: raise ValueError(f'Unknown {pattern=}') if isinstance(pattern, list): return modify(WordList.from_list(pattern, seed=seed)).generate_list() return modify(pattern(seed=seed)).generate_list(n=n) else: return [token] return [from_pattern(s) for s in word_tokenizer(string, exclude_curly_brackets=True)]","title":"options_from_brackets"},{"location":"reference/text_sensitivity/data/lists/","text":"Module text_sensitivity.data.lists None None","title":"Lists"},{"location":"reference/text_sensitivity/data/lists/#module-text_sensitivitydatalists","text":"None None","title":"Module text_sensitivity.data.lists"},{"location":"reference/text_sensitivity/data/wordlist/","text":"Module text_sensitivity.data.wordlist None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 from functools import lru_cache from typing import Dict, List, Optional, Union import numpy as np import pandas as pd from genbase import CaseMixin, Readable, SeedMixin Label = Union[str, int] class WordList(Readable, SeedMixin, CaseMixin): def __init__(self, wordlist: pd.DataFrame, main_column: Optional[Label] = None, seed: int = 0): self.wordlist = wordlist self.__wordlist = wordlist.copy(deep=True) self.main_column = main_column self._seed = self._original_seed = seed self._lowercase = self._sentencecase = self._titlecase = self._uppercase = False @classmethod def from_list(cls, wordlist: List[str], name: Label = 'words', seed: int = 0): return cls(pd.DataFrame(wordlist, columns=[name]), seed=seed) @classmethod def from_dictionary(cls, wordlist: Dict, key_name: Label = 'key', value_name: Label = 'value', value_as_main: bool = False, seed: int = 0): main_column = value_name if value_as_main else key_name return cls(pd.DataFrame(wordlist, columns=[key_name, value_name]), main_column=main_column, seed=seed) @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `WordList.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_csv(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_csv(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_json(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_json(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_excel(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_excel(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_pickle(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_pickle(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_file(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): import os extension = str.lower(os.path.splitext(filename)[1]) if extension == 'csv': return cls.from_csv(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'json': return cls.from_json(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension in ['xls', 'xlsx']: return cls.from_excel(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'pkl': return cls.from_pickle(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) else: return cls(pd.read_table(filename, main_column=main_column, seed=seed, *args, **kwargs), main_column=main_column) @lru_cache(1) def get(self, sort_by: Optional[Label] = None, **sort_kwargs): wordlist = self.wordlist.sort_values(by=sort_by, **sort_kwargs) if sort_by is not None else self.wordlist col = wordlist.iloc[:, 0] if self.main_column is None or self.main_column not in self.wordlist.columns \\ else wordlist.loc[:, self.main_column] return [self.apply_case(c) for c in list(col)] def generate_list(self, n: Optional[int] = None, likelihood_column: Optional[Label] = None): if n is None or isinstance(n, int) and n >= len(self.wordlist.index): return self.get() if likelihood_column is not None: likelihood_column = self.wordlist[likelihood_column].values / self.wordlist[likelihood_column].sum() np.random.seed(self._seed) return list(np.random.choice(self.get(), size=n, replace=False, p=likelihood_column)) def filter(self, column: Label, values: Union[Label, List[Label]]): if not isinstance(values, list): values = [values] self.wordlist = self.wordlist[self.wordlist[column].isin(values)] return self def reset(self): self.wordlist = self.__wordlist.copy(deep=True) return self def __len__(self): return len(self.get()) def __getitem__(self, item): return self.get()[item] class WordListGetterMixin: def get(self, *args, **kwargs): return self.wordlist.get(*args, **kwargs) def generate_list(self, *args, **kwargs): return self.wordlist.generate_list(*args, **kwargs) def filter(self, *args, **kwargs): return self.wordlist.filter(*args, **kwargs) def reset(self): return self.wordlist.reset() def __len__(self): return len(self.wordlist) Variables 1 Label Classes WordList 1 2 3 4 5 class WordList ( wordlist : pandas . core . frame . DataFrame , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 class WordList(Readable, SeedMixin, CaseMixin): def __init__(self, wordlist: pd.DataFrame, main_column: Optional[Label] = None, seed: int = 0): self.wordlist = wordlist self.__wordlist = wordlist.copy(deep=True) self.main_column = main_column self._seed = self._original_seed = seed self._lowercase = self._sentencecase = self._titlecase = self._uppercase = False @classmethod def from_list(cls, wordlist: List[str], name: Label = 'words', seed: int = 0): return cls(pd.DataFrame(wordlist, columns=[name]), seed=seed) @classmethod def from_dictionary(cls, wordlist: Dict, key_name: Label = 'key', value_name: Label = 'value', value_as_main: bool = False, seed: int = 0): main_column = value_name if value_as_main else key_name return cls(pd.DataFrame(wordlist, columns=[key_name, value_name]), main_column=main_column, seed=seed) @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `WordList.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_csv(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_csv(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_json(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_json(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_excel(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_excel(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_pickle(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_pickle(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_file(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): import os extension = str.lower(os.path.splitext(filename)[1]) if extension == 'csv': return cls.from_csv(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'json': return cls.from_json(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension in ['xls', 'xlsx']: return cls.from_excel(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'pkl': return cls.from_pickle(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) else: return cls(pd.read_table(filename, main_column=main_column, seed=seed, *args, **kwargs), main_column=main_column) @lru_cache(1) def get(self, sort_by: Optional[Label] = None, **sort_kwargs): wordlist = self.wordlist.sort_values(by=sort_by, **sort_kwargs) if sort_by is not None else self.wordlist col = wordlist.iloc[:, 0] if self.main_column is None or self.main_column not in self.wordlist.columns \\ else wordlist.loc[:, self.main_column] return [self.apply_case(c) for c in list(col)] def generate_list(self, n: Optional[int] = None, likelihood_column: Optional[Label] = None): if n is None or isinstance(n, int) and n >= len(self.wordlist.index): return self.get() if likelihood_column is not None: likelihood_column = self.wordlist[likelihood_column].values / self.wordlist[likelihood_column].sum() np.random.seed(self._seed) return list(np.random.choice(self.get(), size=n, replace=False, p=likelihood_column)) def filter(self, column: Label, values: Union[Label, List[Label]]): if not isinstance(values, list): values = [values] self.wordlist = self.wordlist[self.wordlist[column].isin(values)] return self def reset(self): self.wordlist = self.__wordlist.copy(deep=True) return self def __len__(self): return len(self.get()) def __getitem__(self, item): return self.get()[item] Ancestors (in MRO) genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Static methods from_csv 1 2 3 4 5 6 7 def from_csv ( filename : str , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 , * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_csv(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_csv(filename, *args, **kwargs), main_column=main_column, seed=seed) from_dict 1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for WordList.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `WordList.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) from_dictionary 1 2 3 4 5 6 7 def from_dictionary ( wordlist : Dict , key_name : Union [ str , int ] = 'key' , value_name : Union [ str , int ] = 'value' , value_as_main : bool = False , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @classmethod def from_dictionary(cls, wordlist: Dict, key_name: Label = 'key', value_name: Label = 'value', value_as_main: bool = False, seed: int = 0): main_column = value_name if value_as_main else key_name return cls(pd.DataFrame(wordlist, columns=[key_name, value_name]), main_column=main_column, seed=seed) from_excel 1 2 3 4 5 6 7 def from_excel ( filename : str , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 , * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_excel(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_excel(filename, *args, **kwargs), main_column=main_column, seed=seed) from_file 1 2 3 4 5 6 7 def from_file ( filename : str , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 , * args , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @classmethod def from_file(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): import os extension = str.lower(os.path.splitext(filename)[1]) if extension == 'csv': return cls.from_csv(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'json': return cls.from_json(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension in ['xls', 'xlsx']: return cls.from_excel(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'pkl': return cls.from_pickle(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) else: return cls(pd.read_table(filename, main_column=main_column, seed=seed, *args, **kwargs), main_column=main_column) from_json 1 2 3 4 5 6 7 def from_json ( filename : str , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 , * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_json(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_json(filename, *args, **kwargs), main_column=main_column, seed=seed) from_list 1 2 3 4 5 def from_list ( wordlist : List [ str ], name : Union [ str , int ] = 'words' , seed : int = 0 ) View Source 1 2 3 4 5 @classmethod def from_list(cls, wordlist: List[str], name: Label = 'words', seed: int = 0): return cls(pd.DataFrame(wordlist, columns=[name]), seed=seed) from_pickle 1 2 3 4 5 6 7 def from_pickle ( filename : str , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 , * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_pickle(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_pickle(filename, *args, **kwargs), main_column=main_column, seed=seed) Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string filter 1 2 3 4 5 def filter ( self , column : Union [ str , int ], values : Union [ str , int , List [ Union [ str , int ]]] ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def filter(self, column: Label, values: Union[Label, List[Label]]): if not isinstance(values, list): values = [values] self.wordlist = self.wordlist[self.wordlist[column].isin(values)] return self generate_list 1 2 3 4 5 def generate_list ( self , n : Optional [ int ] = None , likelihood_column : Union [ str , int , NoneType ] = None ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def generate_list(self, n: Optional[int] = None, likelihood_column: Optional[Label] = None): if n is None or isinstance(n, int) and n >= len(self.wordlist.index): return self.get() if likelihood_column is not None: likelihood_column = self.wordlist[likelihood_column].values / self.wordlist[likelihood_column].sum() np.random.seed(self._seed) return list(np.random.choice(self.get(), size=n, replace=False, p=likelihood_column)) get 1 2 3 4 5 def get ( self , sort_by : Union [ str , int , NoneType ] = None , ** sort_kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @lru_cache(1) def get(self, sort_by: Optional[Label] = None, **sort_kwargs): wordlist = self.wordlist.sort_values(by=sort_by, **sort_kwargs) if sort_by is not None else self.wordlist col = wordlist.iloc[:, 0] if self.main_column is None or self.main_column not in self.wordlist.columns \\ else wordlist.loc[:, self.main_column] return [self.apply_case(c) for c in list(col)] lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset 1 2 3 def reset ( self ) View Source 1 2 3 4 5 def reset(self): self.wordlist = self.__wordlist.copy(deep=True) return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self WordListGetterMixin 1 2 3 4 5 class WordListGetterMixin ( / , * args , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class WordListGetterMixin: def get(self, *args, **kwargs): return self.wordlist.get(*args, **kwargs) def generate_list(self, *args, **kwargs): return self.wordlist.generate_list(*args, **kwargs) def filter(self, *args, **kwargs): return self.wordlist.filter(*args, **kwargs) def reset(self): return self.wordlist.reset() def __len__(self): return len(self.wordlist) Methods filter 1 2 3 4 5 def filter ( self , * args , ** kwargs ) View Source 1 2 3 def filter(self, *args, **kwargs): return self.wordlist.filter(*args, **kwargs) generate_list 1 2 3 4 5 def generate_list ( self , * args , ** kwargs ) View Source 1 2 3 def generate_list(self, *args, **kwargs): return self.wordlist.generate_list(*args, **kwargs) get 1 2 3 4 5 def get ( self , * args , ** kwargs ) View Source 1 2 3 def get(self, *args, **kwargs): return self.wordlist.get(*args, **kwargs) reset 1 2 3 def reset ( self ) View Source 1 2 3 def reset(self): return self.wordlist.reset()","title":"Wordlist"},{"location":"reference/text_sensitivity/data/wordlist/#module-text_sensitivitydatawordlist","text":"None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 from functools import lru_cache from typing import Dict, List, Optional, Union import numpy as np import pandas as pd from genbase import CaseMixin, Readable, SeedMixin Label = Union[str, int] class WordList(Readable, SeedMixin, CaseMixin): def __init__(self, wordlist: pd.DataFrame, main_column: Optional[Label] = None, seed: int = 0): self.wordlist = wordlist self.__wordlist = wordlist.copy(deep=True) self.main_column = main_column self._seed = self._original_seed = seed self._lowercase = self._sentencecase = self._titlecase = self._uppercase = False @classmethod def from_list(cls, wordlist: List[str], name: Label = 'words', seed: int = 0): return cls(pd.DataFrame(wordlist, columns=[name]), seed=seed) @classmethod def from_dictionary(cls, wordlist: Dict, key_name: Label = 'key', value_name: Label = 'value', value_as_main: bool = False, seed: int = 0): main_column = value_name if value_as_main else key_name return cls(pd.DataFrame(wordlist, columns=[key_name, value_name]), main_column=main_column, seed=seed) @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `WordList.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_csv(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_csv(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_json(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_json(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_excel(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_excel(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_pickle(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_pickle(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_file(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): import os extension = str.lower(os.path.splitext(filename)[1]) if extension == 'csv': return cls.from_csv(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'json': return cls.from_json(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension in ['xls', 'xlsx']: return cls.from_excel(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'pkl': return cls.from_pickle(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) else: return cls(pd.read_table(filename, main_column=main_column, seed=seed, *args, **kwargs), main_column=main_column) @lru_cache(1) def get(self, sort_by: Optional[Label] = None, **sort_kwargs): wordlist = self.wordlist.sort_values(by=sort_by, **sort_kwargs) if sort_by is not None else self.wordlist col = wordlist.iloc[:, 0] if self.main_column is None or self.main_column not in self.wordlist.columns \\ else wordlist.loc[:, self.main_column] return [self.apply_case(c) for c in list(col)] def generate_list(self, n: Optional[int] = None, likelihood_column: Optional[Label] = None): if n is None or isinstance(n, int) and n >= len(self.wordlist.index): return self.get() if likelihood_column is not None: likelihood_column = self.wordlist[likelihood_column].values / self.wordlist[likelihood_column].sum() np.random.seed(self._seed) return list(np.random.choice(self.get(), size=n, replace=False, p=likelihood_column)) def filter(self, column: Label, values: Union[Label, List[Label]]): if not isinstance(values, list): values = [values] self.wordlist = self.wordlist[self.wordlist[column].isin(values)] return self def reset(self): self.wordlist = self.__wordlist.copy(deep=True) return self def __len__(self): return len(self.get()) def __getitem__(self, item): return self.get()[item] class WordListGetterMixin: def get(self, *args, **kwargs): return self.wordlist.get(*args, **kwargs) def generate_list(self, *args, **kwargs): return self.wordlist.generate_list(*args, **kwargs) def filter(self, *args, **kwargs): return self.wordlist.filter(*args, **kwargs) def reset(self): return self.wordlist.reset() def __len__(self): return len(self.wordlist)","title":"Module text_sensitivity.data.wordlist"},{"location":"reference/text_sensitivity/data/wordlist/#variables","text":"1 Label","title":"Variables"},{"location":"reference/text_sensitivity/data/wordlist/#classes","text":"","title":"Classes"},{"location":"reference/text_sensitivity/data/wordlist/#wordlist","text":"1 2 3 4 5 class WordList ( wordlist : pandas . core . frame . DataFrame , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 class WordList(Readable, SeedMixin, CaseMixin): def __init__(self, wordlist: pd.DataFrame, main_column: Optional[Label] = None, seed: int = 0): self.wordlist = wordlist self.__wordlist = wordlist.copy(deep=True) self.main_column = main_column self._seed = self._original_seed = seed self._lowercase = self._sentencecase = self._titlecase = self._uppercase = False @classmethod def from_list(cls, wordlist: List[str], name: Label = 'words', seed: int = 0): return cls(pd.DataFrame(wordlist, columns=[name]), seed=seed) @classmethod def from_dictionary(cls, wordlist: Dict, key_name: Label = 'key', value_name: Label = 'value', value_as_main: bool = False, seed: int = 0): main_column = value_name if value_as_main else key_name return cls(pd.DataFrame(wordlist, columns=[key_name, value_name]), main_column=main_column, seed=seed) @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `WordList.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_csv(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_csv(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_json(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_json(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_excel(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_excel(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_pickle(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_pickle(filename, *args, **kwargs), main_column=main_column, seed=seed) @classmethod def from_file(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): import os extension = str.lower(os.path.splitext(filename)[1]) if extension == 'csv': return cls.from_csv(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'json': return cls.from_json(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension in ['xls', 'xlsx']: return cls.from_excel(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'pkl': return cls.from_pickle(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) else: return cls(pd.read_table(filename, main_column=main_column, seed=seed, *args, **kwargs), main_column=main_column) @lru_cache(1) def get(self, sort_by: Optional[Label] = None, **sort_kwargs): wordlist = self.wordlist.sort_values(by=sort_by, **sort_kwargs) if sort_by is not None else self.wordlist col = wordlist.iloc[:, 0] if self.main_column is None or self.main_column not in self.wordlist.columns \\ else wordlist.loc[:, self.main_column] return [self.apply_case(c) for c in list(col)] def generate_list(self, n: Optional[int] = None, likelihood_column: Optional[Label] = None): if n is None or isinstance(n, int) and n >= len(self.wordlist.index): return self.get() if likelihood_column is not None: likelihood_column = self.wordlist[likelihood_column].values / self.wordlist[likelihood_column].sum() np.random.seed(self._seed) return list(np.random.choice(self.get(), size=n, replace=False, p=likelihood_column)) def filter(self, column: Label, values: Union[Label, List[Label]]): if not isinstance(values, list): values = [values] self.wordlist = self.wordlist[self.wordlist[column].isin(values)] return self def reset(self): self.wordlist = self.__wordlist.copy(deep=True) return self def __len__(self): return len(self.get()) def __getitem__(self, item): return self.get()[item]","title":"WordList"},{"location":"reference/text_sensitivity/data/wordlist/#ancestors-in-mro","text":"genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/wordlist/#static-methods","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/data/wordlist/#from_csv","text":"1 2 3 4 5 6 7 def from_csv ( filename : str , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 , * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_csv(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_csv(filename, *args, **kwargs), main_column=main_column, seed=seed)","title":"from_csv"},{"location":"reference/text_sensitivity/data/wordlist/#from_dict","text":"1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for WordList.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `WordList.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs)","title":"from_dict"},{"location":"reference/text_sensitivity/data/wordlist/#from_dictionary","text":"1 2 3 4 5 6 7 def from_dictionary ( wordlist : Dict , key_name : Union [ str , int ] = 'key' , value_name : Union [ str , int ] = 'value' , value_as_main : bool = False , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @classmethod def from_dictionary(cls, wordlist: Dict, key_name: Label = 'key', value_name: Label = 'value', value_as_main: bool = False, seed: int = 0): main_column = value_name if value_as_main else key_name return cls(pd.DataFrame(wordlist, columns=[key_name, value_name]), main_column=main_column, seed=seed)","title":"from_dictionary"},{"location":"reference/text_sensitivity/data/wordlist/#from_excel","text":"1 2 3 4 5 6 7 def from_excel ( filename : str , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 , * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_excel(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_excel(filename, *args, **kwargs), main_column=main_column, seed=seed)","title":"from_excel"},{"location":"reference/text_sensitivity/data/wordlist/#from_file","text":"1 2 3 4 5 6 7 def from_file ( filename : str , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 , * args , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @classmethod def from_file(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): import os extension = str.lower(os.path.splitext(filename)[1]) if extension == 'csv': return cls.from_csv(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'json': return cls.from_json(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension in ['xls', 'xlsx']: return cls.from_excel(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) elif extension == 'pkl': return cls.from_pickle(filename=filename, main_column=main_column, seed=seed, *args, **kwargs) else: return cls(pd.read_table(filename, main_column=main_column, seed=seed, *args, **kwargs), main_column=main_column)","title":"from_file"},{"location":"reference/text_sensitivity/data/wordlist/#from_json","text":"1 2 3 4 5 6 7 def from_json ( filename : str , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 , * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_json(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_json(filename, *args, **kwargs), main_column=main_column, seed=seed)","title":"from_json"},{"location":"reference/text_sensitivity/data/wordlist/#from_list","text":"1 2 3 4 5 def from_list ( wordlist : List [ str ], name : Union [ str , int ] = 'words' , seed : int = 0 ) View Source 1 2 3 4 5 @classmethod def from_list(cls, wordlist: List[str], name: Label = 'words', seed: int = 0): return cls(pd.DataFrame(wordlist, columns=[name]), seed=seed)","title":"from_list"},{"location":"reference/text_sensitivity/data/wordlist/#from_pickle","text":"1 2 3 4 5 6 7 def from_pickle ( filename : str , main_column : Union [ str , int , NoneType ] = None , seed : int = 0 , * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_pickle(cls, filename: str, main_column: Optional[Label] = None, seed: int = 0, *args, **kwargs): return cls(pd.read_pickle(filename, *args, **kwargs), main_column=main_column, seed=seed)","title":"from_pickle"},{"location":"reference/text_sensitivity/data/wordlist/#instance-variables","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/wordlist/#methods","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/wordlist/#apply_case","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/wordlist/#filter","text":"1 2 3 4 5 def filter ( self , column : Union [ str , int ], values : Union [ str , int , List [ Union [ str , int ]]] ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def filter(self, column: Label, values: Union[Label, List[Label]]): if not isinstance(values, list): values = [values] self.wordlist = self.wordlist[self.wordlist[column].isin(values)] return self","title":"filter"},{"location":"reference/text_sensitivity/data/wordlist/#generate_list","text":"1 2 3 4 5 def generate_list ( self , n : Optional [ int ] = None , likelihood_column : Union [ str , int , NoneType ] = None ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def generate_list(self, n: Optional[int] = None, likelihood_column: Optional[Label] = None): if n is None or isinstance(n, int) and n >= len(self.wordlist.index): return self.get() if likelihood_column is not None: likelihood_column = self.wordlist[likelihood_column].values / self.wordlist[likelihood_column].sum() np.random.seed(self._seed) return list(np.random.choice(self.get(), size=n, replace=False, p=likelihood_column))","title":"generate_list"},{"location":"reference/text_sensitivity/data/wordlist/#get","text":"1 2 3 4 5 def get ( self , sort_by : Union [ str , int , NoneType ] = None , ** sort_kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @lru_cache(1) def get(self, sort_by: Optional[Label] = None, **sort_kwargs): wordlist = self.wordlist.sort_values(by=sort_by, **sort_kwargs) if sort_by is not None else self.wordlist col = wordlist.iloc[:, 0] if self.main_column is None or self.main_column not in self.wordlist.columns \\ else wordlist.loc[:, self.main_column] return [self.apply_case(c) for c in list(col)]","title":"get"},{"location":"reference/text_sensitivity/data/wordlist/#lower","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/wordlist/#original","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/wordlist/#reset","text":"1 2 3 def reset ( self ) View Source 1 2 3 4 5 def reset(self): self.wordlist = self.__wordlist.copy(deep=True) return self","title":"reset"},{"location":"reference/text_sensitivity/data/wordlist/#reset_seed","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/wordlist/#sentence","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/wordlist/#set_seed","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/wordlist/#title","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/wordlist/#upper","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/wordlist/#wordlistgettermixin","text":"1 2 3 4 5 class WordListGetterMixin ( / , * args , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class WordListGetterMixin: def get(self, *args, **kwargs): return self.wordlist.get(*args, **kwargs) def generate_list(self, *args, **kwargs): return self.wordlist.generate_list(*args, **kwargs) def filter(self, *args, **kwargs): return self.wordlist.filter(*args, **kwargs) def reset(self): return self.wordlist.reset() def __len__(self): return len(self.wordlist)","title":"WordListGetterMixin"},{"location":"reference/text_sensitivity/data/wordlist/#methods_1","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/wordlist/#filter_1","text":"1 2 3 4 5 def filter ( self , * args , ** kwargs ) View Source 1 2 3 def filter(self, *args, **kwargs): return self.wordlist.filter(*args, **kwargs)","title":"filter"},{"location":"reference/text_sensitivity/data/wordlist/#generate_list_1","text":"1 2 3 4 5 def generate_list ( self , * args , ** kwargs ) View Source 1 2 3 def generate_list(self, *args, **kwargs): return self.wordlist.generate_list(*args, **kwargs)","title":"generate_list"},{"location":"reference/text_sensitivity/data/wordlist/#get_1","text":"1 2 3 4 5 def get ( self , * args , ** kwargs ) View Source 1 2 3 def get(self, *args, **kwargs): return self.wordlist.get(*args, **kwargs)","title":"get"},{"location":"reference/text_sensitivity/data/wordlist/#reset_1","text":"1 2 3 def reset ( self ) View Source 1 2 3 def reset(self): return self.wordlist.reset()","title":"reset"},{"location":"reference/text_sensitivity/data/random/","text":"Module text_sensitivity.data.random Generate random data for robustness and sensitivity testing. None View Source 1 \"\"\"Generate random data for robustness and sensitivity testing.\"\"\" Sub-modules text_sensitivity.data.random.entity text_sensitivity.data.random.string","title":"Index"},{"location":"reference/text_sensitivity/data/random/#module-text_sensitivitydatarandom","text":"Generate random data for robustness and sensitivity testing. None View Source 1 \"\"\"Generate random data for robustness and sensitivity testing.\"\"\"","title":"Module text_sensitivity.data.random"},{"location":"reference/text_sensitivity/data/random/#sub-modules","text":"text_sensitivity.data.random.entity text_sensitivity.data.random.string","title":"Sub-modules"},{"location":"reference/text_sensitivity/data/random/entity/","text":"Module text_sensitivity.data.random.entity None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 from typing import Callable, Dict, List, Optional, Tuple, Union import numpy as np from faker.factory import Factory from faker.generator import Generator from genbase import LOCALE_MAP, CaseMixin, Readable, SeedMixin, get_locale from instancelib.instances.text import TextInstanceProvider from instancelib.labels.memory import MemoryLabelProvider class RandomEntity(Readable, SeedMixin, CaseMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), providers: List[str] = ['person'], fn_name: Union[str, List[str]] = 'name', attribute: str = 'fn', attribute_rename: Optional[Callable[[str], str]] = None, sep: str = '\\n', seed: int = 0): \"\"\"Base class to generate entity data for (a) given language(s). Args: languages (Union[str, List[str]], optional): .... Defaults to your current locale (see `get_locale()`). providers (List[str], optional): Providers from `faker` used in generation. Defaults to ['person']. fn_name (Union[str, List[str]], optional): Function name(s) to call for each generator. Defaults to 'name'. attribute (str, optional): Name of additional attribute (other than language). Defaults to 'fn'. attribute_rename (Optional[Callable[[str], str]], optional): Rename function for attribute value. Defaults to None. sep (str, optional): Separator to replace '\\n' character with. Defaults to '\\n'. seed (int, optional): Seed for reproducibility. Defaults to 0. \"\"\" self.languages = [languages] if isinstance(languages, str) else languages self.providers = [f'faker.providers.{provider}' if not provider.startswith('faker.providers.') else provider for provider in providers] self.generators = {lang: Factory.create(LOCALE_MAP[lang] if lang in LOCALE_MAP.keys() else lang, self.providers, Generator(), None) for lang in self.languages} self.attribute = attribute if attribute_rename is None: self.attribute_rename = lambda x: x else: self.attribute_rename = attribute_rename self.sep = sep self.fn_name = fn_name if isinstance(fn_name, list) else [fn_name] self._original_seed = self._seed = seed self._lowercase = self._sentencecase = self._titlecase = self._uppercase = False def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values class CityByPopulationMixin(Readable): @staticmethod def cities_by_population(cities: List[str], country_code: str): \"\"\"Add population scores to each city in a country. Args: cities (List[str]): Current list of cities. If no replacement is found, this will be returned back. country_code (str): Two-letter country code (e.g. 'nl'). \"\"\" country_code = country_code.split('_')[-1] if '_' in country_code else country_code import json import os from collections import OrderedDict import pandas as pd import requests res = [] file = os.path.abspath(__file__ + f'/../../lists/cities_by_population_{country_code}.csv') if os.path.isfile(file): # already exists, using cached file res = pd.read_csv(file, header=None).values.tolist() else: # try and get a new one from the internet try: response = requests.get('https://public.opendatasoft.com/api/records/1.0/search/' + '?dataset=geonames-all-cities-with-a-population-1000&q=' + f'&lang={str.lower(country_code)}&fields=name,population&sort=population' + f'&refine.country_code={str.upper(country_code)}&rows={len(cities)}') if response.status_code != 200: return cities res = [(city['fields']['name'], float(city['fields']['population'])) for city in json.loads(response.content)['records']] pd.DataFrame(res).to_csv(file, index=False, header=None) except Exception as e: print(e) return cities return OrderedDict(res) if len(res) > 0 else cities def add_likelihood_to_cities(self): for lang, generator in self.generators.items(): if hasattr(generator.provider('faker.providers.address'), 'cities'): generator.provider('faker.providers.address').cities = CityByPopulationMixin.cities_by_population( cities=generator.provider('faker.providers.address').cities, country_code=lang) class RandomAddress(RandomEntity, CityByPopulationMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), likelihood_based_on_city_population: bool = True, sep: str = '\\n', seed: int = 0): \"\"\"Generate random cities in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address', 'person'], fn_name='address', sep=sep, seed=seed) if likelihood_based_on_city_population: self.add_likelihood_to_cities() class RandomCity(RandomEntity, CityByPopulationMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), likelihood_based_on_city_population: bool = True, seed: int = 0): \"\"\"Generate random cities in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address'], fn_name='city', seed=seed) if likelihood_based_on_city_population: self.add_likelihood_to_cities() class RandomCountry(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random countries for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address'], fn_name='country', seed=seed) class RandomName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), sex: List[str] = ['male', 'female'], seed: int = 0): \"\"\"Generate random full names for (a) given language(s).\"\"\" if isinstance(sex, str): sex = [sex] super().__init__(languages=languages, providers=['person'], fn_name=[f'name_{s}' for s in sex], attribute='sex', attribute_rename=lambda x: str(x).replace('name_', ''), seed=seed) class RandomFirstName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), sex: List[str] = ['male', 'female'], seed: int = 0): \"\"\"Generate random first names for (a) given language(s).\"\"\" if isinstance(sex, str): sex = [sex] super().__init__(languages=languages, providers=['person'], fn_name=[f'first_name_{s}' for s in sex], attribute='sex', attribute_rename=lambda x: str(x).replace('name_', ''), seed=seed) class RandomLastName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random last names for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['person'], fn_name='last_name', seed=seed) class RandomEmail(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random e-mail addresses for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['person', 'company', 'internet'], fn_name='email', seed=seed) class RandomPhoneNumber(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random phone numbers for (a) given language(s) / country.\"\"\" super().__init__(languages=languages, providers=['phone_number'], fn_name='phone_number', seed=seed) class RandomYear(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random year.\"\"\" super().__init__(languages='en', providers=['date_time'], fn_name='year', seed=seed) class RandomMonth(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random month name in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['date_time'], fn_name='month_name', seed=seed) class RandomDay(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random day of the month.\"\"\" super().__init__(languages='en', providers=['date_time'], fn_name='day_of_month', seed=seed) class RandomDayOfWeek(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random day of week in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['date_time'], fn_name='day_of_week', seed=seed) class RandomPriceTag(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random pricetag names in (a) given languages' currency.\"\"\" super().__init__(languages=languages, providers=['currency'], fn_name='pricetag', seed=seed) class RandomCurrencySymbol(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random currency symbols.\"\"\" super().__init__(languages='en', providers=['currency'], fn_name='currency_symbol', seed=seed) class RandomCryptoCurrency(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random cryptocurrency names.\"\"\" super().__init__(languages='en', providers=['currency'], fn_name='cryptocurrency_name', seed=seed) class RandomLicensePlate(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random license plates for a given country.\"\"\" super().__init__(languages='en', providers=['automotive'], fn_name='license_plate', seed=seed) Variables 1 LOCALE_MAP Classes CityByPopulationMixin 1 2 3 4 5 class CityByPopulationMixin ( / , * args , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 class CityByPopulationMixin(Readable): @staticmethod def cities_by_population(cities: List[str], country_code: str): \"\"\"Add population scores to each city in a country. Args: cities (List[str]): Current list of cities. If no replacement is found, this will be returned back. country_code (str): Two-letter country code (e.g. 'nl'). \"\"\" country_code = country_code.split('_')[-1] if '_' in country_code else country_code import json import os from collections import OrderedDict import pandas as pd import requests res = [] file = os.path.abspath(__file__ + f'/../../lists/cities_by_population_{country_code}.csv') if os.path.isfile(file): # already exists, using cached file res = pd.read_csv(file, header=None).values.tolist() else: # try and get a new one from the internet try: response = requests.get('https://public.opendatasoft.com/api/records/1.0/search/' + '?dataset=geonames-all-cities-with-a-population-1000&q=' + f'&lang={str.lower(country_code)}&fields=name,population&sort=population' + f'&refine.country_code={str.upper(country_code)}&rows={len(cities)}') if response.status_code != 200: return cities res = [(city['fields']['name'], float(city['fields']['population'])) for city in json.loads(response.content)['records']] pd.DataFrame(res).to_csv(file, index=False, header=None) except Exception as e: print(e) return cities return OrderedDict(res) if len(res) > 0 else cities def add_likelihood_to_cities(self): for lang, generator in self.generators.items(): if hasattr(generator.provider('faker.providers.address'), 'cities'): generator.provider('faker.providers.address').cities = CityByPopulationMixin.cities_by_population( cities=generator.provider('faker.providers.address').cities, country_code=lang) Ancestors (in MRO) genbase.Readable Descendants text_sensitivity.data.random.entity.RandomAddress text_sensitivity.data.random.entity.RandomCity Static methods cities_by_population 1 2 3 4 def cities_by_population ( cities : List [ str ], country_code : str ) Add population scores to each city in a country. Parameters: Name Type Description Default cities List[str] Current list of cities. If no replacement is found, this will be returned back. None country_code str Two-letter country code (e.g. 'nl'). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @staticmethod def cities_by_population(cities: List[str], country_code: str): \"\"\"Add population scores to each city in a country. Args: cities (List[str]): Current list of cities. If no replacement is found, this will be returned back. country_code (str): Two-letter country code (e.g. 'nl'). \"\"\" country_code = country_code.split('_')[-1] if '_' in country_code else country_code import json import os from collections import OrderedDict import pandas as pd import requests res = [] file = os.path.abspath(__file__ + f'/../../lists/cities_by_population_{country_code}.csv') if os.path.isfile(file): # already exists, using cached file res = pd.read_csv(file, header=None).values.tolist() else: # try and get a new one from the internet try: response = requests.get('https://public.opendatasoft.com/api/records/1.0/search/' + '?dataset=geonames-all-cities-with-a-population-1000&q=' + f'&lang={str.lower(country_code)}&fields=name,population&sort=population' + f'&refine.country_code={str.upper(country_code)}&rows={len(cities)}') if response.status_code != 200: return cities res = [(city['fields']['name'], float(city['fields']['population'])) for city in json.loads(response.content)['records']] pd.DataFrame(res).to_csv(file, index=False, header=None) except Exception as e: print(e) return cities return OrderedDict(res) if len(res) > 0 else cities Methods add_likelihood_to_cities 1 2 3 def add_likelihood_to_cities ( self ) View Source 1 2 3 4 5 6 7 8 9 10 11 def add_likelihood_to_cities(self): for lang, generator in self.generators.items(): if hasattr(generator.provider('faker.providers.address'), 'cities'): generator.provider('faker.providers.address').cities = CityByPopulationMixin.cities_by_population( cities=generator.provider('faker.providers.address').cities, country_code=lang) RandomAddress 1 2 3 4 5 6 class RandomAddress ( languages : Union [ str , List [ str ]] = 'nl' , likelihood_based_on_city_population : bool = True , sep : str = ' \\n ' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class RandomAddress(RandomEntity, CityByPopulationMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), likelihood_based_on_city_population: bool = True, sep: str = '\\n', seed: int = 0): \"\"\"Generate random cities in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address', 'person'], fn_name='address', sep=sep, seed=seed) if likelihood_based_on_city_population: self.add_likelihood_to_cities() Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity text_sensitivity.data.random.entity.CityByPopulationMixin genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Static methods cities_by_population 1 2 3 4 def cities_by_population ( cities : List [ str ], country_code : str ) Add population scores to each city in a country. Parameters: Name Type Description Default cities List[str] Current list of cities. If no replacement is found, this will be returned back. None country_code str Two-letter country code (e.g. 'nl'). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @staticmethod def cities_by_population(cities: List[str], country_code: str): \"\"\"Add population scores to each city in a country. Args: cities (List[str]): Current list of cities. If no replacement is found, this will be returned back. country_code (str): Two-letter country code (e.g. 'nl'). \"\"\" country_code = country_code.split('_')[-1] if '_' in country_code else country_code import json import os from collections import OrderedDict import pandas as pd import requests res = [] file = os.path.abspath(__file__ + f'/../../lists/cities_by_population_{country_code}.csv') if os.path.isfile(file): # already exists, using cached file res = pd.read_csv(file, header=None).values.tolist() else: # try and get a new one from the internet try: response = requests.get('https://public.opendatasoft.com/api/records/1.0/search/' + '?dataset=geonames-all-cities-with-a-population-1000&q=' + f'&lang={str.lower(country_code)}&fields=name,population&sort=population' + f'&refine.country_code={str.upper(country_code)}&rows={len(cities)}') if response.status_code != 200: return cities res = [(city['fields']['name'], float(city['fields']['population'])) for city in json.loads(response.content)['records']] pd.DataFrame(res).to_csv(file, index=False, header=None) except Exception as e: print(e) return cities return OrderedDict(res) if len(res) > 0 else cities Instance variables 1 seed Methods add_likelihood_to_cities 1 2 3 def add_likelihood_to_cities ( self ) View Source 1 2 3 4 5 6 7 8 9 10 11 def add_likelihood_to_cities(self): for lang, generator in self.generators.items(): if hasattr(generator.provider('faker.providers.address'), 'cities'): generator.provider('faker.providers.address').cities = CityByPopulationMixin.cities_by_population( cities=generator.provider('faker.providers.address').cities, country_code=lang) apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomCity 1 2 3 4 5 class RandomCity ( languages : Union [ str , List [ str ]] = 'nl' , likelihood_based_on_city_population : bool = True , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class RandomCity(RandomEntity, CityByPopulationMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), likelihood_based_on_city_population: bool = True, seed: int = 0): \"\"\"Generate random cities in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address'], fn_name='city', seed=seed) if likelihood_based_on_city_population: self.add_likelihood_to_cities() Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity text_sensitivity.data.random.entity.CityByPopulationMixin genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Static methods cities_by_population 1 2 3 4 def cities_by_population ( cities : List [ str ], country_code : str ) Add population scores to each city in a country. Parameters: Name Type Description Default cities List[str] Current list of cities. If no replacement is found, this will be returned back. None country_code str Two-letter country code (e.g. 'nl'). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @staticmethod def cities_by_population(cities: List[str], country_code: str): \"\"\"Add population scores to each city in a country. Args: cities (List[str]): Current list of cities. If no replacement is found, this will be returned back. country_code (str): Two-letter country code (e.g. 'nl'). \"\"\" country_code = country_code.split('_')[-1] if '_' in country_code else country_code import json import os from collections import OrderedDict import pandas as pd import requests res = [] file = os.path.abspath(__file__ + f'/../../lists/cities_by_population_{country_code}.csv') if os.path.isfile(file): # already exists, using cached file res = pd.read_csv(file, header=None).values.tolist() else: # try and get a new one from the internet try: response = requests.get('https://public.opendatasoft.com/api/records/1.0/search/' + '?dataset=geonames-all-cities-with-a-population-1000&q=' + f'&lang={str.lower(country_code)}&fields=name,population&sort=population' + f'&refine.country_code={str.upper(country_code)}&rows={len(cities)}') if response.status_code != 200: return cities res = [(city['fields']['name'], float(city['fields']['population'])) for city in json.loads(response.content)['records']] pd.DataFrame(res).to_csv(file, index=False, header=None) except Exception as e: print(e) return cities return OrderedDict(res) if len(res) > 0 else cities Instance variables 1 seed Methods add_likelihood_to_cities 1 2 3 def add_likelihood_to_cities ( self ) View Source 1 2 3 4 5 6 7 8 9 10 11 def add_likelihood_to_cities(self): for lang, generator in self.generators.items(): if hasattr(generator.provider('faker.providers.address'), 'cities'): generator.provider('faker.providers.address').cities = CityByPopulationMixin.cities_by_population( cities=generator.provider('faker.providers.address').cities, country_code=lang) apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomCountry 1 2 3 4 class RandomCountry ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomCountry(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random countries for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address'], fn_name='country', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomCryptoCurrency 1 2 3 class RandomCryptoCurrency ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RandomCryptoCurrency(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random cryptocurrency names.\"\"\" super().__init__(languages='en', providers=['currency'], fn_name='cryptocurrency_name', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomCurrencySymbol 1 2 3 class RandomCurrencySymbol ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RandomCurrencySymbol(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random currency symbols.\"\"\" super().__init__(languages='en', providers=['currency'], fn_name='currency_symbol', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomDay 1 2 3 class RandomDay ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RandomDay(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random day of the month.\"\"\" super().__init__(languages='en', providers=['date_time'], fn_name='day_of_month', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomDayOfWeek 1 2 3 4 class RandomDayOfWeek ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomDayOfWeek(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random day of week in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['date_time'], fn_name='day_of_week', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomEmail 1 2 3 4 class RandomEmail ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomEmail(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random e-mail addresses for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['person', 'company', 'internet'], fn_name='email', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomEntity 1 2 3 4 5 6 7 8 9 class RandomEntity ( languages : Union [ str , List [ str ]] = 'nl' , providers : List [ str ] = [ 'person' ], fn_name : Union [ str , List [ str ]] = 'name' , attribute : str = 'fn' , attribute_rename : Optional [ Callable [[ str ], str ]] = None , sep : str = ' \\n ' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 class RandomEntity(Readable, SeedMixin, CaseMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), providers: List[str] = ['person'], fn_name: Union[str, List[str]] = 'name', attribute: str = 'fn', attribute_rename: Optional[Callable[[str], str]] = None, sep: str = '\\n', seed: int = 0): \"\"\"Base class to generate entity data for (a) given language(s). Args: languages (Union[str, List[str]], optional): .... Defaults to your current locale (see `get_locale()`). providers (List[str], optional): Providers from `faker` used in generation. Defaults to ['person']. fn_name (Union[str, List[str]], optional): Function name(s) to call for each generator. Defaults to 'name'. attribute (str, optional): Name of additional attribute (other than language). Defaults to 'fn'. attribute_rename (Optional[Callable[[str], str]], optional): Rename function for attribute value. Defaults to None. sep (str, optional): Separator to replace '\\n' character with. Defaults to '\\n'. seed (int, optional): Seed for reproducibility. Defaults to 0. \"\"\" self.languages = [languages] if isinstance(languages, str) else languages self.providers = [f'faker.providers.{provider}' if not provider.startswith('faker.providers.') else provider for provider in providers] self.generators = {lang: Factory.create(LOCALE_MAP[lang] if lang in LOCALE_MAP.keys() else lang, self.providers, Generator(), None) for lang in self.languages} self.attribute = attribute if attribute_rename is None: self.attribute_rename = lambda x: x else: self.attribute_rename = attribute_rename self.sep = sep self.fn_name = fn_name if isinstance(fn_name, list) else [fn_name] self._original_seed = self._seed = seed self._lowercase = self._sentencecase = self._titlecase = self._uppercase = False def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values Ancestors (in MRO) genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Descendants text_sensitivity.data.random.entity.RandomAddress text_sensitivity.data.random.entity.RandomCity text_sensitivity.data.random.entity.RandomCountry text_sensitivity.data.random.entity.RandomName text_sensitivity.data.random.entity.RandomFirstName text_sensitivity.data.random.entity.RandomLastName text_sensitivity.data.random.entity.RandomEmail text_sensitivity.data.random.entity.RandomPhoneNumber text_sensitivity.data.random.entity.RandomYear text_sensitivity.data.random.entity.RandomMonth text_sensitivity.data.random.entity.RandomDay text_sensitivity.data.random.entity.RandomDayOfWeek text_sensitivity.data.random.entity.RandomPriceTag text_sensitivity.data.random.entity.RandomCurrencySymbol text_sensitivity.data.random.entity.RandomCryptoCurrency text_sensitivity.data.random.entity.RandomLicensePlate Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomFirstName 1 2 3 4 5 class RandomFirstName ( languages : Union [ str , List [ str ]] = 'nl' , sex : List [ str ] = [ 'male' , 'female' ], seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class RandomFirstName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), sex: List[str] = ['male', 'female'], seed: int = 0): \"\"\"Generate random first names for (a) given language(s).\"\"\" if isinstance(sex, str): sex = [sex] super().__init__(languages=languages, providers=['person'], fn_name=[f'first_name_{s}' for s in sex], attribute='sex', attribute_rename=lambda x: str(x).replace('name_', ''), seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomLastName 1 2 3 4 class RandomLastName ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomLastName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random last names for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['person'], fn_name='last_name', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomLicensePlate 1 2 3 class RandomLicensePlate ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RandomLicensePlate(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random license plates for a given country.\"\"\" super().__init__(languages='en', providers=['automotive'], fn_name='license_plate', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomMonth 1 2 3 4 class RandomMonth ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomMonth(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random month name in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['date_time'], fn_name='month_name', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomName 1 2 3 4 5 class RandomName ( languages : Union [ str , List [ str ]] = 'nl' , sex : List [ str ] = [ 'male' , 'female' ], seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class RandomName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), sex: List[str] = ['male', 'female'], seed: int = 0): \"\"\"Generate random full names for (a) given language(s).\"\"\" if isinstance(sex, str): sex = [sex] super().__init__(languages=languages, providers=['person'], fn_name=[f'name_{s}' for s in sex], attribute='sex', attribute_rename=lambda x: str(x).replace('name_', ''), seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomPhoneNumber 1 2 3 4 class RandomPhoneNumber ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomPhoneNumber(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random phone numbers for (a) given language(s) / country.\"\"\" super().__init__(languages=languages, providers=['phone_number'], fn_name='phone_number', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomPriceTag 1 2 3 4 class RandomPriceTag ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomPriceTag(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random pricetag names in (a) given languages' currency.\"\"\" super().__init__(languages=languages, providers=['currency'], fn_name='pricetag', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self RandomYear 1 2 3 class RandomYear ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RandomYear(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random year.\"\"\" super().__init__(languages='en', providers=['date_time'], fn_name='year', seed=seed) Ancestors (in MRO) text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin Instance variables 1 seed Methods apply_case 1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string generate 1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values generate_list 1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) lower 1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self original 1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self sentence 1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() title 1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self upper 1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"Entity"},{"location":"reference/text_sensitivity/data/random/entity/#module-text_sensitivitydatarandomentity","text":"None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 from typing import Callable, Dict, List, Optional, Tuple, Union import numpy as np from faker.factory import Factory from faker.generator import Generator from genbase import LOCALE_MAP, CaseMixin, Readable, SeedMixin, get_locale from instancelib.instances.text import TextInstanceProvider from instancelib.labels.memory import MemoryLabelProvider class RandomEntity(Readable, SeedMixin, CaseMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), providers: List[str] = ['person'], fn_name: Union[str, List[str]] = 'name', attribute: str = 'fn', attribute_rename: Optional[Callable[[str], str]] = None, sep: str = '\\n', seed: int = 0): \"\"\"Base class to generate entity data for (a) given language(s). Args: languages (Union[str, List[str]], optional): .... Defaults to your current locale (see `get_locale()`). providers (List[str], optional): Providers from `faker` used in generation. Defaults to ['person']. fn_name (Union[str, List[str]], optional): Function name(s) to call for each generator. Defaults to 'name'. attribute (str, optional): Name of additional attribute (other than language). Defaults to 'fn'. attribute_rename (Optional[Callable[[str], str]], optional): Rename function for attribute value. Defaults to None. sep (str, optional): Separator to replace '\\n' character with. Defaults to '\\n'. seed (int, optional): Seed for reproducibility. Defaults to 0. \"\"\" self.languages = [languages] if isinstance(languages, str) else languages self.providers = [f'faker.providers.{provider}' if not provider.startswith('faker.providers.') else provider for provider in providers] self.generators = {lang: Factory.create(LOCALE_MAP[lang] if lang in LOCALE_MAP.keys() else lang, self.providers, Generator(), None) for lang in self.languages} self.attribute = attribute if attribute_rename is None: self.attribute_rename = lambda x: x else: self.attribute_rename = attribute_rename self.sep = sep self.fn_name = fn_name if isinstance(fn_name, list) else [fn_name] self._original_seed = self._seed = seed self._lowercase = self._sentencecase = self._titlecase = self._uppercase = False def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values class CityByPopulationMixin(Readable): @staticmethod def cities_by_population(cities: List[str], country_code: str): \"\"\"Add population scores to each city in a country. Args: cities (List[str]): Current list of cities. If no replacement is found, this will be returned back. country_code (str): Two-letter country code (e.g. 'nl'). \"\"\" country_code = country_code.split('_')[-1] if '_' in country_code else country_code import json import os from collections import OrderedDict import pandas as pd import requests res = [] file = os.path.abspath(__file__ + f'/../../lists/cities_by_population_{country_code}.csv') if os.path.isfile(file): # already exists, using cached file res = pd.read_csv(file, header=None).values.tolist() else: # try and get a new one from the internet try: response = requests.get('https://public.opendatasoft.com/api/records/1.0/search/' + '?dataset=geonames-all-cities-with-a-population-1000&q=' + f'&lang={str.lower(country_code)}&fields=name,population&sort=population' + f'&refine.country_code={str.upper(country_code)}&rows={len(cities)}') if response.status_code != 200: return cities res = [(city['fields']['name'], float(city['fields']['population'])) for city in json.loads(response.content)['records']] pd.DataFrame(res).to_csv(file, index=False, header=None) except Exception as e: print(e) return cities return OrderedDict(res) if len(res) > 0 else cities def add_likelihood_to_cities(self): for lang, generator in self.generators.items(): if hasattr(generator.provider('faker.providers.address'), 'cities'): generator.provider('faker.providers.address').cities = CityByPopulationMixin.cities_by_population( cities=generator.provider('faker.providers.address').cities, country_code=lang) class RandomAddress(RandomEntity, CityByPopulationMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), likelihood_based_on_city_population: bool = True, sep: str = '\\n', seed: int = 0): \"\"\"Generate random cities in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address', 'person'], fn_name='address', sep=sep, seed=seed) if likelihood_based_on_city_population: self.add_likelihood_to_cities() class RandomCity(RandomEntity, CityByPopulationMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), likelihood_based_on_city_population: bool = True, seed: int = 0): \"\"\"Generate random cities in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address'], fn_name='city', seed=seed) if likelihood_based_on_city_population: self.add_likelihood_to_cities() class RandomCountry(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random countries for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address'], fn_name='country', seed=seed) class RandomName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), sex: List[str] = ['male', 'female'], seed: int = 0): \"\"\"Generate random full names for (a) given language(s).\"\"\" if isinstance(sex, str): sex = [sex] super().__init__(languages=languages, providers=['person'], fn_name=[f'name_{s}' for s in sex], attribute='sex', attribute_rename=lambda x: str(x).replace('name_', ''), seed=seed) class RandomFirstName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), sex: List[str] = ['male', 'female'], seed: int = 0): \"\"\"Generate random first names for (a) given language(s).\"\"\" if isinstance(sex, str): sex = [sex] super().__init__(languages=languages, providers=['person'], fn_name=[f'first_name_{s}' for s in sex], attribute='sex', attribute_rename=lambda x: str(x).replace('name_', ''), seed=seed) class RandomLastName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random last names for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['person'], fn_name='last_name', seed=seed) class RandomEmail(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random e-mail addresses for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['person', 'company', 'internet'], fn_name='email', seed=seed) class RandomPhoneNumber(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random phone numbers for (a) given language(s) / country.\"\"\" super().__init__(languages=languages, providers=['phone_number'], fn_name='phone_number', seed=seed) class RandomYear(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random year.\"\"\" super().__init__(languages='en', providers=['date_time'], fn_name='year', seed=seed) class RandomMonth(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random month name in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['date_time'], fn_name='month_name', seed=seed) class RandomDay(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random day of the month.\"\"\" super().__init__(languages='en', providers=['date_time'], fn_name='day_of_month', seed=seed) class RandomDayOfWeek(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random day of week in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['date_time'], fn_name='day_of_week', seed=seed) class RandomPriceTag(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random pricetag names in (a) given languages' currency.\"\"\" super().__init__(languages=languages, providers=['currency'], fn_name='pricetag', seed=seed) class RandomCurrencySymbol(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random currency symbols.\"\"\" super().__init__(languages='en', providers=['currency'], fn_name='currency_symbol', seed=seed) class RandomCryptoCurrency(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random cryptocurrency names.\"\"\" super().__init__(languages='en', providers=['currency'], fn_name='cryptocurrency_name', seed=seed) class RandomLicensePlate(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random license plates for a given country.\"\"\" super().__init__(languages='en', providers=['automotive'], fn_name='license_plate', seed=seed)","title":"Module text_sensitivity.data.random.entity"},{"location":"reference/text_sensitivity/data/random/entity/#variables","text":"1 LOCALE_MAP","title":"Variables"},{"location":"reference/text_sensitivity/data/random/entity/#classes","text":"","title":"Classes"},{"location":"reference/text_sensitivity/data/random/entity/#citybypopulationmixin","text":"1 2 3 4 5 class CityByPopulationMixin ( / , * args , ** kwargs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 class CityByPopulationMixin(Readable): @staticmethod def cities_by_population(cities: List[str], country_code: str): \"\"\"Add population scores to each city in a country. Args: cities (List[str]): Current list of cities. If no replacement is found, this will be returned back. country_code (str): Two-letter country code (e.g. 'nl'). \"\"\" country_code = country_code.split('_')[-1] if '_' in country_code else country_code import json import os from collections import OrderedDict import pandas as pd import requests res = [] file = os.path.abspath(__file__ + f'/../../lists/cities_by_population_{country_code}.csv') if os.path.isfile(file): # already exists, using cached file res = pd.read_csv(file, header=None).values.tolist() else: # try and get a new one from the internet try: response = requests.get('https://public.opendatasoft.com/api/records/1.0/search/' + '?dataset=geonames-all-cities-with-a-population-1000&q=' + f'&lang={str.lower(country_code)}&fields=name,population&sort=population' + f'&refine.country_code={str.upper(country_code)}&rows={len(cities)}') if response.status_code != 200: return cities res = [(city['fields']['name'], float(city['fields']['population'])) for city in json.loads(response.content)['records']] pd.DataFrame(res).to_csv(file, index=False, header=None) except Exception as e: print(e) return cities return OrderedDict(res) if len(res) > 0 else cities def add_likelihood_to_cities(self): for lang, generator in self.generators.items(): if hasattr(generator.provider('faker.providers.address'), 'cities'): generator.provider('faker.providers.address').cities = CityByPopulationMixin.cities_by_population( cities=generator.provider('faker.providers.address').cities, country_code=lang)","title":"CityByPopulationMixin"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro","text":"genbase.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#descendants","text":"text_sensitivity.data.random.entity.RandomAddress text_sensitivity.data.random.entity.RandomCity","title":"Descendants"},{"location":"reference/text_sensitivity/data/random/entity/#static-methods","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/data/random/entity/#cities_by_population","text":"1 2 3 4 def cities_by_population ( cities : List [ str ], country_code : str ) Add population scores to each city in a country. Parameters: Name Type Description Default cities List[str] Current list of cities. If no replacement is found, this will be returned back. None country_code str Two-letter country code (e.g. 'nl'). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @staticmethod def cities_by_population(cities: List[str], country_code: str): \"\"\"Add population scores to each city in a country. Args: cities (List[str]): Current list of cities. If no replacement is found, this will be returned back. country_code (str): Two-letter country code (e.g. 'nl'). \"\"\" country_code = country_code.split('_')[-1] if '_' in country_code else country_code import json import os from collections import OrderedDict import pandas as pd import requests res = [] file = os.path.abspath(__file__ + f'/../../lists/cities_by_population_{country_code}.csv') if os.path.isfile(file): # already exists, using cached file res = pd.read_csv(file, header=None).values.tolist() else: # try and get a new one from the internet try: response = requests.get('https://public.opendatasoft.com/api/records/1.0/search/' + '?dataset=geonames-all-cities-with-a-population-1000&q=' + f'&lang={str.lower(country_code)}&fields=name,population&sort=population' + f'&refine.country_code={str.upper(country_code)}&rows={len(cities)}') if response.status_code != 200: return cities res = [(city['fields']['name'], float(city['fields']['population'])) for city in json.loads(response.content)['records']] pd.DataFrame(res).to_csv(file, index=False, header=None) except Exception as e: print(e) return cities return OrderedDict(res) if len(res) > 0 else cities","title":"cities_by_population"},{"location":"reference/text_sensitivity/data/random/entity/#methods","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#add_likelihood_to_cities","text":"1 2 3 def add_likelihood_to_cities ( self ) View Source 1 2 3 4 5 6 7 8 9 10 11 def add_likelihood_to_cities(self): for lang, generator in self.generators.items(): if hasattr(generator.provider('faker.providers.address'), 'cities'): generator.provider('faker.providers.address').cities = CityByPopulationMixin.cities_by_population( cities=generator.provider('faker.providers.address').cities, country_code=lang)","title":"add_likelihood_to_cities"},{"location":"reference/text_sensitivity/data/random/entity/#randomaddress","text":"1 2 3 4 5 6 class RandomAddress ( languages : Union [ str , List [ str ]] = 'nl' , likelihood_based_on_city_population : bool = True , sep : str = ' \\n ' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class RandomAddress(RandomEntity, CityByPopulationMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), likelihood_based_on_city_population: bool = True, sep: str = '\\n', seed: int = 0): \"\"\"Generate random cities in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address', 'person'], fn_name='address', sep=sep, seed=seed) if likelihood_based_on_city_population: self.add_likelihood_to_cities()","title":"RandomAddress"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_1","text":"text_sensitivity.data.random.entity.RandomEntity text_sensitivity.data.random.entity.CityByPopulationMixin genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/data/random/entity/#cities_by_population_1","text":"1 2 3 4 def cities_by_population ( cities : List [ str ], country_code : str ) Add population scores to each city in a country. Parameters: Name Type Description Default cities List[str] Current list of cities. If no replacement is found, this will be returned back. None country_code str Two-letter country code (e.g. 'nl'). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @staticmethod def cities_by_population(cities: List[str], country_code: str): \"\"\"Add population scores to each city in a country. Args: cities (List[str]): Current list of cities. If no replacement is found, this will be returned back. country_code (str): Two-letter country code (e.g. 'nl'). \"\"\" country_code = country_code.split('_')[-1] if '_' in country_code else country_code import json import os from collections import OrderedDict import pandas as pd import requests res = [] file = os.path.abspath(__file__ + f'/../../lists/cities_by_population_{country_code}.csv') if os.path.isfile(file): # already exists, using cached file res = pd.read_csv(file, header=None).values.tolist() else: # try and get a new one from the internet try: response = requests.get('https://public.opendatasoft.com/api/records/1.0/search/' + '?dataset=geonames-all-cities-with-a-population-1000&q=' + f'&lang={str.lower(country_code)}&fields=name,population&sort=population' + f'&refine.country_code={str.upper(country_code)}&rows={len(cities)}') if response.status_code != 200: return cities res = [(city['fields']['name'], float(city['fields']['population'])) for city in json.loads(response.content)['records']] pd.DataFrame(res).to_csv(file, index=False, header=None) except Exception as e: print(e) return cities return OrderedDict(res) if len(res) > 0 else cities","title":"cities_by_population"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_1","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#add_likelihood_to_cities_1","text":"1 2 3 def add_likelihood_to_cities ( self ) View Source 1 2 3 4 5 6 7 8 9 10 11 def add_likelihood_to_cities(self): for lang, generator in self.generators.items(): if hasattr(generator.provider('faker.providers.address'), 'cities'): generator.provider('faker.providers.address').cities = CityByPopulationMixin.cities_by_population( cities=generator.provider('faker.providers.address').cities, country_code=lang)","title":"add_likelihood_to_cities"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomcity","text":"1 2 3 4 5 class RandomCity ( languages : Union [ str , List [ str ]] = 'nl' , likelihood_based_on_city_population : bool = True , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class RandomCity(RandomEntity, CityByPopulationMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), likelihood_based_on_city_population: bool = True, seed: int = 0): \"\"\"Generate random cities in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address'], fn_name='city', seed=seed) if likelihood_based_on_city_population: self.add_likelihood_to_cities()","title":"RandomCity"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_2","text":"text_sensitivity.data.random.entity.RandomEntity text_sensitivity.data.random.entity.CityByPopulationMixin genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#static-methods_2","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/data/random/entity/#cities_by_population_2","text":"1 2 3 4 def cities_by_population ( cities : List [ str ], country_code : str ) Add population scores to each city in a country. Parameters: Name Type Description Default cities List[str] Current list of cities. If no replacement is found, this will be returned back. None country_code str Two-letter country code (e.g. 'nl'). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @staticmethod def cities_by_population(cities: List[str], country_code: str): \"\"\"Add population scores to each city in a country. Args: cities (List[str]): Current list of cities. If no replacement is found, this will be returned back. country_code (str): Two-letter country code (e.g. 'nl'). \"\"\" country_code = country_code.split('_')[-1] if '_' in country_code else country_code import json import os from collections import OrderedDict import pandas as pd import requests res = [] file = os.path.abspath(__file__ + f'/../../lists/cities_by_population_{country_code}.csv') if os.path.isfile(file): # already exists, using cached file res = pd.read_csv(file, header=None).values.tolist() else: # try and get a new one from the internet try: response = requests.get('https://public.opendatasoft.com/api/records/1.0/search/' + '?dataset=geonames-all-cities-with-a-population-1000&q=' + f'&lang={str.lower(country_code)}&fields=name,population&sort=population' + f'&refine.country_code={str.upper(country_code)}&rows={len(cities)}') if response.status_code != 200: return cities res = [(city['fields']['name'], float(city['fields']['population'])) for city in json.loads(response.content)['records']] pd.DataFrame(res).to_csv(file, index=False, header=None) except Exception as e: print(e) return cities return OrderedDict(res) if len(res) > 0 else cities","title":"cities_by_population"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_1","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_2","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#add_likelihood_to_cities_2","text":"1 2 3 def add_likelihood_to_cities ( self ) View Source 1 2 3 4 5 6 7 8 9 10 11 def add_likelihood_to_cities(self): for lang, generator in self.generators.items(): if hasattr(generator.provider('faker.providers.address'), 'cities'): generator.provider('faker.providers.address').cities = CityByPopulationMixin.cities_by_population( cities=generator.provider('faker.providers.address').cities, country_code=lang)","title":"add_likelihood_to_cities"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_1","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_1","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_1","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_1","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_1","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_1","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_1","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_1","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_1","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_1","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomcountry","text":"1 2 3 4 class RandomCountry ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomCountry(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random countries for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['address'], fn_name='country', seed=seed)","title":"RandomCountry"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_3","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_2","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_3","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_2","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_2","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_2","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_2","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_2","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_2","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_2","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_2","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_2","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_2","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomcryptocurrency","text":"1 2 3 class RandomCryptoCurrency ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RandomCryptoCurrency(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random cryptocurrency names.\"\"\" super().__init__(languages='en', providers=['currency'], fn_name='cryptocurrency_name', seed=seed)","title":"RandomCryptoCurrency"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_4","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_3","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_4","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_3","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_3","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_3","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_3","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_3","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_3","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_3","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_3","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_3","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_3","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomcurrencysymbol","text":"1 2 3 class RandomCurrencySymbol ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RandomCurrencySymbol(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random currency symbols.\"\"\" super().__init__(languages='en', providers=['currency'], fn_name='currency_symbol', seed=seed)","title":"RandomCurrencySymbol"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_5","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_4","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_5","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_4","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_4","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_4","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_4","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_4","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_4","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_4","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_4","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_4","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_4","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomday","text":"1 2 3 class RandomDay ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RandomDay(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random day of the month.\"\"\" super().__init__(languages='en', providers=['date_time'], fn_name='day_of_month', seed=seed)","title":"RandomDay"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_6","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_5","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_6","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_5","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_5","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_5","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_5","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_5","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_5","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_5","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_5","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_5","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_5","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomdayofweek","text":"1 2 3 4 class RandomDayOfWeek ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomDayOfWeek(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random day of week in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['date_time'], fn_name='day_of_week', seed=seed)","title":"RandomDayOfWeek"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_7","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_6","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_7","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_6","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_6","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_6","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_6","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_6","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_6","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_6","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_6","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_6","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_6","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomemail","text":"1 2 3 4 class RandomEmail ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomEmail(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random e-mail addresses for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['person', 'company', 'internet'], fn_name='email', seed=seed)","title":"RandomEmail"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_8","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_7","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_8","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_7","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_7","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_7","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_7","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_7","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_7","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_7","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_7","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_7","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_7","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomentity","text":"1 2 3 4 5 6 7 8 9 class RandomEntity ( languages : Union [ str , List [ str ]] = 'nl' , providers : List [ str ] = [ 'person' ], fn_name : Union [ str , List [ str ]] = 'name' , attribute : str = 'fn' , attribute_rename : Optional [ Callable [[ str ], str ]] = None , sep : str = ' \\n ' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 class RandomEntity(Readable, SeedMixin, CaseMixin): def __init__(self, languages: Union[str, List[str]] = get_locale(), providers: List[str] = ['person'], fn_name: Union[str, List[str]] = 'name', attribute: str = 'fn', attribute_rename: Optional[Callable[[str], str]] = None, sep: str = '\\n', seed: int = 0): \"\"\"Base class to generate entity data for (a) given language(s). Args: languages (Union[str, List[str]], optional): .... Defaults to your current locale (see `get_locale()`). providers (List[str], optional): Providers from `faker` used in generation. Defaults to ['person']. fn_name (Union[str, List[str]], optional): Function name(s) to call for each generator. Defaults to 'name'. attribute (str, optional): Name of additional attribute (other than language). Defaults to 'fn'. attribute_rename (Optional[Callable[[str], str]], optional): Rename function for attribute value. Defaults to None. sep (str, optional): Separator to replace '\\n' character with. Defaults to '\\n'. seed (int, optional): Seed for reproducibility. Defaults to 0. \"\"\" self.languages = [languages] if isinstance(languages, str) else languages self.providers = [f'faker.providers.{provider}' if not provider.startswith('faker.providers.') else provider for provider in providers] self.generators = {lang: Factory.create(LOCALE_MAP[lang] if lang in LOCALE_MAP.keys() else lang, self.providers, Generator(), None) for lang in self.languages} self.attribute = attribute if attribute_rename is None: self.attribute_rename = lambda x: x else: self.attribute_rename = attribute_rename self.sep = sep self.fn_name = fn_name if isinstance(fn_name, list) else [fn_name] self._original_seed = self._seed = seed self._lowercase = self._sentencecase = self._titlecase = self._uppercase = False def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr)) def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"RandomEntity"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_9","text":"genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#descendants_1","text":"text_sensitivity.data.random.entity.RandomAddress text_sensitivity.data.random.entity.RandomCity text_sensitivity.data.random.entity.RandomCountry text_sensitivity.data.random.entity.RandomName text_sensitivity.data.random.entity.RandomFirstName text_sensitivity.data.random.entity.RandomLastName text_sensitivity.data.random.entity.RandomEmail text_sensitivity.data.random.entity.RandomPhoneNumber text_sensitivity.data.random.entity.RandomYear text_sensitivity.data.random.entity.RandomMonth text_sensitivity.data.random.entity.RandomDay text_sensitivity.data.random.entity.RandomDayOfWeek text_sensitivity.data.random.entity.RandomPriceTag text_sensitivity.data.random.entity.RandomCurrencySymbol text_sensitivity.data.random.entity.RandomCryptoCurrency text_sensitivity.data.random.entity.RandomLicensePlate","title":"Descendants"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_8","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_9","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_8","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_8","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_8","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_8","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_8","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_8","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_8","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_8","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_8","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_8","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomfirstname","text":"1 2 3 4 5 class RandomFirstName ( languages : Union [ str , List [ str ]] = 'nl' , sex : List [ str ] = [ 'male' , 'female' ], seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class RandomFirstName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), sex: List[str] = ['male', 'female'], seed: int = 0): \"\"\"Generate random first names for (a) given language(s).\"\"\" if isinstance(sex, str): sex = [sex] super().__init__(languages=languages, providers=['person'], fn_name=[f'first_name_{s}' for s in sex], attribute='sex', attribute_rename=lambda x: str(x).replace('name_', ''), seed=seed)","title":"RandomFirstName"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_10","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_9","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_10","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_9","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_9","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_9","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_9","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_9","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_9","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_9","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_9","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_9","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_9","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomlastname","text":"1 2 3 4 class RandomLastName ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomLastName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random last names for (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['person'], fn_name='last_name', seed=seed)","title":"RandomLastName"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_11","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_10","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_11","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_10","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_10","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_10","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_10","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_10","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_10","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_10","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_10","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_10","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_10","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomlicenseplate","text":"1 2 3 class RandomLicensePlate ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RandomLicensePlate(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random license plates for a given country.\"\"\" super().__init__(languages='en', providers=['automotive'], fn_name='license_plate', seed=seed)","title":"RandomLicensePlate"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_12","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_11","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_12","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_11","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_11","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_11","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_11","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_11","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_11","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_11","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_11","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_11","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_11","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randommonth","text":"1 2 3 4 class RandomMonth ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomMonth(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random month name in (a) given language(s).\"\"\" super().__init__(languages=languages, providers=['date_time'], fn_name='month_name', seed=seed)","title":"RandomMonth"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_13","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_12","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_13","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_12","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_12","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_12","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_12","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_12","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_12","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_12","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_12","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_12","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_12","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomname","text":"1 2 3 4 5 class RandomName ( languages : Union [ str , List [ str ]] = 'nl' , sex : List [ str ] = [ 'male' , 'female' ], seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class RandomName(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), sex: List[str] = ['male', 'female'], seed: int = 0): \"\"\"Generate random full names for (a) given language(s).\"\"\" if isinstance(sex, str): sex = [sex] super().__init__(languages=languages, providers=['person'], fn_name=[f'name_{s}' for s in sex], attribute='sex', attribute_rename=lambda x: str(x).replace('name_', ''), seed=seed)","title":"RandomName"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_14","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_13","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_14","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_13","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_13","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_13","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_13","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_13","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_13","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_13","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_13","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_13","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_13","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomphonenumber","text":"1 2 3 4 class RandomPhoneNumber ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomPhoneNumber(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random phone numbers for (a) given language(s) / country.\"\"\" super().__init__(languages=languages, providers=['phone_number'], fn_name='phone_number', seed=seed)","title":"RandomPhoneNumber"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_15","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_14","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_15","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_14","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_14","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_14","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_14","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_14","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_14","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_14","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_14","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_14","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_14","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randompricetag","text":"1 2 3 4 class RandomPriceTag ( languages : Union [ str , List [ str ]] = 'nl' , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RandomPriceTag(RandomEntity): def __init__(self, languages: Union[str, List[str]] = get_locale(), seed: int = 0): \"\"\"Generate random pricetag names in (a) given languages' currency.\"\"\" super().__init__(languages=languages, providers=['currency'], fn_name='pricetag', seed=seed)","title":"RandomPriceTag"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_16","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_15","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_16","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_15","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_15","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_15","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_15","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_15","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_15","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_15","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_15","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_15","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_15","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/entity/#randomyear","text":"1 2 3 class RandomYear ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RandomYear(RandomEntity): def __init__(self, seed: int = 0): \"\"\"Generate random year.\"\"\" super().__init__(languages='en', providers=['date_time'], fn_name='year', seed=seed)","title":"RandomYear"},{"location":"reference/text_sensitivity/data/random/entity/#ancestors-in-mro_17","text":"text_sensitivity.data.random.entity.RandomEntity genbase.Readable genbase.mixin.SeedMixin genbase.mixin.CaseMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/entity/#instance-variables_16","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/entity/#methods_17","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/entity/#apply_case_16","text":"1 2 3 4 def apply_case ( self , string ) Apply the selected case to a string. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def apply_case(self, string): \"\"\"Apply the selected case to a string.\"\"\" if not isinstance(string, str) or string.isnumeric(): return string if self._lowercase: return string.lower() elif self._sentencecase: return string.capitalize() elif self._titlecase: return string.title() elif self._uppercase: return string.upper() return string","title":"apply_case"},{"location":"reference/text_sensitivity/data/random/entity/#generate_16","text":"1 2 3 4 5 def generate ( self , n : int , attributes : bool = False ) -> Union [ instancelib . instances . text . TextInstanceProvider , Tuple [ instancelib . instances . text . TextInstanceProvider , Dict [ str , instancelib . labels . memory . MemoryLabelProvider ]]] Generate n instances of random data. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description TextInstanceProvider Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def generate(self, n: int, attributes: bool = False ) -> Union[TextInstanceProvider, Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]]: \"\"\"Generate n instances of random data. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: TextInstanceProvider: Provider containing generated instances (if attributes = False). Tuple[TextInstanceProvider, Dict[str, MemoryLabelProvider]]: Provider and corresponding attribute labels (if attributes = True). \"\"\" res = self.generate_list(n=n, attributes=attributes) values = [v for v, _ in res] if attributes else res values = TextInstanceProvider.from_data(values) if attributes: # Group labels, and put all of them into labelproviders with the same keys as the instanceprovider labels = [l for _, l in res] labels = {key: MemoryLabelProvider.from_tuples(zip(list(values), [frozenset({label[key]}) for label in labels])) for key in labels[0].keys()} return values, labels return values","title":"generate"},{"location":"reference/text_sensitivity/data/random/entity/#generate_list_16","text":"1 2 3 4 5 def generate_list ( self , n : int , attributes : bool = False ) -> Union [ List [ str ], List [ Tuple [ str , Dict [ str , str ]]]] Generate n instances of random data and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None attributes bool Include attributes (language, which function was used, etc.) or not. Defaults to False. None Returns: Type Description List[str] Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def generate_list(self, n: int, attributes: bool = False) -> Union[List[str], List[Tuple[str, Dict[str, str]]]]: \"\"\"Generate n instances of random data and return as list. Args: n (int): Number of instances to generate. attributes (bool, optional): Include attributes (language, which function was used, etc.) or not. Defaults to False. Returns: List[str]: Generated instances (if attributes = False). List[Tuple[str, Dict[str, str]]]: Generated instances and corresponding attributes (if attributes = True). \"\"\" np.random.seed(self._seed) self._seed += 1 languages = np.random.choice(self.languages, size=n) fn_names = np.random.choice(self.fn_name, size=n) for generator in self.generators.values(): generator.seed(self._seed) sentences = [self.apply_case(eval(f'self.generators[\"{lang}\"].{fn}()').replace('\\n', self.sep)) # nosec for fn, lang in zip(fn_names, languages)] if not attributes: return sentences attr = [{'language': lang} for lang in languages] if len(self.fn_name) == 1 \\ else [{'language': lang, self.attribute: self.attribute_rename(fn)} for lang, fn in zip(languages, fn_names)] return list(zip(sentences, attr))","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/entity/#lower_16","text":"1 2 3 def lower ( self ) Switch to lowercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def lower(self): \"\"\"Switch to lowercase data generation, and return self.\"\"\" self._lowercase = True self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"lower"},{"location":"reference/text_sensitivity/data/random/entity/#original_16","text":"1 2 3 def original ( self ) Switch to original case data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def original(self): \"\"\"Switch to original case data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = False return self","title":"original"},{"location":"reference/text_sensitivity/data/random/entity/#reset_seed_16","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/entity/#sentence_16","text":"1 2 3 def sentence ( self ) Switch to sentencecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def sentence(self): \"\"\"Switch to sentencecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = True self._titlecase = False self._uppercase = False return self","title":"sentence"},{"location":"reference/text_sensitivity/data/random/entity/#set_seed_16","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/entity/#title_16","text":"1 2 3 def title ( self ) Switch to titlecase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def title(self): \"\"\"Switch to titlecase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = True self._uppercase = False return self","title":"title"},{"location":"reference/text_sensitivity/data/random/entity/#upper_16","text":"1 2 3 def upper ( self ) Switch to uppercase data generation, and return self. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def upper(self): \"\"\"Switch to uppercase data generation, and return self.\"\"\" self._lowercase = False self._sentencecase = False self._titlecase = False self._uppercase = True return self","title":"upper"},{"location":"reference/text_sensitivity/data/random/string/","text":"Module text_sensitivity.data.random.string None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 import string from typing import List, Optional, Union import numpy as np from genbase import Readable, SeedMixin from instancelib.instances.text import TextInstanceProvider class RandomString(Readable, SeedMixin): def __init__(self, seed: int = 0, options: Union[str, List[str]] = string.printable): \"\"\"Base class for random data (string) generation. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. options (Union[str, List[str]], optional): Characters or strings to generate data from. Defaults to string.printable. \"\"\" self._original_seed = self._seed = seed self.options = options def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] def __call__(self, *args, **kwargs): \"\"\"Alias for `RandomString.generate()`.\"\"\" return self.generate(*args, **kwargs) class RandomSpaces(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number of spaces.\"\"\" super().__init__(seed=seed, options=' ') class RandomWhitespace(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number whitespace characters.\"\"\" super().__init__(seed=seed, options=string.whitespace) class RandomAscii(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII characters.\"\"\" super().__init__(seed=seed, options=string.ascii_letters) class RandomUpper(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII uppercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_uppercase) class RandomLower(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII lowercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_lowercase) class RandomDigits(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random digits.\"\"\" super().__init__(seed=seed, options=string.digits) class RandomPunctuation(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random punctuation characters.\"\"\" super().__init__(seed=seed, options=string.punctuation) class RandomEmojis(RandomString): def __init__(self, seed: int = 0, base: bool = True, dingbats: bool = True, flags: bool = True, components: bool = True): \"\"\"Generate strings containing a subset of random unicode emojis. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. base (bool, optional): Include base emojis (e.g. smiley face). Defaults to True. dingbats (bool, optional): Include dingbat emojis. Defaults to True. flags (bool, optional): Include flag emojis. Defaults to True. components (bool, optional): Include emoji components (e.g. skin color modifier or country flags). Defaults to True. Raises: ValueError: At least one of `base`, `dingbats`, `flags` should be True. \"\"\" if not(base or dingbats or flags): raise ValueError('At least one of base, dingbats, flags should be True.') emojis = [] if base: emojis.extend(['\\U0001F600', '\\U0001F601', '\\U0001F602', '\\U0001F603', '\\U0001F604', '\\U0001F605', '\\U0001F606', '\\U0001F607', '\\U0001F608', '\\U0001F609', '\\U0001F60A', '\\U0001F60B', '\\U0001F60C', '\\U0001F60D', '\\U0001F60E', '\\U0001F60F', '\\U0001F610', '\\U0001F611', '\\U0001F612', '\\U0001F613', '\\U0001F910', '\\U0001F911', '\\U0001F912', '\\U0001F913']) if dingbats: # 2700-27BF emojis.extend(['\\U00002704', '\\U00002705', '\\U00002706', '\\U00002707', '\\U00002708', '\\U00002709', '\\U0000270A', '\\U0000270B', '\\U0000270C', '\\U0000270D', '\\U0000270E', '\\U0000270F', '\\U0000274C', '\\U0000274D', '\\U0000274E', '\\U0000274F']) if flags: emojis.extend(['\\U00002690', '\\U00002691', '\\U0001F3F3', '\\U0001F3F4', '\\U0001F6A9']) if components: # e.g. country flags emojis.extend(['\\U0001F1E6\\U0001F1E8', '\\U0001F1E6\\U0001F1E9', '\\U0001F1E6\\U0001F1EA', '\\U0001F1E6\\U0001F1EB']) if components: emojis.extend(['\\U0001F9D1\\U0001F3FB', '\\U0001F9D1\\U0001F3FC', '\\U0001F9D1\\U0001F3FD', '\\U0001F9D1\\U0001F3FE']) super().__init__(seed=seed, options=emojis) class RandomCyrillic(RandomString): def __init__(self, languages: Union[List[str], str] = 'ru', upper: bool = True, lower: bool = True, seed: int = 0): \"\"\"Generate containing random Cyrillic characters. Can generate text in Bulgarian ('bg'), Macedonian ('mk'), Russian ('ru'), Serbian ('sr'), Ukrainian ('uk'), and all combinations thereof. Args: languages (Union[List[str], str], optional): Cyrillic languages to select. Defaults to 'ru'. upper (bool, optional): Whether to include seed (int, optional): Seed for reproducibility. Defaults to 0. Raises: ValueError: Either upper or lower should be True. ValueError: One of the selected languages is unknown. \"\"\" if not upper and not lower: raise ValueError('At least one of upper and lower should be True. Cannot generate text.') if isinstance(languages, str): languages = [languages] languages = [str.lower(lang) for lang in languages] lowercase = {'bg': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044c\u044a\u044e\u044f', 'mk': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0437\u0438\u0458\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0453\u0436\u0455\u0459\u045a\u045c\u0447\u045f\u0448', 'ru': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0451\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044a\u044b\u044c\u044d\u044e\u044f', 'sr': u'\u0430\u0431\u0432\u0433\u0434\u0452\u0435\u0436\u0437\u0438\u0458\u043a\u043b\u0459\u043c\u043d\u045a\u043e\u043f\u0440\u0441\u0442\u045b\u0443\u0444\u0445\u0446\u0447\u045f\u0448', 'uk': u'\u0430\u0431\u0432\u0433\u0491\u0434\u0435\u0437\u0438\u0456\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u044c\u0454\u0436\u0457\u0445\u0446\u0447\u0448\u0449\u044e\u044f'} uppercase = {'bg': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0416\u0417\u0418\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0427\u0428\u0429\u042e\u042f\u042a', 'mk': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0417\u0418\u0408\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0403\u0416\u0405\u0409\u040a\u040c\u0427\u040f\u0428', 'ru': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0401\u0416\u0417\u0418\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0427\u0428\u0429\u042a\u042b\u042c\u042d\u042e\u042f', 'sr': u'\u0410\u0411\u0412\u0413\u0414\u0402\u0415\u0416\u0417\u0418\u0408\u041a\u041b\u0409\u041c\u041d\u040a\u041e\u041f\u0420\u0421\u0422\u040b\u0423\u0424\u0425\u0426\u0427\u040f\u0428', 'uk': u'\u0410\u0411\u0412\u0413\u0490\u0414\u0415\u0417\u0418\u0406\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u042c\u0404\u0416\u0407\u0425\u0426\u0427\u0428\u0429\u042e\u042f'} options = '' for lang in languages: if lang not in lowercase.keys(): raise ValueError(f'Unknown language code {lang=}. Choose from {list(lowercase.keys())}.') if lower: options += lowercase[lang] if upper: options += uppercase[lang] super().__init__(seed=seed, options=options) def combine_generators(*generators, seed: Optional[int] = None) -> RandomString: \"\"\"Combine muliple random string generators into one. Args: *generators: Generators to combine. seed (Optional[int]): Seed value for new generator. If None picks a random seed from the generators. Defaults to None. Example: Make a generator that generates random punctuation, emojis and ASCII characters: >>> new_generator = combine_generators(RandomPunctuation(), RandomEmojis(), RandomAscii()) Returns: RandomString: Generator with all generator options combined. \"\"\" all_options = [list(generator.options) for generator in generators] if seed is None: seed = np.random.choice([generator._seed for generator in generators]) return RandomString(seed=seed, options=[item for sublist in all_options for item in sublist]) Functions combine_generators 1 2 3 4 def combine_generators ( * generators , seed : Optional [ int ] = None ) -> text_sensitivity . data . random . string . RandomString Combine muliple random string generators into one. Parameters: Name Type Description Default *generators None Generators to combine. None seed Optional[int] Seed value for new generator. If None picks a random seed from the generators. Defaults to None. None Returns: Type Description RandomString Generator with all generator options combined. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def combine_generators(*generators, seed: Optional[int] = None) -> RandomString: \"\"\"Combine muliple random string generators into one. Args: *generators: Generators to combine. seed (Optional[int]): Seed value for new generator. If None picks a random seed from the generators. Defaults to None. Example: Make a generator that generates random punctuation, emojis and ASCII characters: >>> new_generator = combine_generators(RandomPunctuation(), RandomEmojis(), RandomAscii()) Returns: RandomString: Generator with all generator options combined. \"\"\" all_options = [list(generator.options) for generator in generators] if seed is None: seed = np.random.choice([generator._seed for generator in generators]) return RandomString(seed=seed, options=[item for sublist in all_options for item in sublist]) Classes RandomAscii 1 2 3 class RandomAscii ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomAscii(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII characters.\"\"\" super().__init__(seed=seed, options=string.ascii_letters) Ancestors (in MRO) text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin Instance variables 1 seed Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) generate_list 1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() RandomCyrillic 1 2 3 4 5 6 class RandomCyrillic ( languages : Union [ List [ str ], str ] = 'ru' , upper : bool = True , lower : bool = True , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class RandomCyrillic(RandomString): def __init__(self, languages: Union[List[str], str] = 'ru', upper: bool = True, lower: bool = True, seed: int = 0): \"\"\"Generate containing random Cyrillic characters. Can generate text in Bulgarian ('bg'), Macedonian ('mk'), Russian ('ru'), Serbian ('sr'), Ukrainian ('uk'), and all combinations thereof. Args: languages (Union[List[str], str], optional): Cyrillic languages to select. Defaults to 'ru'. upper (bool, optional): Whether to include seed (int, optional): Seed for reproducibility. Defaults to 0. Raises: ValueError: Either upper or lower should be True. ValueError: One of the selected languages is unknown. \"\"\" if not upper and not lower: raise ValueError('At least one of upper and lower should be True. Cannot generate text.') if isinstance(languages, str): languages = [languages] languages = [str.lower(lang) for lang in languages] lowercase = {'bg': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044c\u044a\u044e\u044f', 'mk': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0437\u0438\u0458\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0453\u0436\u0455\u0459\u045a\u045c\u0447\u045f\u0448', 'ru': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0451\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044a\u044b\u044c\u044d\u044e\u044f', 'sr': u'\u0430\u0431\u0432\u0433\u0434\u0452\u0435\u0436\u0437\u0438\u0458\u043a\u043b\u0459\u043c\u043d\u045a\u043e\u043f\u0440\u0441\u0442\u045b\u0443\u0444\u0445\u0446\u0447\u045f\u0448', 'uk': u'\u0430\u0431\u0432\u0433\u0491\u0434\u0435\u0437\u0438\u0456\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u044c\u0454\u0436\u0457\u0445\u0446\u0447\u0448\u0449\u044e\u044f'} uppercase = {'bg': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0416\u0417\u0418\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0427\u0428\u0429\u042e\u042f\u042a', 'mk': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0417\u0418\u0408\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0403\u0416\u0405\u0409\u040a\u040c\u0427\u040f\u0428', 'ru': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0401\u0416\u0417\u0418\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0427\u0428\u0429\u042a\u042b\u042c\u042d\u042e\u042f', 'sr': u'\u0410\u0411\u0412\u0413\u0414\u0402\u0415\u0416\u0417\u0418\u0408\u041a\u041b\u0409\u041c\u041d\u040a\u041e\u041f\u0420\u0421\u0422\u040b\u0423\u0424\u0425\u0426\u0427\u040f\u0428', 'uk': u'\u0410\u0411\u0412\u0413\u0490\u0414\u0415\u0417\u0418\u0406\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u042c\u0404\u0416\u0407\u0425\u0426\u0427\u0428\u0429\u042e\u042f'} options = '' for lang in languages: if lang not in lowercase.keys(): raise ValueError(f'Unknown language code {lang=}. Choose from {list(lowercase.keys())}.') if lower: options += lowercase[lang] if upper: options += uppercase[lang] super().__init__(seed=seed, options=options) Ancestors (in MRO) text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin Instance variables 1 seed Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) generate_list 1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() RandomDigits 1 2 3 class RandomDigits ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomDigits(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random digits.\"\"\" super().__init__(seed=seed, options=string.digits) Ancestors (in MRO) text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin Instance variables 1 seed Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) generate_list 1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() RandomEmojis 1 2 3 4 5 6 7 class RandomEmojis ( seed : int = 0 , base : bool = True , dingbats : bool = True , flags : bool = True , components : bool = True ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class RandomEmojis(RandomString): def __init__(self, seed: int = 0, base: bool = True, dingbats: bool = True, flags: bool = True, components: bool = True): \"\"\"Generate strings containing a subset of random unicode emojis. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. base (bool, optional): Include base emojis (e.g. smiley face). Defaults to True. dingbats (bool, optional): Include dingbat emojis. Defaults to True. flags (bool, optional): Include flag emojis. Defaults to True. components (bool, optional): Include emoji components (e.g. skin color modifier or country flags). Defaults to True. Raises: ValueError: At least one of `base`, `dingbats`, `flags` should be True. \"\"\" if not(base or dingbats or flags): raise ValueError('At least one of base, dingbats, flags should be True.') emojis = [] if base: emojis.extend(['\\U0001F600', '\\U0001F601', '\\U0001F602', '\\U0001F603', '\\U0001F604', '\\U0001F605', '\\U0001F606', '\\U0001F607', '\\U0001F608', '\\U0001F609', '\\U0001F60A', '\\U0001F60B', '\\U0001F60C', '\\U0001F60D', '\\U0001F60E', '\\U0001F60F', '\\U0001F610', '\\U0001F611', '\\U0001F612', '\\U0001F613', '\\U0001F910', '\\U0001F911', '\\U0001F912', '\\U0001F913']) if dingbats: # 2700-27BF emojis.extend(['\\U00002704', '\\U00002705', '\\U00002706', '\\U00002707', '\\U00002708', '\\U00002709', '\\U0000270A', '\\U0000270B', '\\U0000270C', '\\U0000270D', '\\U0000270E', '\\U0000270F', '\\U0000274C', '\\U0000274D', '\\U0000274E', '\\U0000274F']) if flags: emojis.extend(['\\U00002690', '\\U00002691', '\\U0001F3F3', '\\U0001F3F4', '\\U0001F6A9']) if components: # e.g. country flags emojis.extend(['\\U0001F1E6\\U0001F1E8', '\\U0001F1E6\\U0001F1E9', '\\U0001F1E6\\U0001F1EA', '\\U0001F1E6\\U0001F1EB']) if components: emojis.extend(['\\U0001F9D1\\U0001F3FB', '\\U0001F9D1\\U0001F3FC', '\\U0001F9D1\\U0001F3FD', '\\U0001F9D1\\U0001F3FE']) super().__init__(seed=seed, options=emojis) Ancestors (in MRO) text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin Instance variables 1 seed Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) generate_list 1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() RandomLower 1 2 3 class RandomLower ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomLower(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII lowercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_lowercase) Ancestors (in MRO) text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin Instance variables 1 seed Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) generate_list 1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() RandomPunctuation 1 2 3 class RandomPunctuation ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomPunctuation(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random punctuation characters.\"\"\" super().__init__(seed=seed, options=string.punctuation) Ancestors (in MRO) text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin Instance variables 1 seed Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) generate_list 1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() RandomSpaces 1 2 3 class RandomSpaces ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomSpaces(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number of spaces.\"\"\" super().__init__(seed=seed, options=' ') Ancestors (in MRO) text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin Instance variables 1 seed Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) generate_list 1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() RandomString 1 2 3 4 class RandomString ( seed : int = 0 , options : Union [ str , List [ str ]] = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%& \\' ()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n\\r\\x0b\\x0c ' ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 class RandomString(Readable, SeedMixin): def __init__(self, seed: int = 0, options: Union[str, List[str]] = string.printable): \"\"\"Base class for random data (string) generation. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. options (Union[str, List[str]], optional): Characters or strings to generate data from. Defaults to string.printable. \"\"\" self._original_seed = self._seed = seed self.options = options def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] def __call__(self, *args, **kwargs): \"\"\"Alias for `RandomString.generate()`.\"\"\" return self.generate(*args, **kwargs) Ancestors (in MRO) genbase.Readable genbase.mixin.SeedMixin Descendants text_sensitivity.data.random.string.RandomSpaces text_sensitivity.data.random.string.RandomWhitespace text_sensitivity.data.random.string.RandomAscii text_sensitivity.data.random.string.RandomUpper text_sensitivity.data.random.string.RandomLower text_sensitivity.data.random.string.RandomDigits text_sensitivity.data.random.string.RandomPunctuation text_sensitivity.data.random.string.RandomEmojis text_sensitivity.data.random.string.RandomCyrillic Instance variables 1 seed Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) generate_list 1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() RandomUpper 1 2 3 class RandomUpper ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomUpper(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII uppercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_uppercase) Ancestors (in MRO) text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin Instance variables 1 seed Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) generate_list 1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed() RandomWhitespace 1 2 3 class RandomWhitespace ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomWhitespace(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number whitespace characters.\"\"\" super().__init__(seed=seed, options=string.whitespace) Ancestors (in MRO) text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin Instance variables 1 seed Methods generate 1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) generate_list 1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] reset_seed 1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self set_seed 1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"String"},{"location":"reference/text_sensitivity/data/random/string/#module-text_sensitivitydatarandomstring","text":"None None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 import string from typing import List, Optional, Union import numpy as np from genbase import Readable, SeedMixin from instancelib.instances.text import TextInstanceProvider class RandomString(Readable, SeedMixin): def __init__(self, seed: int = 0, options: Union[str, List[str]] = string.printable): \"\"\"Base class for random data (string) generation. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. options (Union[str, List[str]], optional): Characters or strings to generate data from. Defaults to string.printable. \"\"\" self._original_seed = self._seed = seed self.options = options def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] def __call__(self, *args, **kwargs): \"\"\"Alias for `RandomString.generate()`.\"\"\" return self.generate(*args, **kwargs) class RandomSpaces(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number of spaces.\"\"\" super().__init__(seed=seed, options=' ') class RandomWhitespace(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number whitespace characters.\"\"\" super().__init__(seed=seed, options=string.whitespace) class RandomAscii(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII characters.\"\"\" super().__init__(seed=seed, options=string.ascii_letters) class RandomUpper(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII uppercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_uppercase) class RandomLower(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII lowercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_lowercase) class RandomDigits(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random digits.\"\"\" super().__init__(seed=seed, options=string.digits) class RandomPunctuation(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random punctuation characters.\"\"\" super().__init__(seed=seed, options=string.punctuation) class RandomEmojis(RandomString): def __init__(self, seed: int = 0, base: bool = True, dingbats: bool = True, flags: bool = True, components: bool = True): \"\"\"Generate strings containing a subset of random unicode emojis. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. base (bool, optional): Include base emojis (e.g. smiley face). Defaults to True. dingbats (bool, optional): Include dingbat emojis. Defaults to True. flags (bool, optional): Include flag emojis. Defaults to True. components (bool, optional): Include emoji components (e.g. skin color modifier or country flags). Defaults to True. Raises: ValueError: At least one of `base`, `dingbats`, `flags` should be True. \"\"\" if not(base or dingbats or flags): raise ValueError('At least one of base, dingbats, flags should be True.') emojis = [] if base: emojis.extend(['\\U0001F600', '\\U0001F601', '\\U0001F602', '\\U0001F603', '\\U0001F604', '\\U0001F605', '\\U0001F606', '\\U0001F607', '\\U0001F608', '\\U0001F609', '\\U0001F60A', '\\U0001F60B', '\\U0001F60C', '\\U0001F60D', '\\U0001F60E', '\\U0001F60F', '\\U0001F610', '\\U0001F611', '\\U0001F612', '\\U0001F613', '\\U0001F910', '\\U0001F911', '\\U0001F912', '\\U0001F913']) if dingbats: # 2700-27BF emojis.extend(['\\U00002704', '\\U00002705', '\\U00002706', '\\U00002707', '\\U00002708', '\\U00002709', '\\U0000270A', '\\U0000270B', '\\U0000270C', '\\U0000270D', '\\U0000270E', '\\U0000270F', '\\U0000274C', '\\U0000274D', '\\U0000274E', '\\U0000274F']) if flags: emojis.extend(['\\U00002690', '\\U00002691', '\\U0001F3F3', '\\U0001F3F4', '\\U0001F6A9']) if components: # e.g. country flags emojis.extend(['\\U0001F1E6\\U0001F1E8', '\\U0001F1E6\\U0001F1E9', '\\U0001F1E6\\U0001F1EA', '\\U0001F1E6\\U0001F1EB']) if components: emojis.extend(['\\U0001F9D1\\U0001F3FB', '\\U0001F9D1\\U0001F3FC', '\\U0001F9D1\\U0001F3FD', '\\U0001F9D1\\U0001F3FE']) super().__init__(seed=seed, options=emojis) class RandomCyrillic(RandomString): def __init__(self, languages: Union[List[str], str] = 'ru', upper: bool = True, lower: bool = True, seed: int = 0): \"\"\"Generate containing random Cyrillic characters. Can generate text in Bulgarian ('bg'), Macedonian ('mk'), Russian ('ru'), Serbian ('sr'), Ukrainian ('uk'), and all combinations thereof. Args: languages (Union[List[str], str], optional): Cyrillic languages to select. Defaults to 'ru'. upper (bool, optional): Whether to include seed (int, optional): Seed for reproducibility. Defaults to 0. Raises: ValueError: Either upper or lower should be True. ValueError: One of the selected languages is unknown. \"\"\" if not upper and not lower: raise ValueError('At least one of upper and lower should be True. Cannot generate text.') if isinstance(languages, str): languages = [languages] languages = [str.lower(lang) for lang in languages] lowercase = {'bg': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044c\u044a\u044e\u044f', 'mk': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0437\u0438\u0458\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0453\u0436\u0455\u0459\u045a\u045c\u0447\u045f\u0448', 'ru': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0451\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044a\u044b\u044c\u044d\u044e\u044f', 'sr': u'\u0430\u0431\u0432\u0433\u0434\u0452\u0435\u0436\u0437\u0438\u0458\u043a\u043b\u0459\u043c\u043d\u045a\u043e\u043f\u0440\u0441\u0442\u045b\u0443\u0444\u0445\u0446\u0447\u045f\u0448', 'uk': u'\u0430\u0431\u0432\u0433\u0491\u0434\u0435\u0437\u0438\u0456\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u044c\u0454\u0436\u0457\u0445\u0446\u0447\u0448\u0449\u044e\u044f'} uppercase = {'bg': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0416\u0417\u0418\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0427\u0428\u0429\u042e\u042f\u042a', 'mk': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0417\u0418\u0408\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0403\u0416\u0405\u0409\u040a\u040c\u0427\u040f\u0428', 'ru': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0401\u0416\u0417\u0418\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0427\u0428\u0429\u042a\u042b\u042c\u042d\u042e\u042f', 'sr': u'\u0410\u0411\u0412\u0413\u0414\u0402\u0415\u0416\u0417\u0418\u0408\u041a\u041b\u0409\u041c\u041d\u040a\u041e\u041f\u0420\u0421\u0422\u040b\u0423\u0424\u0425\u0426\u0427\u040f\u0428', 'uk': u'\u0410\u0411\u0412\u0413\u0490\u0414\u0415\u0417\u0418\u0406\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u042c\u0404\u0416\u0407\u0425\u0426\u0427\u0428\u0429\u042e\u042f'} options = '' for lang in languages: if lang not in lowercase.keys(): raise ValueError(f'Unknown language code {lang=}. Choose from {list(lowercase.keys())}.') if lower: options += lowercase[lang] if upper: options += uppercase[lang] super().__init__(seed=seed, options=options) def combine_generators(*generators, seed: Optional[int] = None) -> RandomString: \"\"\"Combine muliple random string generators into one. Args: *generators: Generators to combine. seed (Optional[int]): Seed value for new generator. If None picks a random seed from the generators. Defaults to None. Example: Make a generator that generates random punctuation, emojis and ASCII characters: >>> new_generator = combine_generators(RandomPunctuation(), RandomEmojis(), RandomAscii()) Returns: RandomString: Generator with all generator options combined. \"\"\" all_options = [list(generator.options) for generator in generators] if seed is None: seed = np.random.choice([generator._seed for generator in generators]) return RandomString(seed=seed, options=[item for sublist in all_options for item in sublist])","title":"Module text_sensitivity.data.random.string"},{"location":"reference/text_sensitivity/data/random/string/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/data/random/string/#combine_generators","text":"1 2 3 4 def combine_generators ( * generators , seed : Optional [ int ] = None ) -> text_sensitivity . data . random . string . RandomString Combine muliple random string generators into one. Parameters: Name Type Description Default *generators None Generators to combine. None seed Optional[int] Seed value for new generator. If None picks a random seed from the generators. Defaults to None. None Returns: Type Description RandomString Generator with all generator options combined. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def combine_generators(*generators, seed: Optional[int] = None) -> RandomString: \"\"\"Combine muliple random string generators into one. Args: *generators: Generators to combine. seed (Optional[int]): Seed value for new generator. If None picks a random seed from the generators. Defaults to None. Example: Make a generator that generates random punctuation, emojis and ASCII characters: >>> new_generator = combine_generators(RandomPunctuation(), RandomEmojis(), RandomAscii()) Returns: RandomString: Generator with all generator options combined. \"\"\" all_options = [list(generator.options) for generator in generators] if seed is None: seed = np.random.choice([generator._seed for generator in generators]) return RandomString(seed=seed, options=[item for sublist in all_options for item in sublist])","title":"combine_generators"},{"location":"reference/text_sensitivity/data/random/string/#classes","text":"","title":"Classes"},{"location":"reference/text_sensitivity/data/random/string/#randomascii","text":"1 2 3 class RandomAscii ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomAscii(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII characters.\"\"\" super().__init__(seed=seed, options=string.ascii_letters)","title":"RandomAscii"},{"location":"reference/text_sensitivity/data/random/string/#ancestors-in-mro","text":"text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/string/#instance-variables","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/string/#methods","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/string/#generate","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/string/#generate_list","text":"1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)]","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/string/#reset_seed","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/string/#set_seed","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/string/#randomcyrillic","text":"1 2 3 4 5 6 class RandomCyrillic ( languages : Union [ List [ str ], str ] = 'ru' , upper : bool = True , lower : bool = True , seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class RandomCyrillic(RandomString): def __init__(self, languages: Union[List[str], str] = 'ru', upper: bool = True, lower: bool = True, seed: int = 0): \"\"\"Generate containing random Cyrillic characters. Can generate text in Bulgarian ('bg'), Macedonian ('mk'), Russian ('ru'), Serbian ('sr'), Ukrainian ('uk'), and all combinations thereof. Args: languages (Union[List[str], str], optional): Cyrillic languages to select. Defaults to 'ru'. upper (bool, optional): Whether to include seed (int, optional): Seed for reproducibility. Defaults to 0. Raises: ValueError: Either upper or lower should be True. ValueError: One of the selected languages is unknown. \"\"\" if not upper and not lower: raise ValueError('At least one of upper and lower should be True. Cannot generate text.') if isinstance(languages, str): languages = [languages] languages = [str.lower(lang) for lang in languages] lowercase = {'bg': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044c\u044a\u044e\u044f', 'mk': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0437\u0438\u0458\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0453\u0436\u0455\u0459\u045a\u045c\u0447\u045f\u0448', 'ru': u'\u0430\u0431\u0432\u0433\u0434\u0435\u0451\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044a\u044b\u044c\u044d\u044e\u044f', 'sr': u'\u0430\u0431\u0432\u0433\u0434\u0452\u0435\u0436\u0437\u0438\u0458\u043a\u043b\u0459\u043c\u043d\u045a\u043e\u043f\u0440\u0441\u0442\u045b\u0443\u0444\u0445\u0446\u0447\u045f\u0448', 'uk': u'\u0430\u0431\u0432\u0433\u0491\u0434\u0435\u0437\u0438\u0456\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u044c\u0454\u0436\u0457\u0445\u0446\u0447\u0448\u0449\u044e\u044f'} uppercase = {'bg': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0416\u0417\u0418\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0427\u0428\u0429\u042e\u042f\u042a', 'mk': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0417\u0418\u0408\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0403\u0416\u0405\u0409\u040a\u040c\u0427\u040f\u0428', 'ru': u'\u0410\u0411\u0412\u0413\u0414\u0415\u0401\u0416\u0417\u0418\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u0427\u0428\u0429\u042a\u042b\u042c\u042d\u042e\u042f', 'sr': u'\u0410\u0411\u0412\u0413\u0414\u0402\u0415\u0416\u0417\u0418\u0408\u041a\u041b\u0409\u041c\u041d\u040a\u041e\u041f\u0420\u0421\u0422\u040b\u0423\u0424\u0425\u0426\u0427\u040f\u0428', 'uk': u'\u0410\u0411\u0412\u0413\u0490\u0414\u0415\u0417\u0418\u0406\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u042c\u0404\u0416\u0407\u0425\u0426\u0427\u0428\u0429\u042e\u042f'} options = '' for lang in languages: if lang not in lowercase.keys(): raise ValueError(f'Unknown language code {lang=}. Choose from {list(lowercase.keys())}.') if lower: options += lowercase[lang] if upper: options += uppercase[lang] super().__init__(seed=seed, options=options)","title":"RandomCyrillic"},{"location":"reference/text_sensitivity/data/random/string/#ancestors-in-mro_1","text":"text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/string/#instance-variables_1","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/string/#methods_1","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/string/#generate_1","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/string/#generate_list_1","text":"1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)]","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/string/#reset_seed_1","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/string/#set_seed_1","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/string/#randomdigits","text":"1 2 3 class RandomDigits ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomDigits(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random digits.\"\"\" super().__init__(seed=seed, options=string.digits)","title":"RandomDigits"},{"location":"reference/text_sensitivity/data/random/string/#ancestors-in-mro_2","text":"text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/string/#instance-variables_2","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/string/#methods_2","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/string/#generate_2","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/string/#generate_list_2","text":"1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)]","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/string/#reset_seed_2","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/string/#set_seed_2","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/string/#randomemojis","text":"1 2 3 4 5 6 7 class RandomEmojis ( seed : int = 0 , base : bool = True , dingbats : bool = True , flags : bool = True , components : bool = True ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class RandomEmojis(RandomString): def __init__(self, seed: int = 0, base: bool = True, dingbats: bool = True, flags: bool = True, components: bool = True): \"\"\"Generate strings containing a subset of random unicode emojis. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. base (bool, optional): Include base emojis (e.g. smiley face). Defaults to True. dingbats (bool, optional): Include dingbat emojis. Defaults to True. flags (bool, optional): Include flag emojis. Defaults to True. components (bool, optional): Include emoji components (e.g. skin color modifier or country flags). Defaults to True. Raises: ValueError: At least one of `base`, `dingbats`, `flags` should be True. \"\"\" if not(base or dingbats or flags): raise ValueError('At least one of base, dingbats, flags should be True.') emojis = [] if base: emojis.extend(['\\U0001F600', '\\U0001F601', '\\U0001F602', '\\U0001F603', '\\U0001F604', '\\U0001F605', '\\U0001F606', '\\U0001F607', '\\U0001F608', '\\U0001F609', '\\U0001F60A', '\\U0001F60B', '\\U0001F60C', '\\U0001F60D', '\\U0001F60E', '\\U0001F60F', '\\U0001F610', '\\U0001F611', '\\U0001F612', '\\U0001F613', '\\U0001F910', '\\U0001F911', '\\U0001F912', '\\U0001F913']) if dingbats: # 2700-27BF emojis.extend(['\\U00002704', '\\U00002705', '\\U00002706', '\\U00002707', '\\U00002708', '\\U00002709', '\\U0000270A', '\\U0000270B', '\\U0000270C', '\\U0000270D', '\\U0000270E', '\\U0000270F', '\\U0000274C', '\\U0000274D', '\\U0000274E', '\\U0000274F']) if flags: emojis.extend(['\\U00002690', '\\U00002691', '\\U0001F3F3', '\\U0001F3F4', '\\U0001F6A9']) if components: # e.g. country flags emojis.extend(['\\U0001F1E6\\U0001F1E8', '\\U0001F1E6\\U0001F1E9', '\\U0001F1E6\\U0001F1EA', '\\U0001F1E6\\U0001F1EB']) if components: emojis.extend(['\\U0001F9D1\\U0001F3FB', '\\U0001F9D1\\U0001F3FC', '\\U0001F9D1\\U0001F3FD', '\\U0001F9D1\\U0001F3FE']) super().__init__(seed=seed, options=emojis)","title":"RandomEmojis"},{"location":"reference/text_sensitivity/data/random/string/#ancestors-in-mro_3","text":"text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/string/#instance-variables_3","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/string/#methods_3","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/string/#generate_3","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/string/#generate_list_3","text":"1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)]","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/string/#reset_seed_3","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/string/#set_seed_3","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/string/#randomlower","text":"1 2 3 class RandomLower ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomLower(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII lowercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_lowercase)","title":"RandomLower"},{"location":"reference/text_sensitivity/data/random/string/#ancestors-in-mro_4","text":"text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/string/#instance-variables_4","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/string/#methods_4","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/string/#generate_4","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/string/#generate_list_4","text":"1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)]","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/string/#reset_seed_4","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/string/#set_seed_4","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/string/#randompunctuation","text":"1 2 3 class RandomPunctuation ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomPunctuation(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings containing random punctuation characters.\"\"\" super().__init__(seed=seed, options=string.punctuation)","title":"RandomPunctuation"},{"location":"reference/text_sensitivity/data/random/string/#ancestors-in-mro_5","text":"text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/string/#instance-variables_5","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/string/#methods_5","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/string/#generate_5","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/string/#generate_list_5","text":"1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)]","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/string/#reset_seed_5","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/string/#set_seed_5","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/string/#randomspaces","text":"1 2 3 class RandomSpaces ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomSpaces(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number of spaces.\"\"\" super().__init__(seed=seed, options=' ')","title":"RandomSpaces"},{"location":"reference/text_sensitivity/data/random/string/#ancestors-in-mro_6","text":"text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/string/#instance-variables_6","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/string/#methods_6","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/string/#generate_6","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/string/#generate_list_6","text":"1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)]","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/string/#reset_seed_6","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/string/#set_seed_6","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/string/#randomstring","text":"1 2 3 4 class RandomString ( seed : int = 0 , options : Union [ str , List [ str ]] = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%& \\' ()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n\\r\\x0b\\x0c ' ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 class RandomString(Readable, SeedMixin): def __init__(self, seed: int = 0, options: Union[str, List[str]] = string.printable): \"\"\"Base class for random data (string) generation. Args: seed (int, optional): Seed for reproducibility. Defaults to 0. options (Union[str, List[str]], optional): Characters or strings to generate data from. Defaults to string.printable. \"\"\" self._original_seed = self._seed = seed self.options = options def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data) def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)] def __call__(self, *args, **kwargs): \"\"\"Alias for `RandomString.generate()`.\"\"\" return self.generate(*args, **kwargs)","title":"RandomString"},{"location":"reference/text_sensitivity/data/random/string/#ancestors-in-mro_7","text":"genbase.Readable genbase.mixin.SeedMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/string/#descendants","text":"text_sensitivity.data.random.string.RandomSpaces text_sensitivity.data.random.string.RandomWhitespace text_sensitivity.data.random.string.RandomAscii text_sensitivity.data.random.string.RandomUpper text_sensitivity.data.random.string.RandomLower text_sensitivity.data.random.string.RandomDigits text_sensitivity.data.random.string.RandomPunctuation text_sensitivity.data.random.string.RandomEmojis text_sensitivity.data.random.string.RandomCyrillic","title":"Descendants"},{"location":"reference/text_sensitivity/data/random/string/#instance-variables_7","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/string/#methods_7","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/string/#generate_7","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/string/#generate_list_7","text":"1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)]","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/string/#reset_seed_7","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/string/#set_seed_7","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/string/#randomupper","text":"1 2 3 class RandomUpper ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomUpper(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate random ASCII uppercase characters.\"\"\" super().__init__(seed=seed, options=string.ascii_uppercase)","title":"RandomUpper"},{"location":"reference/text_sensitivity/data/random/string/#ancestors-in-mro_8","text":"text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/string/#instance-variables_8","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/string/#methods_8","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/string/#generate_8","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/string/#generate_list_8","text":"1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)]","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/string/#reset_seed_8","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/string/#set_seed_8","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/data/random/string/#randomwhitespace","text":"1 2 3 class RandomWhitespace ( seed : int = 0 ) View Source 1 2 3 4 5 6 7 8 9 class RandomWhitespace(RandomString): def __init__(self, seed: int = 0): \"\"\"Generate strings with a random number whitespace characters.\"\"\" super().__init__(seed=seed, options=string.whitespace)","title":"RandomWhitespace"},{"location":"reference/text_sensitivity/data/random/string/#ancestors-in-mro_9","text":"text_sensitivity.data.random.string.RandomString genbase.Readable genbase.mixin.SeedMixin","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/data/random/string/#instance-variables_9","text":"1 seed","title":"Instance variables"},{"location":"reference/text_sensitivity/data/random/string/#methods_9","text":"","title":"Methods"},{"location":"reference/text_sensitivity/data/random/string/#generate_9","text":"1 2 3 4 5 6 def generate ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> instancelib . instances . text . TextInstanceProvider Generate n instances of random strings. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description TextInstanceProvider Provider containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def generate(self, n: int, min_length: int = 0, max_length: int = 100) -> TextInstanceProvider: \"\"\"Generate n instances of random strings. Example: Create a TextInstanceProvider containing n=10 strings of random characters from `'12345xXyY!?'` between length 3 and 10: >>> RandomString(seed=0, options='12345xXyY!?').generate_list(n=10, min_length=3, max_length=10) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: TextInstanceProvider: Provider containing generated instances. \"\"\" data = self.generate_list(n=n, min_length=min_length, max_length=max_length) return TextInstanceProvider.from_data(data)","title":"generate"},{"location":"reference/text_sensitivity/data/random/string/#generate_list_9","text":"1 2 3 4 5 6 def generate_list ( self , n : int , min_length : int = 0 , max_length : int = 100 ) -> List [ str ] Generate n instances of random strings and return as list. Parameters: Name Type Description Default n int Number of instances to generate. None min_length int Minimum length of random instance. Defaults to 0. 0 max_length int Maximum length of random instance. Defaults to 100. 100 Returns: Type Description List[str] List containing generated instances. Raises: Type Description ValueError min_length should be smaller than max_length . View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def generate_list(self, n: int, min_length: int = 0, max_length: int = 100) -> List[str]: \"\"\"Generate n instances of random strings and return as list. Example: Generate a list of random characters from `u'ABCabc\\U0001F600'` between length 10 and 50 (n=10 strings): >>> RandomString(seed=0, options=u'ABCabc\\U0001F600').generate_list(n=10, min_length=10, max_length=50) Args: n (int): Number of instances to generate. min_length (int, optional): Minimum length of random instance. Defaults to 0. max_length (int, optional): Maximum length of random instance. Defaults to 100. Raises: ValueError: `min_length` should be smaller than `max_length`. Returns: List[str]: List containing generated instances. \"\"\" if min_length > max_length: raise ValueError(f'{min_length=} should be smaller than {max_length=}') min_length = max(min_length, 0) np.random.seed(self._seed) return [''.join(np.random.choice(list(self.options)) for _ in range(np.random.randint(min_length, max_length))) for _ in range(n)]","title":"generate_list"},{"location":"reference/text_sensitivity/data/random/string/#reset_seed_9","text":"1 2 3 def reset_seed ( self ) Reset the seed to the original seed value, and return self. View Source 1 2 3 4 5 6 7 def reset_seed(self): \"\"\"Reset the seed to the original seed value, and return self.\"\"\" self._seed = self._original_seed return self","title":"reset_seed"},{"location":"reference/text_sensitivity/data/random/string/#set_seed_9","text":"1 2 3 4 def set_seed ( self , seed : Optional [ int ] = None ) Set the current seed and original seed to a new value, and return self. Parameters: Name Type Description Default seed Optional[int] Seed value. If None, select a random seed. Defaults to None. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def set_seed(self, seed: Optional[int] = None): \"\"\"Set the current seed and original seed to a new value, and return self. Args: seed (Optional[int], optional): Seed value. If None, select a random seed. Defaults to None. \"\"\" if seed is None: seed = np.random.randint(100000) self._original_seed = seed return self.reset_seed()","title":"set_seed"},{"location":"reference/text_sensitivity/perturbation/","text":"Module text_sensitivity.perturbation Apply perturbation to one or multiple (tokenized) strings. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \"\"\"Apply perturbation to one or multiple (tokenized) strings.\"\"\" from text_sensitivity.perturbation.base import (OneToManyPerturbation, OneToOnePerturbation, Perturbation) from text_sensitivity.perturbation.characters import (add_typos, delete_random, random_case_swap, random_lower, random_spaces, random_upper, swap_random) # from text_sensitivity.perturbation.words import from text_sensitivity.perturbation.sentences import (repeat_k_times, to_lower, to_upper) Sub-modules text_sensitivity.perturbation.base text_sensitivity.perturbation.characters text_sensitivity.perturbation.sentences text_sensitivity.perturbation.words","title":"Index"},{"location":"reference/text_sensitivity/perturbation/#module-text_sensitivityperturbation","text":"Apply perturbation to one or multiple (tokenized) strings. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \"\"\"Apply perturbation to one or multiple (tokenized) strings.\"\"\" from text_sensitivity.perturbation.base import (OneToManyPerturbation, OneToOnePerturbation, Perturbation) from text_sensitivity.perturbation.characters import (add_typos, delete_random, random_case_swap, random_lower, random_spaces, random_upper, swap_random) # from text_sensitivity.perturbation.words import from text_sensitivity.perturbation.sentences import (repeat_k_times, to_lower, to_upper)","title":"Module text_sensitivity.perturbation"},{"location":"reference/text_sensitivity/perturbation/#sub-modules","text":"text_sensitivity.perturbation.base text_sensitivity.perturbation.characters text_sensitivity.perturbation.sentences text_sensitivity.perturbation.words","title":"Sub-modules"},{"location":"reference/text_sensitivity/perturbation/base/","text":"Module text_sensitivity.perturbation.base Apply perturbations to TextInstances and/or strings, generating one or many new instances. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 \"\"\"Apply perturbations to TextInstances and/or strings, generating one or many new instances.\"\"\" import copy import itertools from typing import (Callable, Dict, Iterable, List, Optional, Sequence, Tuple, Union) import numpy as np from genbase import Readable from instancelib.instances.text import MemoryTextInstance, TextInstance from instancelib.typehints import KT, LT from nlpaug.base_augmenter import Augmenter from text_explainability.decorators import text_instance from text_explainability.utils import default_detokenizer, default_tokenizer def oneway_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer) -> Optional[Tuple[str, LT, LT]]: tokenized = tokenizer(instance.data) # Get all options options = {i: dictionary[a] for i, a in enumerate(tokenized) if a in dictionary.keys()} option_keys = list(options.keys()) all_options = list(itertools.product(*options.values())) # Pick up to N random replacements and apply them for idx in set(np.random.randint(len(all_options), size=n)): current_option = all_options[idx] new_tokenized = copy.deepcopy(tokenized) for i, option in enumerate(current_option): new_tokenized[option_keys[i]] = option if tokenized != new_tokenized: yield detokenizer(new_tokenized), label_from, label_to def one_to_one_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=1)) return res[0] if res else None def one_to_many_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=n)) res = list(filter(None, res)) if len(res) == 0: return None return res def as_list(x): return [x] if not isinstance(x, Iterable) or isinstance(x, str) else x def format_identifier(instance, key): return f'{instance.identifier}|{key}' class Perturbation(Readable): def __init__(self, perturbation_function: Callable): \"\"\"Apply a perturbation function to a single `TextInstance`. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and resulting instance(s). Should return None if no perturbation has been applied. \"\"\" self.perturbation_function = perturbation_function @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.') @text_instance def __call__(self, instance: TextInstance): return self.perturb(instance) class OneToOnePerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[str, LT, LT]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.': '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity mapping_dict = {k: v for k, v in set(list(itertools.combinations(mapping_list, 2)))} return OneToManyPerturbation.from_dictionary(mapping_dict, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: ValueError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" if prefix is None and suffix is None and replacement is None: raise ValueError('At least one of prefix, suffix and replacement should be provided.') if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res) or not res: return if isinstance(res, list): res = res[0] perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text is not None and perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))]) class OneToManyPerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[Sequence[str], LT, Union[LT, Sequence[LT]]]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, perform_once: bool = False): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. perform_once (bool, optional): If the n parameter is in class construction perform once. Defaults to False. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) elif perform_once: return super().from_function(function, label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to) @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, perform_once=True, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res): return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])] Functions as_list 1 2 3 def as_list ( x ) View Source 1 2 3 def as_list(x): return [x] if not isinstance(x, Iterable) or isinstance(x, str) else x format_identifier 1 2 3 4 def format_identifier ( instance , key ) View Source 1 2 3 def format_identifier(instance, key): return f'{instance.identifier}|{key}' one_to_many_dictionary_mapping 1 2 3 4 5 6 7 8 9 def one_to_many_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int , tokenizer , detokenizer ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def one_to_many_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=n)) res = list(filter(None, res)) if len(res) == 0: return None return res one_to_one_dictionary_mapping 1 2 3 4 5 6 7 8 def one_to_one_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , tokenizer , detokenizer ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def one_to_one_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=1)) return res[0] if res else None oneway_dictionary_mapping 1 2 3 4 5 6 7 8 9 def oneway_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int , tokenizer , detokenizer ) -> Optional [ Tuple [ str , ~ LT , ~ LT ]] View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def oneway_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer) -> Optional[Tuple[str, LT, LT]]: tokenized = tokenizer(instance.data) # Get all options options = {i: dictionary[a] for i, a in enumerate(tokenized) if a in dictionary.keys()} option_keys = list(options.keys()) all_options = list(itertools.product(*options.values())) # Pick up to N random replacements and apply them for idx in set(np.random.randint(len(all_options), size=n)): current_option = all_options[idx] new_tokenized = copy.deepcopy(tokenized) for i, option in enumerate(current_option): new_tokenized[option_keys[i]] = option if tokenized != new_tokenized: yield detokenizer(new_tokenized), label_from, label_to Classes OneToManyPerturbation 1 2 3 class OneToManyPerturbation ( perturbation_function : Callable [[ instancelib . instances . text . TextInstance ], Optional [ Tuple [ Sequence [ str ], ~ LT , Union [ ~ LT , Sequence [ ~ LT ]]]]] ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 class OneToManyPerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[Sequence[str], LT, Union[LT, Sequence[LT]]]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, perform_once: bool = False): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. perform_once (bool, optional): If the n parameter is in class construction perform once. Defaults to False. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) elif perform_once: return super().from_function(function, label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to) @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, perform_once=True, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res): return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])] Ancestors (in MRO) text_sensitivity.perturbation.base.Perturbation genbase.Readable Static methods from_dict 1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) from_dictionary 1 2 3 4 5 6 7 8 def from_dictionary ( dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int = 10 , tokenizer : Callable = < function word_tokenizer at 0x1628b5f70 > , detokenizer : Callable = < function word_detokenizer at 0x1628bb310 > ) Construct a OneToManyPerturbation from a dictionary. Parameters: Name Type Description Default dictionary Dict[str, List[str]] Lookup dictionary to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of dictionary). None label_to LT Attribute label of perturbed instance (right-hand side of dictionary). None n int Number of instances to generate. Defaults to 10. 10 tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) from_function 1 2 3 4 5 6 7 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , n : int = 10 , perform_once : bool = False ) Construct a OneToManyPerturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' n int Number of instances to generate. Defaults to 10. 10 perform_once bool If the n parameter is in class construction perform once. Defaults to False. False View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, perform_once: bool = False): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. perform_once (bool, optional): If the n parameter is in class construction perform once. Defaults to False. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) elif perform_once: return super().from_function(function, label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to) from_nlpaug 1 2 3 4 5 6 7 def from_nlpaug ( augmenter : nlpaug . base_augmenter . Augmenter , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , n : int = 10 , ** augment_kwargs ) Construct a OneToManyPerturbation from a nlpaug _ Augmenter. Parameters: Name Type Description Default augmenter Augmenter Class with .augment() function applying a perturbation to a string. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' n int Number of instances to generate. Defaults to 10. 10 **augment_kwargs None Optional arguments passed to .augment() function. .. _nlpaug: None https None //github.com/makcedward/nlpaug None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, perform_once=True, label_from=label_from, label_to=label_to) from_str 1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) from_string 1 2 3 4 def from_string ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') Methods perturb 1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) -> Optional [ Sequence [ Tuple [ instancelib . instances . text . TextInstance , Sequence [ Tuple [ ~ KT , ~ LT ]]]]] Apply a perturbation function to a single TextInstance , getting a multiple results per instance. Parameters: Name Type Description Default perturbation_function Callable Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. None Returns: Type Description Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]] None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res): return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])] OneToOnePerturbation 1 2 3 class OneToOnePerturbation ( perturbation_function : Callable [[ instancelib . instances . text . TextInstance ], Optional [ Tuple [ str , ~ LT , ~ LT ]]] ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 class OneToOnePerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[str, LT, LT]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.': '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity mapping_dict = {k: v for k, v in set(list(itertools.combinations(mapping_list, 2)))} return OneToManyPerturbation.from_dictionary(mapping_dict, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: ValueError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" if prefix is None and suffix is None and replacement is None: raise ValueError('At least one of prefix, suffix and replacement should be provided.') if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res) or not res: return if isinstance(res, list): res = res[0] perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text is not None and perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))]) Ancestors (in MRO) text_sensitivity.perturbation.base.Perturbation genbase.Readable Static methods from_dict 1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) from_dictionary 1 2 3 4 5 6 7 def from_dictionary ( dictionary : Dict [ str , str ], label_from : ~ LT , label_to : ~ LT , tokenizer : Callable = < function word_tokenizer at 0x1628b5f70 > , detokenizer : Callable = < function word_detokenizer at 0x1628bb310 > ) Construct a OneToOnePerturbation from a dictionary. Parameters: Name Type Description Default dictionary Dict[str, str] Lookup dictionary to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of dictionary). None label_to LT Attribute label of perturbed instance (right-hand side of dictionary). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.': '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) from_function 1 2 3 4 5 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' ) Construct a Perturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) from_list 1 2 3 4 5 6 7 def from_list ( mapping_list : List [ str ], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , tokenizer : Callable = < function word_tokenizer at 0x1628b5f70 > , detokenizer : Callable = < function word_detokenizer at 0x1628bb310 > ) Construct a OneToOnePerturbation from a list. A function is constructed that aims to map any value in the list to any other value in the list. Parameters: Name Type Description Default mapping_list List[str] Lookup list of tokens (e.g. words, characters). None label_from LT Attribute label of original instance (non-replaced). None label_to LT Attribute label of perturbed instance (replaced). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity mapping_dict = {k: v for k, v in set(list(itertools.combinations(mapping_list, 2)))} return OneToManyPerturbation.from_dictionary(mapping_dict, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) from_nlpaug 1 2 3 4 5 6 def from_nlpaug ( augmenter : nlpaug . base_augmenter . Augmenter , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , ** augment_kwargs ) Construct a OneToOnePerturbation from a nlpaug _ Augmenter. Parameters: Name Type Description Default augmenter Augmenter Class with .augment() function applying a perturbation to a string. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' **augment_kwargs None Optional arguments passed to .augment() function. .. _nlpaug: None https None //github.com/makcedward/nlpaug None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to) from_str 1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) from_string 1 2 3 4 5 6 7 8 9 10 def from_string ( prefix : Optional [ str ] = None , suffix : Optional [ str ] = None , replacement : Optional [ str ] = None , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , connector : str = ' ' , connector_before : Optional [ str ] = None , connector_after : Optional [ str ] = None ) Construct a OneToOnePerturbation from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of prefix , suffix or replacement should be a string to apply the replacement. 1 2 3 4 5 6 7 8 9 10 11 Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after=' ', >>> label_to='more_negative') 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: ValueError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: ValueError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" if prefix is None and suffix is None and replacement is None: raise ValueError('At least one of prefix, suffix and replacement should be provided.') if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function) from_tuples 1 2 3 4 5 6 7 def from_tuples ( tuples : List [ Tuple [ str , str ]], label_from : ~ LT , label_to : ~ LT , tokenizer : Callable = < function word_tokenizer at 0x1628b5f70 > , detokenizer : Callable = < function word_detokenizer at 0x1628bb310 > ) Construct a OneToOnePerturbation from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Parameters: Name Type Description Default tuples List[Tuple[str, str]] Lookup tuples to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of tuples). None label_to LT Attribute label of perturbed instance (right-hand side of tuples). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) Methods perturb 1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) -> Optional [ Sequence [ Tuple [ instancelib . instances . text . TextInstance , Sequence [ Tuple [ ~ KT , ~ LT ]]]]] Apply a perturbation function to a single TextInstance , getting a single result per instance. Parameters: Name Type Description Default perturbation_function Callable Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. None Returns: Type Description Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]] None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res) or not res: return if isinstance(res, list): res = res[0] perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text is not None and perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))]) Perturbation 1 2 3 class Perturbation ( perturbation_function : Callable ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class Perturbation(Readable): def __init__(self, perturbation_function: Callable): \"\"\"Apply a perturbation function to a single `TextInstance`. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and resulting instance(s). Should return None if no perturbation has been applied. \"\"\" self.perturbation_function = perturbation_function @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.') @text_instance def __call__(self, instance: TextInstance): return self.perturb(instance) Ancestors (in MRO) genbase.Readable Descendants text_sensitivity.perturbation.base.OneToOnePerturbation text_sensitivity.perturbation.base.OneToManyPerturbation Static methods from_dict 1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) from_dictionary 1 2 3 4 def from_dictionary ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') from_function 1 2 3 4 5 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' ) Construct a Perturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) from_str 1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) from_string 1 2 3 4 def from_string ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') Methods perturb 1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) View Source 1 2 3 4 5 @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.')","title":"Base"},{"location":"reference/text_sensitivity/perturbation/base/#module-text_sensitivityperturbationbase","text":"Apply perturbations to TextInstances and/or strings, generating one or many new instances. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 \"\"\"Apply perturbations to TextInstances and/or strings, generating one or many new instances.\"\"\" import copy import itertools from typing import (Callable, Dict, Iterable, List, Optional, Sequence, Tuple, Union) import numpy as np from genbase import Readable from instancelib.instances.text import MemoryTextInstance, TextInstance from instancelib.typehints import KT, LT from nlpaug.base_augmenter import Augmenter from text_explainability.decorators import text_instance from text_explainability.utils import default_detokenizer, default_tokenizer def oneway_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer) -> Optional[Tuple[str, LT, LT]]: tokenized = tokenizer(instance.data) # Get all options options = {i: dictionary[a] for i, a in enumerate(tokenized) if a in dictionary.keys()} option_keys = list(options.keys()) all_options = list(itertools.product(*options.values())) # Pick up to N random replacements and apply them for idx in set(np.random.randint(len(all_options), size=n)): current_option = all_options[idx] new_tokenized = copy.deepcopy(tokenized) for i, option in enumerate(current_option): new_tokenized[option_keys[i]] = option if tokenized != new_tokenized: yield detokenizer(new_tokenized), label_from, label_to def one_to_one_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=1)) return res[0] if res else None def one_to_many_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=n)) res = list(filter(None, res)) if len(res) == 0: return None return res def as_list(x): return [x] if not isinstance(x, Iterable) or isinstance(x, str) else x def format_identifier(instance, key): return f'{instance.identifier}|{key}' class Perturbation(Readable): def __init__(self, perturbation_function: Callable): \"\"\"Apply a perturbation function to a single `TextInstance`. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and resulting instance(s). Should return None if no perturbation has been applied. \"\"\" self.perturbation_function = perturbation_function @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.') @text_instance def __call__(self, instance: TextInstance): return self.perturb(instance) class OneToOnePerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[str, LT, LT]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.': '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity mapping_dict = {k: v for k, v in set(list(itertools.combinations(mapping_list, 2)))} return OneToManyPerturbation.from_dictionary(mapping_dict, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: ValueError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" if prefix is None and suffix is None and replacement is None: raise ValueError('At least one of prefix, suffix and replacement should be provided.') if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res) or not res: return if isinstance(res, list): res = res[0] perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text is not None and perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))]) class OneToManyPerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[Sequence[str], LT, Union[LT, Sequence[LT]]]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, perform_once: bool = False): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. perform_once (bool, optional): If the n parameter is in class construction perform once. Defaults to False. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) elif perform_once: return super().from_function(function, label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to) @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, perform_once=True, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res): return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])]","title":"Module text_sensitivity.perturbation.base"},{"location":"reference/text_sensitivity/perturbation/base/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/perturbation/base/#as_list","text":"1 2 3 def as_list ( x ) View Source 1 2 3 def as_list(x): return [x] if not isinstance(x, Iterable) or isinstance(x, str) else x","title":"as_list"},{"location":"reference/text_sensitivity/perturbation/base/#format_identifier","text":"1 2 3 4 def format_identifier ( instance , key ) View Source 1 2 3 def format_identifier(instance, key): return f'{instance.identifier}|{key}'","title":"format_identifier"},{"location":"reference/text_sensitivity/perturbation/base/#one_to_many_dictionary_mapping","text":"1 2 3 4 5 6 7 8 9 def one_to_many_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int , tokenizer , detokenizer ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def one_to_many_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=n)) res = list(filter(None, res)) if len(res) == 0: return None return res","title":"one_to_many_dictionary_mapping"},{"location":"reference/text_sensitivity/perturbation/base/#one_to_one_dictionary_mapping","text":"1 2 3 4 5 6 7 8 def one_to_one_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , tokenizer , detokenizer ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def one_to_one_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, tokenizer, detokenizer): res = list(oneway_dictionary_mapping(instance, dictionary, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer, n=1)) return res[0] if res else None","title":"one_to_one_dictionary_mapping"},{"location":"reference/text_sensitivity/perturbation/base/#oneway_dictionary_mapping","text":"1 2 3 4 5 6 7 8 9 def oneway_dictionary_mapping ( instance : instancelib . instances . text . TextInstance , dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int , tokenizer , detokenizer ) -> Optional [ Tuple [ str , ~ LT , ~ LT ]] View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def oneway_dictionary_mapping(instance: TextInstance, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int, tokenizer, detokenizer) -> Optional[Tuple[str, LT, LT]]: tokenized = tokenizer(instance.data) # Get all options options = {i: dictionary[a] for i, a in enumerate(tokenized) if a in dictionary.keys()} option_keys = list(options.keys()) all_options = list(itertools.product(*options.values())) # Pick up to N random replacements and apply them for idx in set(np.random.randint(len(all_options), size=n)): current_option = all_options[idx] new_tokenized = copy.deepcopy(tokenized) for i, option in enumerate(current_option): new_tokenized[option_keys[i]] = option if tokenized != new_tokenized: yield detokenizer(new_tokenized), label_from, label_to","title":"oneway_dictionary_mapping"},{"location":"reference/text_sensitivity/perturbation/base/#classes","text":"","title":"Classes"},{"location":"reference/text_sensitivity/perturbation/base/#onetomanyperturbation","text":"1 2 3 class OneToManyPerturbation ( perturbation_function : Callable [[ instancelib . instances . text . TextInstance ], Optional [ Tuple [ Sequence [ str ], ~ LT , Union [ ~ LT , Sequence [ ~ LT ]]]]] ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 class OneToManyPerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[Sequence[str], LT, Union[LT, Sequence[LT]]]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, perform_once: bool = False): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. perform_once (bool, optional): If the n parameter is in class construction perform once. Defaults to False. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) elif perform_once: return super().from_function(function, label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to) @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, perform_once=True, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res): return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])]","title":"OneToManyPerturbation"},{"location":"reference/text_sensitivity/perturbation/base/#ancestors-in-mro","text":"text_sensitivity.perturbation.base.Perturbation genbase.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/perturbation/base/#static-methods","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/perturbation/base/#from_dict","text":"1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs)","title":"from_dict"},{"location":"reference/text_sensitivity/perturbation/base/#from_dictionary","text":"1 2 3 4 5 6 7 8 def from_dictionary ( dictionary : Dict [ str , List [ str ]], label_from : ~ LT , label_to : ~ LT , n : int = 10 , tokenizer : Callable = < function word_tokenizer at 0x1628b5f70 > , detokenizer : Callable = < function word_detokenizer at 0x1628bb310 > ) Construct a OneToManyPerturbation from a dictionary. Parameters: Name Type Description Default dictionary Dict[str, List[str]] Lookup dictionary to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of dictionary). None label_to LT Attribute label of perturbed instance (right-hand side of dictionary). None n int Number of instances to generate. Defaults to 10. 10 tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @classmethod def from_dictionary(cls, dictionary: Dict[str, List[str]], label_from: LT, label_to: LT, n: int = 10, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToManyPerturbation` from a dictionary. Example: Replace the word 'good' (positive) with 'bad', 'mediocre', 'terrible' (negative) up to 5 times in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'good': ['bad', 'mediocre', 'terrible']} >>> OneToManyPerturbation.from_dictionary(replacement, >>> n=5, >>> label_from='positive', >>> label_to='negative') Args: dictionary (Dict[str, List[str]]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). n (int, optional): Number of instances to generate. Defaults to 10. tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_many_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, n=n, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function)","title":"from_dictionary"},{"location":"reference/text_sensitivity/perturbation/base/#from_function","text":"1 2 3 4 5 6 7 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , n : int = 10 , perform_once : bool = False ) Construct a OneToManyPerturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' n int Number of instances to generate. Defaults to 10. 10 perform_once bool If the n parameter is in class construction perform once. Defaults to False. False View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, perform_once: bool = False): \"\"\"Construct a `OneToManyPerturbation` from a perturbation applied to a string. Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. perform_once (bool, optional): If the n parameter is in class construction perform once. Defaults to False. \"\"\" import inspect if 'n' in inspect.signature(function).parameters: return super().from_function(lambda x: function(x, n=n), label_from=label_from, label_to=label_to) elif perform_once: return super().from_function(function, label_from=label_from, label_to=label_to) def perform_n_times(instance): perturbed = list(filter(None, [function(instance) for _ in range(n)])) return None if len(perturbed) == 0 else perturbed return super().from_function(lambda x: perform_n_times(x), label_from=label_from, label_to=label_to)","title":"from_function"},{"location":"reference/text_sensitivity/perturbation/base/#from_nlpaug","text":"1 2 3 4 5 6 7 def from_nlpaug ( augmenter : nlpaug . base_augmenter . Augmenter , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , n : int = 10 , ** augment_kwargs ) Construct a OneToManyPerturbation from a nlpaug _ Augmenter. Parameters: Name Type Description Default augmenter Augmenter Class with .augment() function applying a perturbation to a string. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' n int Number of instances to generate. Defaults to 10. 10 **augment_kwargs None Optional arguments passed to .augment() function. .. _nlpaug: None https None //github.com/makcedward/nlpaug None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', n: int = 10, **augment_kwargs): \"\"\"Construct a `OneToManyPerturbation` from a `nlpaug`_ Augmenter. Example: Add `n=5` versions of keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False) >>> OneToManyPerturbation.from_nlpaug(augmenter, n=5, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. n (int, optional): Number of instances to generate. Defaults to 10. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=n, **augment_kwargs) except: # noqa: E722 return None return cls.from_function(perturbation_function, perform_once=True, label_from=label_from, label_to=label_to)","title":"from_nlpaug"},{"location":"reference/text_sensitivity/perturbation/base/#from_str","text":"1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs)","title":"from_str"},{"location":"reference/text_sensitivity/perturbation/base/#from_string","text":"1 2 3 4 def from_string ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.')","title":"from_string"},{"location":"reference/text_sensitivity/perturbation/base/#methods","text":"","title":"Methods"},{"location":"reference/text_sensitivity/perturbation/base/#perturb","text":"1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) -> Optional [ Sequence [ Tuple [ instancelib . instances . text . TextInstance , Sequence [ Tuple [ ~ KT , ~ LT ]]]]] Apply a perturbation function to a single TextInstance , getting a multiple results per instance. Parameters: Name Type Description Default perturbation_function Callable Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. None Returns: Type Description Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]] None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a multiple results per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instances. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res): return perturbed, original_label, labels = res original_label = (instance.identifier, frozenset({original_label})) labels = as_list(labels) if len(labels) == 1: labels = labels * len(perturbed) filtered_keys = [i for i, p in enumerate(perturbed) if p != str(instance.data)] return [([MemoryTextInstance(format_identifier(instance, key), perturbed[key], None) for key in filtered_keys], [original_label] + [(format_identifier(instance, key), frozenset({labels[key]})) for key in filtered_keys])]","title":"perturb"},{"location":"reference/text_sensitivity/perturbation/base/#onetooneperturbation","text":"1 2 3 class OneToOnePerturbation ( perturbation_function : Callable [[ instancelib . instances . text . TextInstance ], Optional [ Tuple [ str , ~ LT , ~ LT ]]] ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 class OneToOnePerturbation(Perturbation): def __init__(self, perturbation_function: Callable[[TextInstance], Optional[Tuple[str, LT, LT]]]): \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. \"\"\" super().__init__(perturbation_function) @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.': '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function) @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity mapping_dict = {k: v for k, v in set(list(itertools.combinations(mapping_list, 2)))} return OneToManyPerturbation.from_dictionary(mapping_dict, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: ValueError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" if prefix is None and suffix is None and replacement is None: raise ValueError('At least one of prefix, suffix and replacement should be provided.') if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function) @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to) @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res) or not res: return if isinstance(res, list): res = res[0] perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text is not None and perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))])","title":"OneToOnePerturbation"},{"location":"reference/text_sensitivity/perturbation/base/#ancestors-in-mro_1","text":"text_sensitivity.perturbation.base.Perturbation genbase.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/perturbation/base/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/perturbation/base/#from_dict_1","text":"1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs)","title":"from_dict"},{"location":"reference/text_sensitivity/perturbation/base/#from_dictionary_1","text":"1 2 3 4 5 6 7 def from_dictionary ( dictionary : Dict [ str , str ], label_from : ~ LT , label_to : ~ LT , tokenizer : Callable = < function word_tokenizer at 0x1628b5f70 > , detokenizer : Callable = < function word_detokenizer at 0x1628bb310 > ) Construct a OneToOnePerturbation from a dictionary. Parameters: Name Type Description Default dictionary Dict[str, str] Lookup dictionary to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of dictionary). None label_to LT Attribute label of perturbed instance (right-hand side of dictionary). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 @classmethod def from_dictionary(cls, dictionary: Dict[str, str], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a dictionary. Example: Replace the word 'a' or 'an' (indefinite article) with 'the' (definite article) in each instance. The default tokenizer/detokenizer assumes word-level tokens: >>> replacements = {'a': 'the', >>> 'an': 'the'} >>> OneToOnePerturbation.from_dictionary(replacement, >>> label_from='indefinite', >>> label_to='definite') Replace the character '.' with '!' (character-level replacement): >>> from text_explainability import character_tokenizer, character_detokenizer >>> OneToOnePerturbation.from_dictionary({'.': '!'}, >>> label_from='not_excited', >>> label_to='excited', >>> tokenizer=character_tokenizer, >>> detokenizer=character_detokenizer) Args: dictionary (Dict[str, str]): Lookup dictionary to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of dictionary). label_to (LT): Attribute label of perturbed instance (right-hand side of dictionary). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: return one_to_one_dictionary_mapping(instance, dictionary={k: as_list(v) for k, v in dictionary.items()}, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function)","title":"from_dictionary"},{"location":"reference/text_sensitivity/perturbation/base/#from_function_1","text":"1 2 3 4 5 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' ) Construct a Perturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function)","title":"from_function"},{"location":"reference/text_sensitivity/perturbation/base/#from_list","text":"1 2 3 4 5 6 7 def from_list ( mapping_list : List [ str ], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , tokenizer : Callable = < function word_tokenizer at 0x1628b5f70 > , detokenizer : Callable = < function word_detokenizer at 0x1628bb310 > ) Construct a OneToOnePerturbation from a list. A function is constructed that aims to map any value in the list to any other value in the list. Parameters: Name Type Description Default mapping_list List[str] Lookup list of tokens (e.g. words, characters). None label_from LT Attribute label of original instance (non-replaced). None label_to LT Attribute label of perturbed instance (replaced). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @classmethod def from_list(cls, mapping_list: List[str], label_from: LT = 'original', label_to: LT = 'perturbed', tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from a list. A function is constructed that aims to map any value in the list to any other value in the list. Example: For example, if list `['Amsterdam', 'Rotterdam', 'Utrecht']` is provided it aims to map 'Amsterdam' to 'Rotterdam' or 'Utrecht', 'Rotterdam' to 'Amsterdam' to 'Utrecht' and 'Utrecht' to 'Rotterdam' or 'Amsterdam'. If None of these is possible, it returns None. >>> map_list = ['Amsterdam', 'Rotterdam', 'Utrecht'] >>> OneToOnePerturbation.from_list(map_list) Args: mapping_list (List[str]): Lookup list of tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (non-replaced). label_to (LT): Attribute label of perturbed instance (replaced). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" # TODO: add case-sensitivity mapping_dict = {k: v for k, v in set(list(itertools.combinations(mapping_list, 2)))} return OneToManyPerturbation.from_dictionary(mapping_dict, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer)","title":"from_list"},{"location":"reference/text_sensitivity/perturbation/base/#from_nlpaug_1","text":"1 2 3 4 5 6 def from_nlpaug ( augmenter : nlpaug . base_augmenter . Augmenter , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , ** augment_kwargs ) Construct a OneToOnePerturbation from a nlpaug _ Augmenter. Parameters: Name Type Description Default augmenter Augmenter Class with .augment() function applying a perturbation to a string. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' **augment_kwargs None Optional arguments passed to .augment() function. .. _nlpaug: None https None //github.com/makcedward/nlpaug None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @classmethod def from_nlpaug(cls, augmenter: Augmenter, label_from: LT = 'original', label_to: LT = 'perturbed', **augment_kwargs): \"\"\"Construct a `OneToOnePerturbation` from a `nlpaug`_ Augmenter. Example: Add random spaces to words in a sentence using `nlpaug.augmenter.word.SplitAug()`: >>> import nlpaug.augmenter.word as naw >>> OneToOnePerturbation.from_nlpaug(naw.SplitAug(), label_to='with_extra_space') Or add keyboard typing mistakes to lowercase characters in a sentence using `nlpaug.augmenter.char.KeyboardAug()`: >>> import nlpaug.augmenter.char as nac >>> augmenter = nac.KeyboardAug(include_upper_case=False, >>> include_special_char=False, >>> include_numeric=False) >>> OneToOnePerturbation.from_nlpaug(augmenter, label_from='no_typos', label_to='typos') Args: augmenter (Augmenter): Class with `.augment()` function applying a perturbation to a string. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. **augment_kwargs: Optional arguments passed to `.augment()` function. .. _nlpaug: https://github.com/makcedward/nlpaug \"\"\" # assert isinstance(augmenter, Augmenter), \\ # 'Can only construct from nlpaug.base_augmenter.Augmenter subclasses.' @text_instance def perturbation_function(instance: TextInstance) -> Optional[str]: try: return augmenter.augment(str(instance.data), n=1, **augment_kwargs)[0] except: # noqa: E722 return None return cls.from_function(perturbation_function, label_from=label_from, label_to=label_to)","title":"from_nlpaug"},{"location":"reference/text_sensitivity/perturbation/base/#from_str_1","text":"1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs)","title":"from_str"},{"location":"reference/text_sensitivity/perturbation/base/#from_string_1","text":"1 2 3 4 5 6 7 8 9 10 def from_string ( prefix : Optional [ str ] = None , suffix : Optional [ str ] = None , replacement : Optional [ str ] = None , label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' , connector : str = ' ' , connector_before : Optional [ str ] = None , connector_after : Optional [ str ] = None ) Construct a OneToOnePerturbation from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of prefix , suffix or replacement should be a string to apply the replacement. 1 2 3 4 5 6 7 8 9 10 11 Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after=' ', >>> label_to='more_negative') 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: ValueError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 @classmethod def from_string(cls, prefix: Optional[str] = None, suffix: Optional[str] = None, replacement: Optional[str] = None, label_from: LT = 'original', label_to: LT = 'perturbed', connector: str = ' ', connector_before: Optional[str] = None, connector_after: Optional[str] = None): \"\"\"Construct a `OneToOnePerturbation` from a string (replacement, prefix and/or suffix). Provides the ability to replace each instance string with a new one, add a prefix to each instance string and/or add a suffix to each instance string. At least one of `prefix`, `suffix` or `replacement` should be a string to apply the replacement. Example: Add a random unrelated string 'Dit is ongerelateerd.' to each instance (as prefix), where you expect that predictions will not change: >>> OneToOnePerturbation.from_string(prefix='Dit is ongerelateerd.', label_to='with_prefix') Or add a negative string 'Dit is negatief!' to each instance (as suffix on the next line), where you expect that instances will have the same label or become more negative: >>> OneToOnePerturbation.from_string(suffix='Dit is negatief!', >>> connector_after='\\n', >>> label_to='more_negative') Or replace all instances with 'UNKWRDZ': >>> OneToOnePerturbation.from_string(replacement='UNKWRDZ') Raises: ValueError: At least one of `prefix`, `suffix` and `replacement` should be provided. Args: label_from (LT): Attribute label of original instance. Defaults to 'original'. label_to (LT): Attribute label of perturbed instance. Defaults to 'perturbed'. prefix (Optional[str], optional): Text to add before `instance.data`. Defaults to None. suffix (Optional[str], optional): Text to add after `instance.data`. Defaults to None. replacement (Optional[str], optional): Text to replace `instance.data` with. Defaults to None. connector (str): General connector between `prefix`, `instance.data` and `suffix`. Defaults to ' '. connector_before (Optional[str], optional): Overrides connector between `prefix` and `instance.data`, if it is None `connector` is used. Defaults to None. connector_after (Optional[str], optional): Overrides connector between `instance.data` and `suffix`, if it is None `connector` is used. Defaults to None. \"\"\" if prefix is None and suffix is None and replacement is None: raise ValueError('At least one of prefix, suffix and replacement should be provided.') if prefix is None: connector_before = '' if suffix is None: connector_after = '' if connector_before is None: connector_before = connector if connector_after is None: connector_after = connector prefix = '' if prefix is None else prefix suffix = '' if suffix is None else suffix @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: text = replacement if replacement is not None else instance.data return f'{prefix}{connector_before}{text}{connector_after}{suffix}', label_from, label_to return cls(perturbation_function)","title":"from_string"},{"location":"reference/text_sensitivity/perturbation/base/#from_tuples","text":"1 2 3 4 5 6 7 def from_tuples ( tuples : List [ Tuple [ str , str ]], label_from : ~ LT , label_to : ~ LT , tokenizer : Callable = < function word_tokenizer at 0x1628b5f70 > , detokenizer : Callable = < function word_detokenizer at 0x1628bb310 > ) Construct a OneToOnePerturbation from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Parameters: Name Type Description Default tuples List[Tuple[str, str]] Lookup tuples to map tokens (e.g. words, characters). None label_from LT Attribute label of original instance (left-hand side of tuples). None label_to LT Attribute label of perturbed instance (right-hand side of tuples). None tokenizer Callable Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. None detokenizer Callable Function to detokenize tokens into instance data. Defaults to default_detokenizer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 @classmethod def from_tuples(cls, tuples: List[Tuple[str, str]], label_from: LT, label_to: LT, tokenizer: Callable = default_tokenizer, detokenizer: Callable = default_detokenizer): \"\"\"Construct a `OneToOnePerturbation` from tuples. A function is constructed where if first aims to perform the mapping from the tokens on the left-hand side (LHS) to the right-hand side (RHS), and if this has no result it aims to perform the mapping from the tokens on the RHS to the LHS. Example: For example, if `[('he', 'she')]` with `label_from='male'` and `label_to='female'` is provided it first checks whether the tokenized instance contains the word `'he'` (and if so applies the perturbation and returns), and otherwise aims to map `'she'` to `'he'`. If neither is possible, it returns None. >>> tuples = [('he', 'she'), >>>. ('his', 'her')] >>> OneToOnePerturbation.from_tuples(tuples, label_from='male', label_to='female') Args: tuples (List[Tuple[str, str]]): Lookup tuples to map tokens (e.g. words, characters). label_from (LT): Attribute label of original instance (left-hand side of tuples). label_to (LT): Attribute label of perturbed instance (right-hand side of tuples). tokenizer (Callable, optional): Function to tokenize instance data (e.g. words, characters). Defaults to default_tokenizer. detokenizer (Callable, optional): Function to detokenize tokens into instance data. Defaults to default_detokenizer. \"\"\" dictionary_from = {k: as_list(v) for k, v in tuples} dictionary_to = {v: as_list(k) for k, v in tuples} @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[str, LT, LT]]: first_res = one_to_one_dictionary_mapping(instance, dictionary=dictionary_from, label_from=label_from, label_to=label_to, tokenizer=tokenizer, detokenizer=detokenizer) if first_res is not None: return first_res return one_to_one_dictionary_mapping(instance, dictionary=dictionary_to, label_from=label_to, label_to=label_from, tokenizer=tokenizer, detokenizer=detokenizer) return cls(perturbation_function)","title":"from_tuples"},{"location":"reference/text_sensitivity/perturbation/base/#methods_1","text":"","title":"Methods"},{"location":"reference/text_sensitivity/perturbation/base/#perturb_1","text":"1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) -> Optional [ Sequence [ Tuple [ instancelib . instances . text . TextInstance , Sequence [ Tuple [ ~ KT , ~ LT ]]]]] Apply a perturbation function to a single TextInstance , getting a single result per instance. Parameters: Name Type Description Default perturbation_function Callable Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. None Returns: Type Description Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]] None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @text_instance def perturb(self, instance: TextInstance) -> Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: \"\"\"Apply a perturbation function to a single `TextInstance`, getting a single result per instance. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and the resulting instance. Should return None if no perturbation has been applied. Returns: Optional[Sequence[Tuple[TextInstance, Sequence[Tuple[KT, LT]]]]]: None if no perturbation has been applied. Otherwise a sequence of perturbed TextInstances, and attribute labels for the original and perturbed instances. \"\"\" res = self.perturbation_function(instance) if res is None or isinstance(res, list) and all(r is None for r in res) or not res: return if isinstance(res, list): res = res[0] perturbed, original_labels, labels = res perturbed = as_list(perturbed) original_labels = as_list(original_labels) labels = as_list(labels) for perturbed_text, original_label, label in zip(perturbed, original_labels, labels): if perturbed_text is not None and perturbed_text != str(instance.data): identifier = format_identifier(instance, 0) yield (MemoryTextInstance(identifier, perturbed_text, None), [(instance.identifier, frozenset({original_label})), (identifier, frozenset({label}))])","title":"perturb"},{"location":"reference/text_sensitivity/perturbation/base/#perturbation","text":"1 2 3 class Perturbation ( perturbation_function : Callable ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class Perturbation(Readable): def __init__(self, perturbation_function: Callable): \"\"\"Apply a perturbation function to a single `TextInstance`. Args: perturbation_function (Callable): Perturbation function to apply, including attribute label of original instance and resulting instance(s). Should return None if no perturbation has been applied. \"\"\" self.perturbation_function = perturbation_function @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs) @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function) @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.') @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs) @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.') @text_instance def __call__(self, instance: TextInstance): return self.perturb(instance)","title":"Perturbation"},{"location":"reference/text_sensitivity/perturbation/base/#ancestors-in-mro_2","text":"genbase.Readable","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/perturbation/base/#descendants","text":"text_sensitivity.perturbation.base.OneToOnePerturbation text_sensitivity.perturbation.base.OneToManyPerturbation","title":"Descendants"},{"location":"reference/text_sensitivity/perturbation/base/#static-methods_2","text":"","title":"Static methods"},{"location":"reference/text_sensitivity/perturbation/base/#from_dict_2","text":"1 2 3 4 def from_dict ( * args , ** kwargs ) Alias for Perturbation.from_dictionary() . View Source 1 2 3 4 5 6 7 @classmethod def from_dict(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_dictionary()`.\"\"\" return cls.from_dictionary(*args, **kwargs)","title":"from_dict"},{"location":"reference/text_sensitivity/perturbation/base/#from_dictionary_2","text":"1 2 3 4 def from_dictionary ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_dictionary(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.')","title":"from_dictionary"},{"location":"reference/text_sensitivity/perturbation/base/#from_function_2","text":"1 2 3 4 5 def from_function ( function : Callable [[ str ], Union [ str , Sequence [ str ], NoneType ]], label_from : ~ LT = 'original' , label_to : ~ LT = 'perturbed' ) Construct a Perturbation from a perturbation applied to a string. Parameters: Name Type Description Default function Callable[[str], Optional[Union[str, Sequence[str]]]] Function to apply to each string. Return None if no change was applied. None label_from LT Attribute label of original instance. Defaults to 'original'. 'original' label_to LT Attribute label of perturbed instance. Defaults to 'perturbed'. 'perturbed' View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @classmethod def from_function(cls, function: Callable[[str], Optional[Union[str, Sequence[str]]]], label_from: LT = 'original', label_to: LT = 'perturbed'): \"\"\"Construct a `Perturbation` from a perturbation applied to a string. Example: Make each sentence uppercase: >>> OneToOnePerturbation(str.upper, 'not_upper', 'upper') Args: function (Callable[[str], Optional[Union[str, Sequence[str]]]]): Function to apply to each string. Return None if no change was applied. label_from (LT, optional): Attribute label of original instance. Defaults to 'original'. label_to (LT, optional): Attribute label of perturbed instance. Defaults to 'perturbed'. \"\"\" @text_instance def perturbation_function(instance: TextInstance) -> Optional[Tuple[Union[str, Sequence[str]], LT, LT]]: res = function(str(instance.data)) return None if res is None else res, label_from, label_to return cls(perturbation_function)","title":"from_function"},{"location":"reference/text_sensitivity/perturbation/base/#from_str_2","text":"1 2 3 4 def from_str ( * args , ** kwargs ) Alias for Perturbation.from_string() . View Source 1 2 3 4 5 6 7 @classmethod def from_str(cls, *args, **kwargs): \"\"\"Alias for `Perturbation.from_string()`.\"\"\" return cls.from_string(*args, **kwargs)","title":"from_str"},{"location":"reference/text_sensitivity/perturbation/base/#from_string_2","text":"1 2 3 4 def from_string ( * args , ** kwargs ) View Source 1 2 3 4 5 @classmethod def from_string(cls, *args, **kwargs): raise NotImplementedError('Implemented in subclasses.')","title":"from_string"},{"location":"reference/text_sensitivity/perturbation/base/#methods_2","text":"","title":"Methods"},{"location":"reference/text_sensitivity/perturbation/base/#perturb_2","text":"1 2 3 4 def perturb ( self , instance : instancelib . instances . text . TextInstance ) View Source 1 2 3 4 5 @text_instance def perturb(self, instance: TextInstance): raise NotImplementedError('Implemented in subclasses.')","title":"perturb"},{"location":"reference/text_sensitivity/perturbation/characters/","text":"Module text_sensitivity.perturbation.characters Create character-level perturbations ( text_sensitivity.perturbation.base.Perturbation ). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 \"\"\"Create character-level perturbations (`text_sensitivity.perturbation.base.Perturbation`).\"\"\" from typing import Callable import nlpaug.augmenter.char as nac import nlpaug.augmenter.word as naw import numpy as np from text_sensitivity.perturbation.base import (OneToManyPerturbation, OneToOnePerturbation, Perturbation) def __construct(cls_or_fn, constructor_one, constructor_many, **kwargs): \"\"\"Generic constructor, returning `constructor_many` if n > 1 else `constructor_one`.\"\"\" n = 1 label_from = kwargs.pop('label_from') if 'label_from' in kwargs else 'original' label_to = kwargs.pop('label_to') if 'label_to' in kwargs else 'perturbed' if 'n' in kwargs and isinstance(kwargs['n'], int): n = kwargs.pop('n') if not isinstance(cls_or_fn, (str, dict, Callable)) or isinstance(cls_or_fn, type): cls_or_fn = cls_or_fn(**kwargs) if n > 1: return constructor_many(cls_or_fn, n=n, label_from=label_from, label_to=label_to) return constructor_one(cls_or_fn, label_from=label_from, label_to=label_to) def _function(fn, **kwargs) -> Perturbation: \"\"\"Constructor for `Perturbation.from_function`.\"\"\" return __construct(fn, OneToOnePerturbation.from_function, OneToManyPerturbation.from_function, **kwargs) def _nlpaug(cls, **kwargs) -> Perturbation: \"\"\"Constructor for `Perturbation.from_nlpaug`.\"\"\" return __construct(cls, OneToOnePerturbation.from_nlpaug, OneToManyPerturbation.from_nlpaug, **kwargs) def __random_character_fn(string: str, function: Callable) -> str: \"\"\"Apply a function to random characters in a string.\"\"\" if len(string) == 0: return string random_indices = np.random.choice(range(len(string)), size=np.random.randint(1, len(string)), replace=False) for c in random_indices: string = string[:c] + function(string[c]) + string[c + 1:] return string def random_upper(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to uppercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.upper), label_to='random_upper', n=n) def random_lower(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to lowercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.lower), label_to='random_upper', n=n) def random_case_swap(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters case (lower to higher or vice versa). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.swapcase), label_to='random_upper', n=n) def random_spaces(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds random spaces within words (splits them up). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.SplitAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py \"\"\" return _nlpaug(naw.SplitAug, label_to='with_spaces', n=n, **kwargs) def add_typos(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds keyboard typos within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.KeyboardAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py \"\"\" return _nlpaug(nac.KeyboardAug, label_from='without_typos', label_to='with_typos', n=n, **kwargs) def swap_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='swap'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='swap', label_to='characters_swapped', n=n, **kwargs) def delete_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object with random character deletions in words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='delete'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='delete', label_to='characters_deleted', n=n, **kwargs) Functions add_typos 1 2 3 4 def add_typos ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that adds keyboard typos within words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See naw.KeyboardAug _ for optional constructor arguments. None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def add_typos(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds keyboard typos within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.KeyboardAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py \"\"\" return _nlpaug(nac.KeyboardAug, label_from='without_typos', label_to='with_typos', n=n, **kwargs) delete_random 1 2 3 4 def delete_random ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object with random character deletions in words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See nac.RandomCharAug _ for optional constructor arguments (uses action='delete' by default). None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def delete_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object with random character deletions in words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='delete'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='delete', label_to='characters_deleted', n=n, **kwargs) random_case_swap 1 2 3 def random_case_swap ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters case (lower to higher or vice versa). Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_case_swap(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters case (lower to higher or vice versa). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.swapcase), label_to='random_upper', n=n) random_lower 1 2 3 def random_lower ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters to lowercase. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_lower(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to lowercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.lower), label_to='random_upper', n=n) random_spaces 1 2 3 4 def random_spaces ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that adds random spaces within words (splits them up). Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See naw.SplitAug _ for optional constructor arguments. None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def random_spaces(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds random spaces within words (splits them up). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.SplitAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py \"\"\" return _nlpaug(naw.SplitAug, label_to='with_spaces', n=n, **kwargs) random_upper 1 2 3 def random_upper ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters to uppercase. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_upper(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to uppercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.upper), label_to='random_upper', n=n) swap_random 1 2 3 4 def swap_random ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters within words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See nac.RandomCharAug _ for optional constructor arguments (uses action='swap' by default). None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def swap_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='swap'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='swap', label_to='characters_swapped', n=n, **kwargs)","title":"Characters"},{"location":"reference/text_sensitivity/perturbation/characters/#module-text_sensitivityperturbationcharacters","text":"Create character-level perturbations ( text_sensitivity.perturbation.base.Perturbation ). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 \"\"\"Create character-level perturbations (`text_sensitivity.perturbation.base.Perturbation`).\"\"\" from typing import Callable import nlpaug.augmenter.char as nac import nlpaug.augmenter.word as naw import numpy as np from text_sensitivity.perturbation.base import (OneToManyPerturbation, OneToOnePerturbation, Perturbation) def __construct(cls_or_fn, constructor_one, constructor_many, **kwargs): \"\"\"Generic constructor, returning `constructor_many` if n > 1 else `constructor_one`.\"\"\" n = 1 label_from = kwargs.pop('label_from') if 'label_from' in kwargs else 'original' label_to = kwargs.pop('label_to') if 'label_to' in kwargs else 'perturbed' if 'n' in kwargs and isinstance(kwargs['n'], int): n = kwargs.pop('n') if not isinstance(cls_or_fn, (str, dict, Callable)) or isinstance(cls_or_fn, type): cls_or_fn = cls_or_fn(**kwargs) if n > 1: return constructor_many(cls_or_fn, n=n, label_from=label_from, label_to=label_to) return constructor_one(cls_or_fn, label_from=label_from, label_to=label_to) def _function(fn, **kwargs) -> Perturbation: \"\"\"Constructor for `Perturbation.from_function`.\"\"\" return __construct(fn, OneToOnePerturbation.from_function, OneToManyPerturbation.from_function, **kwargs) def _nlpaug(cls, **kwargs) -> Perturbation: \"\"\"Constructor for `Perturbation.from_nlpaug`.\"\"\" return __construct(cls, OneToOnePerturbation.from_nlpaug, OneToManyPerturbation.from_nlpaug, **kwargs) def __random_character_fn(string: str, function: Callable) -> str: \"\"\"Apply a function to random characters in a string.\"\"\" if len(string) == 0: return string random_indices = np.random.choice(range(len(string)), size=np.random.randint(1, len(string)), replace=False) for c in random_indices: string = string[:c] + function(string[c]) + string[c + 1:] return string def random_upper(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to uppercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.upper), label_to='random_upper', n=n) def random_lower(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to lowercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.lower), label_to='random_upper', n=n) def random_case_swap(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters case (lower to higher or vice versa). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.swapcase), label_to='random_upper', n=n) def random_spaces(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds random spaces within words (splits them up). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.SplitAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py \"\"\" return _nlpaug(naw.SplitAug, label_to='with_spaces', n=n, **kwargs) def add_typos(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds keyboard typos within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.KeyboardAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py \"\"\" return _nlpaug(nac.KeyboardAug, label_from='without_typos', label_to='with_typos', n=n, **kwargs) def swap_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='swap'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='swap', label_to='characters_swapped', n=n, **kwargs) def delete_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object with random character deletions in words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='delete'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='delete', label_to='characters_deleted', n=n, **kwargs)","title":"Module text_sensitivity.perturbation.characters"},{"location":"reference/text_sensitivity/perturbation/characters/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/perturbation/characters/#add_typos","text":"1 2 3 4 def add_typos ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that adds keyboard typos within words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See naw.KeyboardAug _ for optional constructor arguments. None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def add_typos(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds keyboard typos within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.KeyboardAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.KeyboardAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/keyboard.py \"\"\" return _nlpaug(nac.KeyboardAug, label_from='without_typos', label_to='with_typos', n=n, **kwargs)","title":"add_typos"},{"location":"reference/text_sensitivity/perturbation/characters/#delete_random","text":"1 2 3 4 def delete_random ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object with random character deletions in words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See nac.RandomCharAug _ for optional constructor arguments (uses action='delete' by default). None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def delete_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object with random character deletions in words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='delete'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='delete', label_to='characters_deleted', n=n, **kwargs)","title":"delete_random"},{"location":"reference/text_sensitivity/perturbation/characters/#random_case_swap","text":"1 2 3 def random_case_swap ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters case (lower to higher or vice versa). Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_case_swap(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters case (lower to higher or vice versa). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.swapcase), label_to='random_upper', n=n)","title":"random_case_swap"},{"location":"reference/text_sensitivity/perturbation/characters/#random_lower","text":"1 2 3 def random_lower ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters to lowercase. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_lower(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to lowercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.lower), label_to='random_upper', n=n)","title":"random_lower"},{"location":"reference/text_sensitivity/perturbation/characters/#random_spaces","text":"1 2 3 4 def random_spaces ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that adds random spaces within words (splits them up). Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See naw.SplitAug _ for optional constructor arguments. None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def random_spaces(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that adds random spaces within words (splits them up). Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `naw.SplitAug`_ for optional constructor arguments. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _naw.SplitAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/word/split.py \"\"\" return _nlpaug(naw.SplitAug, label_to='with_spaces', n=n, **kwargs)","title":"random_spaces"},{"location":"reference/text_sensitivity/perturbation/characters/#random_upper","text":"1 2 3 def random_upper ( n : int = 1 ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters to uppercase. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def random_upper(n: int = 1) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters to uppercase. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. \"\"\" return _function(lambda x: __random_character_fn(x, str.upper), label_to='random_upper', n=n)","title":"random_upper"},{"location":"reference/text_sensitivity/perturbation/characters/#swap_random","text":"1 2 3 4 def swap_random ( n : int = 1 , ** kwargs ) -> text_sensitivity . perturbation . base . Perturbation Create a Perturbation object that randomly swaps characters within words. Parameters: Name Type Description Default n int Number of perturbed instances required. Defaults to 1. 1 **kwargs None See nac.RandomCharAug _ for optional constructor arguments (uses action='swap' by default). None Returns: Type Description Perturbation Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def swap_random(n: int = 1, **kwargs) -> Perturbation: \"\"\"Create a `Perturbation` object that randomly swaps characters within words. Args: n (int, optional): Number of perturbed instances required. Defaults to 1. **kwargs: See `nac.RandomCharAug`_ for optional constructor arguments (uses `action='swap'` by default). Returns: Perturbation: Object able to apply perturbations on strings or TextInstances. .. _nac.RandomCharAug: https://github.com/makcedward/nlpaug/blob/master/nlpaug/augmenter/char/random.py \"\"\" return _nlpaug(nac.RandomCharAug, action='swap', label_to='characters_swapped', n=n, **kwargs)","title":"swap_random"},{"location":"reference/text_sensitivity/perturbation/sentences/","text":"Module text_sensitivity.perturbation.sentences Create sentence-level perturbations ( text_sensitivity.perturbation.base.Perturbation ). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \"\"\"Create sentence-level perturbations (`text_sensitivity.perturbation.base.Perturbation`).\"\"\" from typing import Optional from text_sensitivity.perturbation.base import OneToOnePerturbation def to_upper() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.upper, 'not_upper', 'upper') def to_lower() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.lower, 'not_lower', 'lower') def repeat_k_times(k: int = 10, connector: Optional[str] = ' '): \"\"\"Repeat a string k times.\"\"\" if connector is None: connector = '' def repeat_k(string: str) -> str: return connector.join([string] * k) return OneToOnePerturbation.from_function(repeat_k, label_to='repeated') Functions repeat_k_times 1 2 3 4 def repeat_k_times ( k : int = 10 , connector : Optional [ str ] = ' ' ) Repeat a string k times. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def repeat_k_times(k: int = 10, connector: Optional[str] = ' '): \"\"\"Repeat a string k times.\"\"\" if connector is None: connector = '' def repeat_k(string: str) -> str: return connector.join([string] * k) return OneToOnePerturbation.from_function(repeat_k, label_to='repeated') to_lower 1 2 3 def to_lower ( ) -> text_sensitivity . perturbation . base . OneToOnePerturbation View Source 1 2 3 def to_lower() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.lower, 'not_lower', 'lower') to_upper 1 2 3 def to_upper ( ) -> text_sensitivity . perturbation . base . OneToOnePerturbation View Source 1 2 3 def to_upper() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.upper, 'not_upper', 'upper')","title":"Sentences"},{"location":"reference/text_sensitivity/perturbation/sentences/#module-text_sensitivityperturbationsentences","text":"Create sentence-level perturbations ( text_sensitivity.perturbation.base.Perturbation ). None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \"\"\"Create sentence-level perturbations (`text_sensitivity.perturbation.base.Perturbation`).\"\"\" from typing import Optional from text_sensitivity.perturbation.base import OneToOnePerturbation def to_upper() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.upper, 'not_upper', 'upper') def to_lower() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.lower, 'not_lower', 'lower') def repeat_k_times(k: int = 10, connector: Optional[str] = ' '): \"\"\"Repeat a string k times.\"\"\" if connector is None: connector = '' def repeat_k(string: str) -> str: return connector.join([string] * k) return OneToOnePerturbation.from_function(repeat_k, label_to='repeated')","title":"Module text_sensitivity.perturbation.sentences"},{"location":"reference/text_sensitivity/perturbation/sentences/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/perturbation/sentences/#repeat_k_times","text":"1 2 3 4 def repeat_k_times ( k : int = 10 , connector : Optional [ str ] = ' ' ) Repeat a string k times. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 def repeat_k_times(k: int = 10, connector: Optional[str] = ' '): \"\"\"Repeat a string k times.\"\"\" if connector is None: connector = '' def repeat_k(string: str) -> str: return connector.join([string] * k) return OneToOnePerturbation.from_function(repeat_k, label_to='repeated')","title":"repeat_k_times"},{"location":"reference/text_sensitivity/perturbation/sentences/#to_lower","text":"1 2 3 def to_lower ( ) -> text_sensitivity . perturbation . base . OneToOnePerturbation View Source 1 2 3 def to_lower() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.lower, 'not_lower', 'lower')","title":"to_lower"},{"location":"reference/text_sensitivity/perturbation/sentences/#to_upper","text":"1 2 3 def to_upper ( ) -> text_sensitivity . perturbation . base . OneToOnePerturbation View Source 1 2 3 def to_upper() -> OneToOnePerturbation: return OneToOnePerturbation.from_function(str.upper, 'not_upper', 'upper')","title":"to_upper"},{"location":"reference/text_sensitivity/perturbation/words/","text":"Module text_sensitivity.perturbation.words Create word-level perturbations ( text_sensitivity.perturbation.base.Perturbation ). None View Source 1 \"\"\"Create word-level perturbations (`text_sensitivity.perturbation.base.Perturbation`).\"\"\"","title":"Words"},{"location":"reference/text_sensitivity/perturbation/words/#module-text_sensitivityperturbationwords","text":"Create word-level perturbations ( text_sensitivity.perturbation.base.Perturbation ). None View Source 1 \"\"\"Create word-level perturbations (`text_sensitivity.perturbation.base.Perturbation`).\"\"\"","title":"Module text_sensitivity.perturbation.words"},{"location":"reference/text_sensitivity/ui/","text":"Module text_sensitivity.ui None None Sub-modules text_sensitivity.ui.notebook","title":"Index"},{"location":"reference/text_sensitivity/ui/#module-text_sensitivityui","text":"None None","title":"Module text_sensitivity.ui"},{"location":"reference/text_sensitivity/ui/#sub-modules","text":"text_sensitivity.ui.notebook","title":"Sub-modules"},{"location":"reference/text_sensitivity/ui/notebook/","text":"Module text_sensitivity.ui.notebook Extension of genbase.ui.notebook for custom rendering of `text_sensitivity. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 \"\"\"Extension of `genbase.ui.notebook` for custom rendering of `text_sensitivity.\"\"\" import copy from genbase.ui import get_color from genbase.ui.notebook import Render as BaseRender from genbase.ui.notebook import format_instances from text_explainability.ui.notebook import (default_renderer, get_meta_descriptors) TEST_EXP = {'robustness+input_space': 'This sensitivity test checks if your model is able to handle ' + 'different input character (sequences) without throwing errors.', 'sensitivity+invariance': 'This sensitivity test has the assumption that all instances will have the ' + 'same expected prediction for all instances.'} def success_test_renderer(meta: dict, content: dict, **renderargs) -> str: def h(title): return f'<h3>{title}</h3>' def none_to_show(success_failure: str, succeeded_failed: str): return f'<p>No {success_failure} to show, because all instances {succeeded_failed}.</p>' n_success, n_fail = len(content['successes']), len(content['failures']) kwargs = {'predictions': content['predictions']} if 'predictions' in content else {} color = get_color(content['success_percentage'], min_value=0.0, max_value=1.0, colorscale=[(0, '#A50026'), (0.5, '#BBBB00'), (1.0, '#006837')]) html = h('Test results') html += f'<p style=\"font-size: 110%\">Success: <b style=\"color: {color}\">{content[\"success_percentage\"]:0.00%}</b> ' html += f'({n_success} out of {n_success + n_fail}).</p>' html += h('Success') html += format_instances(content['successes'], **kwargs) if n_success > 0 \\ else none_to_show('successes', 'failed') html += h('Failures') html += format_instances(content['failures'], **kwargs) if n_fail \\ else none_to_show('failures', 'succeeded') return html class Render(BaseRender): def __init__(self, *configs): super().__init__(*configs) self.main_color = '#D32F2F' self.package_link = 'https://git.io/text_sensitivity' @property def tab_title(self): return 'Sensitivity Test Results' @property def custom_tab_title(self): return 'Test Settings' def get_renderer(self, meta: dict): type, subtype, _ = get_meta_descriptors(meta) if type == 'robustness': if subtype == 'input_space': return success_test_renderer if subtype == 'invariance': return success_test_renderer return default_renderer def format_title(self, title: str, h: str = 'h1', **renderargs) -> str: return super().format_title(title, h=h, **renderargs).replace('_', ' ').title() def render_subtitle(self, meta: dict, content, **renderargs) -> str: type, subtype, _ = get_meta_descriptors(meta) name = f'{type}+{subtype}' return self.format_subtitle(TEST_EXP[name]) if name in TEST_EXP else '' def custom_tab(self, config: dict, **renderargs) -> str: meta = config[\"META\"] if 'callargs' not in meta: return '' callargs = copy.deepcopy(meta['callargs']) _ = callargs.pop('__name__') _ = callargs.pop('model') if 'kwargs' in callargs: kwargs = callargs.pop('kwargs') for k, v in kwargs.items(): callargs[k] = v def fmt(k, v) -> str: if isinstance(v, list): return '<ul>' + ''.join([f'<li>{fmt(k, v_)}</li>' for v_ in v]) + '</ul>' elif isinstance(v, dict) and '__class__' in v: if v['__class__'].startswith('text_sensitivity.data.random.string'): options = v['options'] if isinstance(options, str): options = f'\"{options}\"' return f'<kbd>{v[\"__class__\"]}</kbd> ({options})' elif str.lower(k) == 'expectation': return f'<kbd>{v}</kbd>' return str(v) html = ''.join([f'<tr><td>{k}:</td><td>{fmt(k, v)}</td></tr>' for k, v in callargs.items()]) return f'<div class=\"table-wrapper\"><table class=\"sensitivity-test-settings\">{html}</table></div>' Variables 1 TEST_EXP Functions success_test_renderer 1 2 3 4 5 def success_test_renderer ( meta : dict , content : dict , ** renderargs ) -> str View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def success_test_renderer(meta: dict, content: dict, **renderargs) -> str: def h(title): return f'<h3>{title}</h3>' def none_to_show(success_failure: str, succeeded_failed: str): return f'<p>No {success_failure} to show, because all instances {succeeded_failed}.</p>' n_success, n_fail = len(content['successes']), len(content['failures']) kwargs = {'predictions': content['predictions']} if 'predictions' in content else {} color = get_color(content['success_percentage'], min_value=0.0, max_value=1.0, colorscale=[(0, '#A50026'), (0.5, '#BBBB00'), (1.0, '#006837')]) html = h('Test results') html += f'<p style=\"font-size: 110%\">Success: <b style=\"color: {color}\">{content[\"success_percentage\"]:0.00%}</b> ' html += f'({n_success} out of {n_success + n_fail}).</p>' html += h('Success') html += format_instances(content['successes'], **kwargs) if n_success > 0 \\ else none_to_show('successes', 'failed') html += h('Failures') html += format_instances(content['failures'], **kwargs) if n_fail \\ else none_to_show('failures', 'succeeded') return html Classes Render 1 2 3 class Render ( * configs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class Render(BaseRender): def __init__(self, *configs): super().__init__(*configs) self.main_color = '#D32F2F' self.package_link = 'https://git.io/text_sensitivity' @property def tab_title(self): return 'Sensitivity Test Results' @property def custom_tab_title(self): return 'Test Settings' def get_renderer(self, meta: dict): type, subtype, _ = get_meta_descriptors(meta) if type == 'robustness': if subtype == 'input_space': return success_test_renderer if subtype == 'invariance': return success_test_renderer return default_renderer def format_title(self, title: str, h: str = 'h1', **renderargs) -> str: return super().format_title(title, h=h, **renderargs).replace('_', ' ').title() def render_subtitle(self, meta: dict, content, **renderargs) -> str: type, subtype, _ = get_meta_descriptors(meta) name = f'{type}+{subtype}' return self.format_subtitle(TEST_EXP[name]) if name in TEST_EXP else '' def custom_tab(self, config: dict, **renderargs) -> str: meta = config[\"META\"] if 'callargs' not in meta: return '' callargs = copy.deepcopy(meta['callargs']) _ = callargs.pop('__name__') _ = callargs.pop('model') if 'kwargs' in callargs: kwargs = callargs.pop('kwargs') for k, v in kwargs.items(): callargs[k] = v def fmt(k, v) -> str: if isinstance(v, list): return '<ul>' + ''.join([f'<li>{fmt(k, v_)}</li>' for v_ in v]) + '</ul>' elif isinstance(v, dict) and '__class__' in v: if v['__class__'].startswith('text_sensitivity.data.random.string'): options = v['options'] if isinstance(options, str): options = f'\"{options}\"' return f'<kbd>{v[\"__class__\"]}</kbd> ({options})' elif str.lower(k) == 'expectation': return f'<kbd>{v}</kbd>' return str(v) html = ''.join([f'<tr><td>{k}:</td><td>{fmt(k, v)}</td></tr>' for k, v in callargs.items()]) return f'<div class=\"table-wrapper\"><table class=\"sensitivity-test-settings\">{html}</table></div>' Ancestors (in MRO) genbase.ui.notebook.Render Instance variables 1 custom_tab_title 1 package_name 1 tab_title Methods as_html 1 2 3 4 def as_html ( self , ** renderargs ) -> str Get HTML element for interactive environments (e.g. Jupyter notebook). Parameters: Name Type Description Default **renderags None Optional arguments for rendering. None Returns: Type Description str HTML element. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def as_html(self, **renderargs) -> str: \"\"\"Get HTML element for interactive environments (e.g. Jupyter notebook). Args: **renderags: Optional arguments for rendering. Returns: str: HTML element. \"\"\" def fmt_exception(e: Exception, fmt_type: str = 'JSON') -> str: res = f'ERROR IN PARSING {fmt_type}\\n' res += '=' * len(res) + '\\n' return res + '\\n'.join(traceback.TracebackException.from_exception(e).format()) try: json = '\\n'.join(srsly.json_dumps(config, indent=2) for config in self.configs) except TypeError as e: json = fmt_exception(e, fmt_type='JSON') try: yaml = '\\n'.join(srsly.yaml_dumps(config) for config in self.configs) except srsly.ruamel_yaml.representer.RepresenterError as e: yaml = fmt_exception(e, fmt_type='YAML') html = ''.join(self.render_elements(config, **renderargs) for config in self.configs) id = str(uuid.uuid4()) tabs_id = f'tabs-{id}' ui_id = f'ui-{id}' CUSTOM_TAB = ''.join(self.custom_tab(config, **renderargs) for config in self.configs) if CUSTOM_TAB: CUSTOM_TAB = f\"\"\"<input type=\"radio\" name=\"{tabs_id}\" id=\"{tabs_id}-tab2\"/> <label class=\"wide\" for=\"{tabs_id}-tab2\">{self.custom_tab_title}</label> <div class=\"tab\">{CUSTOM_TAB}</div>\"\"\" HTML = f\"\"\" <div id=\"{ui_id}\"> <section class=\"ui-wrapper\"> <div class=\"ui-container\"> <div class=\"ui-block\"> <div id=\"{tabs_id}\"> <input type=\"radio\" name=\"{tabs_id}\" id=\"{tabs_id}-tab1\" checked=\"checked\" /> <label class=\"wide\" for=\"{tabs_id}-tab1\">{self.tab_title}</label> <div class=\"tab\">{html}</div> {CUSTOM_TAB} <input type=\"radio\" name=\"{tabs_id}\" id=\"{tabs_id}-tab{'3' if CUSTOM_TAB else '2'}\" /> <label for=\"{tabs_id}-tab{'3' if CUSTOM_TAB else '2'}\">{self.config_title}</label> <div class=\"tab code\"> <section> <div class=\"pre-buttons\"> <a onclick=\"copy('json-output')\" href=\"#\" title=\"Copy JSON to clipboard\"> {CLONE_SVG} </a> </div> <h3>JSON</h3> </section> <pre id=\"json-output\">{json}</pre> <section> <div class=\"pre-buttons\"> <a onclick=\"copy('yaml-output')\" href=\"#\" title=\"Copy YAML to clipboard\"> {CLONE_SVG} </a> </div> <h3>YAML</h3> </section> <pre id=\"yaml-output\">{yaml}</pre> </div> </div> </div> </div> </section> </div> \"\"\" JS = f'<script type=\"text/javascript\">{CUSTOM_JS}</script>' if CUSTOM_JS else '' main_color = renderargs.pop('main_color', self.main_color) package = renderargs.pop('package_link', self.package_link) package_name = self.package_name CSS = self.css(ui_color=main_color, ui_id=ui_id, tabs_id=tabs_id) FOOTER = f'<footer>Generated with <a href=\"{package}\" target=\"_blank\">{package_name}</a></footer>' return f'<style>{CSS}</style>{HTML}{FOOTER}{JS}' css 1 2 3 4 def css ( self , ** replacement_kwargs ) View Source 1 2 3 4 5 6 7 8 9 def css(self, **replacement_kwargs): css_ = CUSTOM_CSS + '\\n' + self.extra_css for k, v in replacement_kwargs.items(): css_ = css_.replace(f'--var({k})', v) return css_ custom_tab 1 2 3 4 5 def custom_tab ( self , config : dict , ** renderargs ) -> str View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def custom_tab(self, config: dict, **renderargs) -> str: meta = config[\"META\"] if 'callargs' not in meta: return '' callargs = copy.deepcopy(meta['callargs']) _ = callargs.pop('__name__') _ = callargs.pop('model') if 'kwargs' in callargs: kwargs = callargs.pop('kwargs') for k, v in kwargs.items(): callargs[k] = v def fmt(k, v) -> str: if isinstance(v, list): return '<ul>' + ''.join([f'<li>{fmt(k, v_)}</li>' for v_ in v]) + '</ul>' elif isinstance(v, dict) and '__class__' in v: if v['__class__'].startswith('text_sensitivity.data.random.string'): options = v['options'] if isinstance(options, str): options = f'\"{options}\"' return f'<kbd>{v[\"__class__\"]}</kbd> ({options})' elif str.lower(k) == 'expectation': return f'<kbd>{v}</kbd>' return str(v) html = ''.join([f'<tr><td>{k}:</td><td>{fmt(k, v)}</td></tr>' for k, v in callargs.items()]) return f'<div class=\"table-wrapper\"><table class=\"sensitivity-test-settings\">{html}</table></div>' format_subtitle 1 2 3 4 def format_subtitle ( self , subtitle : str ) -> str Format the subtitle in HTML format. Parameters: Name Type Description Default subtitle str Subtitle contents. None Returns: Type Description str Formatted subtitle. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def format_subtitle(self, subtitle: str) -> str: \"\"\"Format the subtitle in HTML format. Args: subtitle (str): Subtitle contents. Returns: str: Formatted subtitle. \"\"\" return f'<p class=\"info\">{subtitle}</p>' format_title 1 2 3 4 5 6 def format_title ( self , title : str , h : str = 'h1' , ** renderargs ) -> str Format title in HTML format. Parameters: Name Type Description Default title str Title contents. None h str h-tag (h1, h2, ...). Defaults to 'h1'. 'h1' Returns: Type Description str Formatted title. View Source 1 2 3 def format_title(self, title: str, h: str = 'h1', **renderargs) -> str: return super().format_title(title, h=h, **renderargs).replace('_', ' ').title() get_renderer 1 2 3 4 def get_renderer ( self , meta : dict ) Get a render function (Callable taking meta , content and **renderargs and returning a str ). Parameters: Name Type Description Default meta dict Meta information to decide on appropriate renderer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def get_renderer(self, meta: dict): type, subtype, _ = get_meta_descriptors(meta) if type == 'robustness': if subtype == 'input_space': return success_test_renderer if subtype == 'invariance': return success_test_renderer return default_renderer render_content 1 2 3 4 5 6 def render_content ( self , meta : dict , content : dict , ** renderargs ) -> str Render content as HTML. Overwrite this when subclassing for your custom implementation. Parameters: Name Type Description Default meta dict Meta config. None content dict Content config. None **renderags None Optional arguments for rendering. None Returns: Type Description str Formatted content. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def render_content(self, meta: dict, content: dict, **renderargs) -> str: \"\"\"Render content as HTML. Overwrite this when subclassing for your custom implementation. Args: meta (dict): Meta config. content (dict): Content config. **renderags: Optional arguments for rendering. Returns: str: Formatted content. \"\"\" renderer = self.get_renderer(meta) return renderer(meta, content, **renderargs) render_elements 1 2 3 4 5 def render_elements ( self , config : dict , ** renderargs ) -> str Render HTML title and content. Parameters: Name Type Description Default config dict Config meta & content. None **renderags None Optional arguments for rendering. None Returns: Type Description str Formatted title and content. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def render_elements(self, config: dict, **renderargs) -> str: \"\"\"Render HTML title and content. Args: config (dict): Config meta & content. **renderags: Optional arguments for rendering. Returns: str: Formatted title and content. \"\"\" meta, content = config['META'], config['CONTENT'] return self.render_title(meta, content, **renderargs) + \\ self.render_subtitle(meta, content, **renderargs) + \\ self.render_content(meta, content, **renderargs) render_subtitle 1 2 3 4 5 6 def render_subtitle ( self , meta : dict , content , ** renderargs ) -> str View Source 1 2 3 4 5 6 7 def render_subtitle(self, meta: dict, content, **renderargs) -> str: type, subtype, _ = get_meta_descriptors(meta) name = f'{type}+{subtype}' return self.format_subtitle(TEST_EXP[name]) if name in TEST_EXP else '' render_title 1 2 3 4 5 6 def render_title ( self , meta : dict , content : dict , ** renderargs ) -> str Render the title as HTML. Overwrite this when subclassing for your custom implementation. Parameters: Name Type Description Default meta dict Meta config. None content dict Content config. None **renderags None Optional arguments for rendering. None Returns: Type Description str Formatted title. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def render_title(self, meta: dict, content: dict, **renderargs) -> str: \"\"\"Render the title as HTML. Overwrite this when subclassing for your custom implementation. Args: meta (dict): Meta config. content (dict): Content config. **renderags: Optional arguments for rendering. Returns: str: Formatted title. \"\"\" title = renderargs.pop('title', None) if title is None: if 'title' in meta: title = meta['title'] elif 'type' in meta: title = meta['type'] if 'subtype' in meta: title += f' ({meta[\"subtype\"]})' return self.format_title(title, **renderargs) if title else ''","title":"Notebook"},{"location":"reference/text_sensitivity/ui/notebook/#module-text_sensitivityuinotebook","text":"Extension of genbase.ui.notebook for custom rendering of `text_sensitivity. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 \"\"\"Extension of `genbase.ui.notebook` for custom rendering of `text_sensitivity.\"\"\" import copy from genbase.ui import get_color from genbase.ui.notebook import Render as BaseRender from genbase.ui.notebook import format_instances from text_explainability.ui.notebook import (default_renderer, get_meta_descriptors) TEST_EXP = {'robustness+input_space': 'This sensitivity test checks if your model is able to handle ' + 'different input character (sequences) without throwing errors.', 'sensitivity+invariance': 'This sensitivity test has the assumption that all instances will have the ' + 'same expected prediction for all instances.'} def success_test_renderer(meta: dict, content: dict, **renderargs) -> str: def h(title): return f'<h3>{title}</h3>' def none_to_show(success_failure: str, succeeded_failed: str): return f'<p>No {success_failure} to show, because all instances {succeeded_failed}.</p>' n_success, n_fail = len(content['successes']), len(content['failures']) kwargs = {'predictions': content['predictions']} if 'predictions' in content else {} color = get_color(content['success_percentage'], min_value=0.0, max_value=1.0, colorscale=[(0, '#A50026'), (0.5, '#BBBB00'), (1.0, '#006837')]) html = h('Test results') html += f'<p style=\"font-size: 110%\">Success: <b style=\"color: {color}\">{content[\"success_percentage\"]:0.00%}</b> ' html += f'({n_success} out of {n_success + n_fail}).</p>' html += h('Success') html += format_instances(content['successes'], **kwargs) if n_success > 0 \\ else none_to_show('successes', 'failed') html += h('Failures') html += format_instances(content['failures'], **kwargs) if n_fail \\ else none_to_show('failures', 'succeeded') return html class Render(BaseRender): def __init__(self, *configs): super().__init__(*configs) self.main_color = '#D32F2F' self.package_link = 'https://git.io/text_sensitivity' @property def tab_title(self): return 'Sensitivity Test Results' @property def custom_tab_title(self): return 'Test Settings' def get_renderer(self, meta: dict): type, subtype, _ = get_meta_descriptors(meta) if type == 'robustness': if subtype == 'input_space': return success_test_renderer if subtype == 'invariance': return success_test_renderer return default_renderer def format_title(self, title: str, h: str = 'h1', **renderargs) -> str: return super().format_title(title, h=h, **renderargs).replace('_', ' ').title() def render_subtitle(self, meta: dict, content, **renderargs) -> str: type, subtype, _ = get_meta_descriptors(meta) name = f'{type}+{subtype}' return self.format_subtitle(TEST_EXP[name]) if name in TEST_EXP else '' def custom_tab(self, config: dict, **renderargs) -> str: meta = config[\"META\"] if 'callargs' not in meta: return '' callargs = copy.deepcopy(meta['callargs']) _ = callargs.pop('__name__') _ = callargs.pop('model') if 'kwargs' in callargs: kwargs = callargs.pop('kwargs') for k, v in kwargs.items(): callargs[k] = v def fmt(k, v) -> str: if isinstance(v, list): return '<ul>' + ''.join([f'<li>{fmt(k, v_)}</li>' for v_ in v]) + '</ul>' elif isinstance(v, dict) and '__class__' in v: if v['__class__'].startswith('text_sensitivity.data.random.string'): options = v['options'] if isinstance(options, str): options = f'\"{options}\"' return f'<kbd>{v[\"__class__\"]}</kbd> ({options})' elif str.lower(k) == 'expectation': return f'<kbd>{v}</kbd>' return str(v) html = ''.join([f'<tr><td>{k}:</td><td>{fmt(k, v)}</td></tr>' for k, v in callargs.items()]) return f'<div class=\"table-wrapper\"><table class=\"sensitivity-test-settings\">{html}</table></div>'","title":"Module text_sensitivity.ui.notebook"},{"location":"reference/text_sensitivity/ui/notebook/#variables","text":"1 TEST_EXP","title":"Variables"},{"location":"reference/text_sensitivity/ui/notebook/#functions","text":"","title":"Functions"},{"location":"reference/text_sensitivity/ui/notebook/#success_test_renderer","text":"1 2 3 4 5 def success_test_renderer ( meta : dict , content : dict , ** renderargs ) -> str View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def success_test_renderer(meta: dict, content: dict, **renderargs) -> str: def h(title): return f'<h3>{title}</h3>' def none_to_show(success_failure: str, succeeded_failed: str): return f'<p>No {success_failure} to show, because all instances {succeeded_failed}.</p>' n_success, n_fail = len(content['successes']), len(content['failures']) kwargs = {'predictions': content['predictions']} if 'predictions' in content else {} color = get_color(content['success_percentage'], min_value=0.0, max_value=1.0, colorscale=[(0, '#A50026'), (0.5, '#BBBB00'), (1.0, '#006837')]) html = h('Test results') html += f'<p style=\"font-size: 110%\">Success: <b style=\"color: {color}\">{content[\"success_percentage\"]:0.00%}</b> ' html += f'({n_success} out of {n_success + n_fail}).</p>' html += h('Success') html += format_instances(content['successes'], **kwargs) if n_success > 0 \\ else none_to_show('successes', 'failed') html += h('Failures') html += format_instances(content['failures'], **kwargs) if n_fail \\ else none_to_show('failures', 'succeeded') return html","title":"success_test_renderer"},{"location":"reference/text_sensitivity/ui/notebook/#classes","text":"","title":"Classes"},{"location":"reference/text_sensitivity/ui/notebook/#render","text":"1 2 3 class Render ( * configs ) View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class Render(BaseRender): def __init__(self, *configs): super().__init__(*configs) self.main_color = '#D32F2F' self.package_link = 'https://git.io/text_sensitivity' @property def tab_title(self): return 'Sensitivity Test Results' @property def custom_tab_title(self): return 'Test Settings' def get_renderer(self, meta: dict): type, subtype, _ = get_meta_descriptors(meta) if type == 'robustness': if subtype == 'input_space': return success_test_renderer if subtype == 'invariance': return success_test_renderer return default_renderer def format_title(self, title: str, h: str = 'h1', **renderargs) -> str: return super().format_title(title, h=h, **renderargs).replace('_', ' ').title() def render_subtitle(self, meta: dict, content, **renderargs) -> str: type, subtype, _ = get_meta_descriptors(meta) name = f'{type}+{subtype}' return self.format_subtitle(TEST_EXP[name]) if name in TEST_EXP else '' def custom_tab(self, config: dict, **renderargs) -> str: meta = config[\"META\"] if 'callargs' not in meta: return '' callargs = copy.deepcopy(meta['callargs']) _ = callargs.pop('__name__') _ = callargs.pop('model') if 'kwargs' in callargs: kwargs = callargs.pop('kwargs') for k, v in kwargs.items(): callargs[k] = v def fmt(k, v) -> str: if isinstance(v, list): return '<ul>' + ''.join([f'<li>{fmt(k, v_)}</li>' for v_ in v]) + '</ul>' elif isinstance(v, dict) and '__class__' in v: if v['__class__'].startswith('text_sensitivity.data.random.string'): options = v['options'] if isinstance(options, str): options = f'\"{options}\"' return f'<kbd>{v[\"__class__\"]}</kbd> ({options})' elif str.lower(k) == 'expectation': return f'<kbd>{v}</kbd>' return str(v) html = ''.join([f'<tr><td>{k}:</td><td>{fmt(k, v)}</td></tr>' for k, v in callargs.items()]) return f'<div class=\"table-wrapper\"><table class=\"sensitivity-test-settings\">{html}</table></div>'","title":"Render"},{"location":"reference/text_sensitivity/ui/notebook/#ancestors-in-mro","text":"genbase.ui.notebook.Render","title":"Ancestors (in MRO)"},{"location":"reference/text_sensitivity/ui/notebook/#instance-variables","text":"1 custom_tab_title 1 package_name 1 tab_title","title":"Instance variables"},{"location":"reference/text_sensitivity/ui/notebook/#methods","text":"","title":"Methods"},{"location":"reference/text_sensitivity/ui/notebook/#as_html","text":"1 2 3 4 def as_html ( self , ** renderargs ) -> str Get HTML element for interactive environments (e.g. Jupyter notebook). Parameters: Name Type Description Default **renderags None Optional arguments for rendering. None Returns: Type Description str HTML element. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def as_html(self, **renderargs) -> str: \"\"\"Get HTML element for interactive environments (e.g. Jupyter notebook). Args: **renderags: Optional arguments for rendering. Returns: str: HTML element. \"\"\" def fmt_exception(e: Exception, fmt_type: str = 'JSON') -> str: res = f'ERROR IN PARSING {fmt_type}\\n' res += '=' * len(res) + '\\n' return res + '\\n'.join(traceback.TracebackException.from_exception(e).format()) try: json = '\\n'.join(srsly.json_dumps(config, indent=2) for config in self.configs) except TypeError as e: json = fmt_exception(e, fmt_type='JSON') try: yaml = '\\n'.join(srsly.yaml_dumps(config) for config in self.configs) except srsly.ruamel_yaml.representer.RepresenterError as e: yaml = fmt_exception(e, fmt_type='YAML') html = ''.join(self.render_elements(config, **renderargs) for config in self.configs) id = str(uuid.uuid4()) tabs_id = f'tabs-{id}' ui_id = f'ui-{id}' CUSTOM_TAB = ''.join(self.custom_tab(config, **renderargs) for config in self.configs) if CUSTOM_TAB: CUSTOM_TAB = f\"\"\"<input type=\"radio\" name=\"{tabs_id}\" id=\"{tabs_id}-tab2\"/> <label class=\"wide\" for=\"{tabs_id}-tab2\">{self.custom_tab_title}</label> <div class=\"tab\">{CUSTOM_TAB}</div>\"\"\" HTML = f\"\"\" <div id=\"{ui_id}\"> <section class=\"ui-wrapper\"> <div class=\"ui-container\"> <div class=\"ui-block\"> <div id=\"{tabs_id}\"> <input type=\"radio\" name=\"{tabs_id}\" id=\"{tabs_id}-tab1\" checked=\"checked\" /> <label class=\"wide\" for=\"{tabs_id}-tab1\">{self.tab_title}</label> <div class=\"tab\">{html}</div> {CUSTOM_TAB} <input type=\"radio\" name=\"{tabs_id}\" id=\"{tabs_id}-tab{'3' if CUSTOM_TAB else '2'}\" /> <label for=\"{tabs_id}-tab{'3' if CUSTOM_TAB else '2'}\">{self.config_title}</label> <div class=\"tab code\"> <section> <div class=\"pre-buttons\"> <a onclick=\"copy('json-output')\" href=\"#\" title=\"Copy JSON to clipboard\"> {CLONE_SVG} </a> </div> <h3>JSON</h3> </section> <pre id=\"json-output\">{json}</pre> <section> <div class=\"pre-buttons\"> <a onclick=\"copy('yaml-output')\" href=\"#\" title=\"Copy YAML to clipboard\"> {CLONE_SVG} </a> </div> <h3>YAML</h3> </section> <pre id=\"yaml-output\">{yaml}</pre> </div> </div> </div> </div> </section> </div> \"\"\" JS = f'<script type=\"text/javascript\">{CUSTOM_JS}</script>' if CUSTOM_JS else '' main_color = renderargs.pop('main_color', self.main_color) package = renderargs.pop('package_link', self.package_link) package_name = self.package_name CSS = self.css(ui_color=main_color, ui_id=ui_id, tabs_id=tabs_id) FOOTER = f'<footer>Generated with <a href=\"{package}\" target=\"_blank\">{package_name}</a></footer>' return f'<style>{CSS}</style>{HTML}{FOOTER}{JS}'","title":"as_html"},{"location":"reference/text_sensitivity/ui/notebook/#css","text":"1 2 3 4 def css ( self , ** replacement_kwargs ) View Source 1 2 3 4 5 6 7 8 9 def css(self, **replacement_kwargs): css_ = CUSTOM_CSS + '\\n' + self.extra_css for k, v in replacement_kwargs.items(): css_ = css_.replace(f'--var({k})', v) return css_","title":"css"},{"location":"reference/text_sensitivity/ui/notebook/#custom_tab","text":"1 2 3 4 5 def custom_tab ( self , config : dict , ** renderargs ) -> str View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def custom_tab(self, config: dict, **renderargs) -> str: meta = config[\"META\"] if 'callargs' not in meta: return '' callargs = copy.deepcopy(meta['callargs']) _ = callargs.pop('__name__') _ = callargs.pop('model') if 'kwargs' in callargs: kwargs = callargs.pop('kwargs') for k, v in kwargs.items(): callargs[k] = v def fmt(k, v) -> str: if isinstance(v, list): return '<ul>' + ''.join([f'<li>{fmt(k, v_)}</li>' for v_ in v]) + '</ul>' elif isinstance(v, dict) and '__class__' in v: if v['__class__'].startswith('text_sensitivity.data.random.string'): options = v['options'] if isinstance(options, str): options = f'\"{options}\"' return f'<kbd>{v[\"__class__\"]}</kbd> ({options})' elif str.lower(k) == 'expectation': return f'<kbd>{v}</kbd>' return str(v) html = ''.join([f'<tr><td>{k}:</td><td>{fmt(k, v)}</td></tr>' for k, v in callargs.items()]) return f'<div class=\"table-wrapper\"><table class=\"sensitivity-test-settings\">{html}</table></div>'","title":"custom_tab"},{"location":"reference/text_sensitivity/ui/notebook/#format_subtitle","text":"1 2 3 4 def format_subtitle ( self , subtitle : str ) -> str Format the subtitle in HTML format. Parameters: Name Type Description Default subtitle str Subtitle contents. None Returns: Type Description str Formatted subtitle. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def format_subtitle(self, subtitle: str) -> str: \"\"\"Format the subtitle in HTML format. Args: subtitle (str): Subtitle contents. Returns: str: Formatted subtitle. \"\"\" return f'<p class=\"info\">{subtitle}</p>'","title":"format_subtitle"},{"location":"reference/text_sensitivity/ui/notebook/#format_title","text":"1 2 3 4 5 6 def format_title ( self , title : str , h : str = 'h1' , ** renderargs ) -> str Format title in HTML format. Parameters: Name Type Description Default title str Title contents. None h str h-tag (h1, h2, ...). Defaults to 'h1'. 'h1' Returns: Type Description str Formatted title. View Source 1 2 3 def format_title(self, title: str, h: str = 'h1', **renderargs) -> str: return super().format_title(title, h=h, **renderargs).replace('_', ' ').title()","title":"format_title"},{"location":"reference/text_sensitivity/ui/notebook/#get_renderer","text":"1 2 3 4 def get_renderer ( self , meta : dict ) Get a render function (Callable taking meta , content and **renderargs and returning a str ). Parameters: Name Type Description Default meta dict Meta information to decide on appropriate renderer. None View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def get_renderer(self, meta: dict): type, subtype, _ = get_meta_descriptors(meta) if type == 'robustness': if subtype == 'input_space': return success_test_renderer if subtype == 'invariance': return success_test_renderer return default_renderer","title":"get_renderer"},{"location":"reference/text_sensitivity/ui/notebook/#render_content","text":"1 2 3 4 5 6 def render_content ( self , meta : dict , content : dict , ** renderargs ) -> str Render content as HTML. Overwrite this when subclassing for your custom implementation. Parameters: Name Type Description Default meta dict Meta config. None content dict Content config. None **renderags None Optional arguments for rendering. None Returns: Type Description str Formatted content. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def render_content(self, meta: dict, content: dict, **renderargs) -> str: \"\"\"Render content as HTML. Overwrite this when subclassing for your custom implementation. Args: meta (dict): Meta config. content (dict): Content config. **renderags: Optional arguments for rendering. Returns: str: Formatted content. \"\"\" renderer = self.get_renderer(meta) return renderer(meta, content, **renderargs)","title":"render_content"},{"location":"reference/text_sensitivity/ui/notebook/#render_elements","text":"1 2 3 4 5 def render_elements ( self , config : dict , ** renderargs ) -> str Render HTML title and content. Parameters: Name Type Description Default config dict Config meta & content. None **renderags None Optional arguments for rendering. None Returns: Type Description str Formatted title and content. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def render_elements(self, config: dict, **renderargs) -> str: \"\"\"Render HTML title and content. Args: config (dict): Config meta & content. **renderags: Optional arguments for rendering. Returns: str: Formatted title and content. \"\"\" meta, content = config['META'], config['CONTENT'] return self.render_title(meta, content, **renderargs) + \\ self.render_subtitle(meta, content, **renderargs) + \\ self.render_content(meta, content, **renderargs)","title":"render_elements"},{"location":"reference/text_sensitivity/ui/notebook/#render_subtitle","text":"1 2 3 4 5 6 def render_subtitle ( self , meta : dict , content , ** renderargs ) -> str View Source 1 2 3 4 5 6 7 def render_subtitle(self, meta: dict, content, **renderargs) -> str: type, subtype, _ = get_meta_descriptors(meta) name = f'{type}+{subtype}' return self.format_subtitle(TEST_EXP[name]) if name in TEST_EXP else ''","title":"render_subtitle"},{"location":"reference/text_sensitivity/ui/notebook/#render_title","text":"1 2 3 4 5 6 def render_title ( self , meta : dict , content : dict , ** renderargs ) -> str Render the title as HTML. Overwrite this when subclassing for your custom implementation. Parameters: Name Type Description Default meta dict Meta config. None content dict Content config. None **renderags None Optional arguments for rendering. None Returns: Type Description str Formatted title. View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def render_title(self, meta: dict, content: dict, **renderargs) -> str: \"\"\"Render the title as HTML. Overwrite this when subclassing for your custom implementation. Args: meta (dict): Meta config. content (dict): Content config. **renderags: Optional arguments for rendering. Returns: str: Formatted title. \"\"\" title = renderargs.pop('title', None) if title is None: if 'title' in meta: title = meta['title'] elif 'type' in meta: title = meta['type'] if 'subtype' in meta: title += f' ({meta[\"subtype\"]})' return self.format_title(title, **renderargs) if title else ''","title":"render_title"}]}